{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"30-second-example/","text":"30 Second Example \u00b6 The UP42 Python package uses six classes, representing the hierarchical structure of UP42 : Project > Workflow > Job > JobTask and Catalog & Tools A new workflow consisting of Sentinel-2 data and Image Sharpening is created. The area of interest and workflow parameters are defined. After running the job , the results are downloaded and visualized. import up42 up42 . authenticate ( project_id = \"123\" , project_api_key = \"456\" ) # up42.authenticate(cfg_file=\"config.json\") project = up42 . initialize_project () workflow = project . create_workflow ( name = \"30-seconds-workflow\" , use_existing = True ) # Add data and processing blocks to the workflow. print ( up42 . get_blocks ( basic = True )) input_tasks = [ 'sobloo-s2-l1c-aoiclipped' , 'sharpening' ] workflow . add_workflow_tasks ( input_tasks = input_tasks ) # Define the aoi and input parameters of the workflow. aoi = workflow . get_example_aoi ( as_dataframe = True ) #aoi = workflow.read_vector_file(\"data/aoi_berlin.geojson\", as_dataframe=True) input_parameters = workflow . construct_parameters ( geometry = aoi , geometry_operation = \"bbox\" , start_date = \"2018-01-01\" , end_date = \"2020-12-31\" , limit = 1 ) input_parameters [ \"sobloo-s2-l1c-aoiclipped:1\" ] . update ({ \"max_cloud_cover\" : 60 }) print ( input_parameters ) # Run a test job to check data availability and configuration. test_job = workflow . test_job ( input_parameters = input_parameters , track_status = True ) test_results = test_job . get_results_json () print ( test_results ) # Run the actual job. job = workflow . run_job ( input_parameters = input_parameters , track_status = True ) job . download_results () job . plot_results ()","title":"30 Second Example"},{"location":"30-second-example/#30-second-example","text":"The UP42 Python package uses six classes, representing the hierarchical structure of UP42 : Project > Workflow > Job > JobTask and Catalog & Tools A new workflow consisting of Sentinel-2 data and Image Sharpening is created. The area of interest and workflow parameters are defined. After running the job , the results are downloaded and visualized. import up42 up42 . authenticate ( project_id = \"123\" , project_api_key = \"456\" ) # up42.authenticate(cfg_file=\"config.json\") project = up42 . initialize_project () workflow = project . create_workflow ( name = \"30-seconds-workflow\" , use_existing = True ) # Add data and processing blocks to the workflow. print ( up42 . get_blocks ( basic = True )) input_tasks = [ 'sobloo-s2-l1c-aoiclipped' , 'sharpening' ] workflow . add_workflow_tasks ( input_tasks = input_tasks ) # Define the aoi and input parameters of the workflow. aoi = workflow . get_example_aoi ( as_dataframe = True ) #aoi = workflow.read_vector_file(\"data/aoi_berlin.geojson\", as_dataframe=True) input_parameters = workflow . construct_parameters ( geometry = aoi , geometry_operation = \"bbox\" , start_date = \"2018-01-01\" , end_date = \"2020-12-31\" , limit = 1 ) input_parameters [ \"sobloo-s2-l1c-aoiclipped:1\" ] . update ({ \"max_cloud_cover\" : 60 }) print ( input_parameters ) # Run a test job to check data availability and configuration. test_job = workflow . test_job ( input_parameters = input_parameters , track_status = True ) test_results = test_job . get_results_json () print ( test_results ) # Run the actual job. job = workflow . run_job ( input_parameters = input_parameters , track_status = True ) job . download_results () job . plot_results ()","title":"30 Second Example"},{"location":"CHANGELOG/","text":"Release notes \u00b6 Upgrading \u00b6 To upgrade to the latest version of up42-py use pip : pip install up42-py --upgrade You can determine your currently installed version using this command: pip show up42-py Versions \u00b6 0.11.0 (2020-08-13) \u00b6 Fix: Remove buffer 0 for fixing invalid geometry. Add map_quicklooks method for visualising quicklooks interactively. Add an example notebook for mapping quicklooks using map_quicklooks method. 0.10.1 (2020-08-13) \u00b6 Hotfix: Fixes usage of multiple features as the input geometry. 0.10.0 (2020-08-07) \u00b6 Add parallel jobs feature. Allows running jobs for multiple geometries, scene_ids or timeperiods in parallel. Adds workflow.construct_parameters_parallel , workflow.test_job_parallel , workflow.run_job_parallel and the new JobCollection object. Adjusts workflow.get_jobs and project.get_jobs to return JobCollections. Adjusts airports-parallel example notebook to use the parallel jobs feature. Adjusts flood mapping example notebook to use OSM block. Adds option to not unpack results in job.download_results . Now allows passing only scene_ids to workflow.construct_parameters . Improves layout of image results plots for multiple results. Added binder links. Now truncates log messages > 2k characters. Various small improvements & code refactorings. 0.9.3 (2020-07-15) \u00b6 Add support for secondary geojson file to job.map_results 0.9.2 (2020-07-04) \u00b6 Fix inconsistency with job.map_results selecting the json instead of the image 0.9.1 (2020-06-25) \u00b6 Fixes typo in catalog search parameters 0.9.0 (2020-05-07) \u00b6 Enable block_name and block_display_name for workflow.add_workflow_tasks Replace requirement to specify provider by sensor for catalog.download_quicklooks Add option to disable logging in up42.settings Add project.get_jobs and limit workflow.get_jobs to jobs in the workflow. Fix download of all output files Job name selectabable in workflow.test_job and workflow.run_job (with added suffix _py) Fix crs issues in make job.map_results , make plotting functionalities more robust 0.8.3 (2020-04-30) \u00b6 Pin geopandas to 0.7.0, package requires new crs convention 0.8.2 (2020-04-27) \u00b6 Removed job.create_and_run_job , now split into job.test_job and job.run_job","title":"Releases"},{"location":"CHANGELOG/#release-notes","text":"","title":"Release notes"},{"location":"CHANGELOG/#upgrading","text":"To upgrade to the latest version of up42-py use pip : pip install up42-py --upgrade You can determine your currently installed version using this command: pip show up42-py","title":"Upgrading"},{"location":"CHANGELOG/#versions","text":"","title":"Versions"},{"location":"CHANGELOG/#0110-2020-08-13","text":"Fix: Remove buffer 0 for fixing invalid geometry. Add map_quicklooks method for visualising quicklooks interactively. Add an example notebook for mapping quicklooks using map_quicklooks method.","title":"0.11.0 (2020-08-13)"},{"location":"CHANGELOG/#0101-2020-08-13","text":"Hotfix: Fixes usage of multiple features as the input geometry.","title":"0.10.1 (2020-08-13)"},{"location":"CHANGELOG/#0100-2020-08-07","text":"Add parallel jobs feature. Allows running jobs for multiple geometries, scene_ids or timeperiods in parallel. Adds workflow.construct_parameters_parallel , workflow.test_job_parallel , workflow.run_job_parallel and the new JobCollection object. Adjusts workflow.get_jobs and project.get_jobs to return JobCollections. Adjusts airports-parallel example notebook to use the parallel jobs feature. Adjusts flood mapping example notebook to use OSM block. Adds option to not unpack results in job.download_results . Now allows passing only scene_ids to workflow.construct_parameters . Improves layout of image results plots for multiple results. Added binder links. Now truncates log messages > 2k characters. Various small improvements & code refactorings.","title":"0.10.0 (2020-08-07)"},{"location":"CHANGELOG/#093-2020-07-15","text":"Add support for secondary geojson file to job.map_results","title":"0.9.3 (2020-07-15)"},{"location":"CHANGELOG/#092-2020-07-04","text":"Fix inconsistency with job.map_results selecting the json instead of the image","title":"0.9.2 (2020-07-04)"},{"location":"CHANGELOG/#091-2020-06-25","text":"Fixes typo in catalog search parameters","title":"0.9.1 (2020-06-25)"},{"location":"CHANGELOG/#090-2020-05-07","text":"Enable block_name and block_display_name for workflow.add_workflow_tasks Replace requirement to specify provider by sensor for catalog.download_quicklooks Add option to disable logging in up42.settings Add project.get_jobs and limit workflow.get_jobs to jobs in the workflow. Fix download of all output files Job name selectabable in workflow.test_job and workflow.run_job (with added suffix _py) Fix crs issues in make job.map_results , make plotting functionalities more robust","title":"0.9.0 (2020-05-07)"},{"location":"CHANGELOG/#083-2020-04-30","text":"Pin geopandas to 0.7.0, package requires new crs convention","title":"0.8.3 (2020-04-30)"},{"location":"CHANGELOG/#082-2020-04-27","text":"Removed job.create_and_run_job , now split into job.test_job and job.run_job","title":"0.8.2 (2020-04-27)"},{"location":"authentication/","text":"Authentication \u00b6 To create and run workflow you first need to authenticate with UP42 via your project credentials . Get your Project credentials \u00b6 Log in to UP42.com and create a new project or select an existing one. In the project's Developers section you can find the project_id and project_api_key . Authenticate \u00b6 Authenticate by passing the project credentials directly as arguments : import up42 up42 . authenticate ( project_id = \"123\" , project_api_key = \"456\" ) Alternatively, create a configuration json file and pass its file path: { \"project_id\" : \"123\" , \"project_api_key\" : \"456\" } import up42 up42 . authenticate ( cfg_file = \"config.json\" )","title":"Authentication"},{"location":"authentication/#authentication","text":"To create and run workflow you first need to authenticate with UP42 via your project credentials .","title":"Authentication"},{"location":"authentication/#get-your-project-credentials","text":"Log in to UP42.com and create a new project or select an existing one. In the project's Developers section you can find the project_id and project_api_key .","title":"Get your Project credentials"},{"location":"authentication/#authenticate","text":"Authenticate by passing the project credentials directly as arguments : import up42 up42 . authenticate ( project_id = \"123\" , project_api_key = \"456\" ) Alternatively, create a configuration json file and pass its file path: { \"project_id\" : \"123\" , \"project_api_key\" : \"456\" } import up42 up42 . authenticate ( cfg_file = \"config.json\" )","title":"Authenticate"},{"location":"catalog/","text":"Catalog Search \u00b6 Check data availability & download image preview quicklooks via the catalog search. You can filter by various parameters e.g. time period, area of interest, cloud cover etc. Currently the following sensors are supported: Pleiades, Spot, Sentinel1, Sentinel2, Sentinel3, Sentinel5p . Initialize Catalog \u00b6 import up42 up42 . authenticate ( project_id = \"123\" , project_api_key = \"456\" ) up42 . authenticate ( cfg_file = \"config.json\" ) catalog = up42 . initialize_catalog () Search scenes in aoi \u00b6 aoi = up42 . get_example_aoi ( location = \"Berlin\" , as_dataframe = True ) #aoi = up42.read_vector_file(\"data/aoi_washington.geojson\", # as_dataframe=False) search_parameters = catalog . construct_parameters ( geometry = aoi , start_date = \"2018-01-01\" , end_date = \"2020-12-31\" , sensors = [ \"pleiades\" ], max_cloudcover = 20 , sortby = \"cloudCoverage\" , limit = 10 ) search_results = catalog . search ( search_parameters = search_parameters ) display ( search_results . head ()) catalog . plot_coverage ( scenes = search_results , aoi = aoi , legend_column = \"scene_id\" ) Download & visualize quicklooks \u00b6 catalog . download_quicklooks ( image_ids = search_results . id . to_list (), sensor = \"pleiades\" ) catalog . map_quicklooks ( scenes = search_results , aoi = aoi )","title":"Catalog Search"},{"location":"catalog/#catalog-search","text":"Check data availability & download image preview quicklooks via the catalog search. You can filter by various parameters e.g. time period, area of interest, cloud cover etc. Currently the following sensors are supported: Pleiades, Spot, Sentinel1, Sentinel2, Sentinel3, Sentinel5p .","title":"Catalog Search"},{"location":"catalog/#initialize-catalog","text":"import up42 up42 . authenticate ( project_id = \"123\" , project_api_key = \"456\" ) up42 . authenticate ( cfg_file = \"config.json\" ) catalog = up42 . initialize_catalog ()","title":"Initialize Catalog"},{"location":"catalog/#search-scenes-in-aoi","text":"aoi = up42 . get_example_aoi ( location = \"Berlin\" , as_dataframe = True ) #aoi = up42.read_vector_file(\"data/aoi_washington.geojson\", # as_dataframe=False) search_parameters = catalog . construct_parameters ( geometry = aoi , start_date = \"2018-01-01\" , end_date = \"2020-12-31\" , sensors = [ \"pleiades\" ], max_cloudcover = 20 , sortby = \"cloudCoverage\" , limit = 10 ) search_results = catalog . search ( search_parameters = search_parameters ) display ( search_results . head ()) catalog . plot_coverage ( scenes = search_results , aoi = aoi , legend_column = \"scene_id\" )","title":"Search scenes in aoi"},{"location":"catalog/#download-visualize-quicklooks","text":"catalog . download_quicklooks ( image_ids = search_results . id . to_list (), sensor = \"pleiades\" ) catalog . map_quicklooks ( scenes = search_results , aoi = aoi )","title":"Download &amp; visualize quicklooks"},{"location":"cli/","text":"Command Line Interface (CLI) \u00b6 The CLI tool allows you to use the UP42 functionality from the command line. It is installed automatically with and based on the Python SDK. To check whether the tool is installed and functioning correctly, type the following on your terminal or command line. This will print out a summary of the available commands. up42 -h To get help on a specific command, use: up42 command -h Authenticate \u00b6 You can authenticate with a PROJECT_ID and PROJECT_API_KEY up42 -pid [ PROJECT_ID ] -pkey [ PROJECT_API_KEY ] auth Or using a config.json file: up42 -cfg [ path to config.json ] auth You can make the authentication persistent by storing either the project key pair or the path to the config file as an environment variable. export UP42_PROJECT_ID =[ PROJECT_ID ] export UP42_PROJECT_API_KEY =[ PROJECT_API_KEY ] Or when using config.json . export UP42_CFG_FILE =[ path to config.json ] To save the authentication for future sessions make sure to append these variables to your bash profile file: # Linux export UP42_CFG_FILE =[ path to config.json ] >> ~/.bashrc # MacOS export UP42_CFG_FILE =[ path to config.json ] >> ~/.bash_profile If you want to create a config.json file from a project key pair, you can use the config command. up42 -pid [ PROJECT_ID ] -pkey [ PROJECT_API_KEY ] config Workflows \u00b6 up42 workflow -h Create a new workflow: up42 project create-workflow a_test Or check which workflows already exist: up42 project get-workflows And get a workflow by its name: up42 project workflow-from-name -name a_test After running the command to persist the workflow you can get the workflow tasks: up42 workflow get-workflow-tasks You can also add workflow tasks to the workflow via a json file (see typical usage for an example): up42 workflow add-workflow-tasks new_workflow_tasks.json Jobs \u00b6 up42 job -h First create and run a new test job with parameters defined in a json file (see typical usage for an example): up42 workflow test-job input_parameters.json --track Then run the actual job with parameters: up42 workflow run-job input_parameters.json --track After running the command to persist the job you can download the quicklooks from job in current working directory (note that not all data blocks support quicklooks): up42 job download-quicklooks . Or download and unpack the results: up42 job download-results . You can also print out the logs of the job: up42 job get-log Catalog \u00b6 up42 catalog -h With the catalog commands you can easily search the UP42 catalog for data. First, create a parameter configuration: up42 catalog construct-parameters example_aoi.geojson --sensors pleiades --max-cloud-cover 5 Then get the results: up42 catalog search example_search_params.json General tools \u00b6 Get all public blocks in the platform: up42 get-blocks Get block details by name: up42 get-block-details -name oneatlas-pleiades-aoiclipped","title":"Command Line Interface (CLI)"},{"location":"cli/#command-line-interface-cli","text":"The CLI tool allows you to use the UP42 functionality from the command line. It is installed automatically with and based on the Python SDK. To check whether the tool is installed and functioning correctly, type the following on your terminal or command line. This will print out a summary of the available commands. up42 -h To get help on a specific command, use: up42 command -h","title":"Command Line Interface (CLI)"},{"location":"cli/#authenticate","text":"You can authenticate with a PROJECT_ID and PROJECT_API_KEY up42 -pid [ PROJECT_ID ] -pkey [ PROJECT_API_KEY ] auth Or using a config.json file: up42 -cfg [ path to config.json ] auth You can make the authentication persistent by storing either the project key pair or the path to the config file as an environment variable. export UP42_PROJECT_ID =[ PROJECT_ID ] export UP42_PROJECT_API_KEY =[ PROJECT_API_KEY ] Or when using config.json . export UP42_CFG_FILE =[ path to config.json ] To save the authentication for future sessions make sure to append these variables to your bash profile file: # Linux export UP42_CFG_FILE =[ path to config.json ] >> ~/.bashrc # MacOS export UP42_CFG_FILE =[ path to config.json ] >> ~/.bash_profile If you want to create a config.json file from a project key pair, you can use the config command. up42 -pid [ PROJECT_ID ] -pkey [ PROJECT_API_KEY ] config","title":"Authenticate"},{"location":"cli/#workflows","text":"up42 workflow -h Create a new workflow: up42 project create-workflow a_test Or check which workflows already exist: up42 project get-workflows And get a workflow by its name: up42 project workflow-from-name -name a_test After running the command to persist the workflow you can get the workflow tasks: up42 workflow get-workflow-tasks You can also add workflow tasks to the workflow via a json file (see typical usage for an example): up42 workflow add-workflow-tasks new_workflow_tasks.json","title":"Workflows"},{"location":"cli/#jobs","text":"up42 job -h First create and run a new test job with parameters defined in a json file (see typical usage for an example): up42 workflow test-job input_parameters.json --track Then run the actual job with parameters: up42 workflow run-job input_parameters.json --track After running the command to persist the job you can download the quicklooks from job in current working directory (note that not all data blocks support quicklooks): up42 job download-quicklooks . Or download and unpack the results: up42 job download-results . You can also print out the logs of the job: up42 job get-log","title":"Jobs"},{"location":"cli/#catalog","text":"up42 catalog -h With the catalog commands you can easily search the UP42 catalog for data. First, create a parameter configuration: up42 catalog construct-parameters example_aoi.geojson --sensors pleiades --max-cloud-cover 5 Then get the results: up42 catalog search example_search_params.json","title":"Catalog"},{"location":"cli/#general-tools","text":"Get all public blocks in the platform: up42 get-blocks Get block details by name: up42 get-block-details -name oneatlas-pleiades-aoiclipped","title":"General tools"},{"location":"detailed-example/","text":"Detailed Example \u00b6 This overview of the most important functions repeats the previous 30-seconds-example, but in more detail and shows additional functionality and alternative steps. Authenticate & access project \u00b6 import up42 up42 . authenticate ( project_id = \"123\" , project_api_key = \"456\" ) #up42.authenticate(cfg_file=\"config.json\") project = up42 . initialize_project () project Get information about the available blocks to later construct your workflow. up42 . get_blocks ( basic = True ) Create or access the workflow \u00b6 You can either create a new workflow, use project.get_workflows() to get all existing workflows within the project, or access an exisiting workflow directly via its workflow_id. Example: Sentinel 2 streaming & sharpening filter # Create a new, empty workflow. workflow = project . create_workflow ( name = \"30-seconds-workflow\" , use_existing = True ) workflow # Add workflow tasks - simple version. See above .get_blocks() result. input_tasks = [ 'sobloo-s2-l1c-aoiclipped' , 'sharpening' ] workflow . add_workflow_tasks ( input_tasks = input_tasks ) # You can also add workflow tasks via a specific block id. This is then tied to a specific block version, whereas adding it by block name will always # give you the latest block version. input_tasks = [ \"a2daaab4-196d-4226-a018-a810444dcad1\" , \"4ed70368-d4e1-4462-bef6-14e768049471\" ] workflow . add_workflow_tasks ( input_tasks = input_tasks ) # Check the added tasks. workflow . get_workflow_tasks ( basic = True ) # Alternative: Get all existing workflows within the project. all_workflows = project . get_workflows () workflow = all_workflows [ 0 ] workflow # Alternative: Directly access an existing workflow within the project by its workflow_id UP42_WORKFLOW_ID = \"7fb2ec8a-45be-41ad-a50f-98ba6b528b98\" workflow = up42 . initialize_workflow ( workflow_id = UP42_WORKFLOW_ID ) workflow Select the aoi \u00b6 There are multiple ways to select an aoi: Provide aoi the geometry directly in code as a FeatureCollection, Feature, GeoDataFrame, shapely Polygon or list of bounds coordinates. Use .draw_aoi() to draw the aoi and export it as a geojson. Use .read_vector_file() to read a geojson, json, shapefile, kml or wkt file. Use .get_example_aoi() to read multiple provided sample aois. aoi = [ 13.375966 , 52.515068 , 13.378314 , 52.516639 ] aoi = workflow . read_vector_file ( \"data/aoi_berlin.geojson\" , as_dataframe = True ) aoi . head ( 1 ) #aoi = workflow.get_example_aoi(location=\"Berlin\") #workflow.draw_aoi() Select the workflow parameters \u00b6 There are also multiple ways to construct the workflow input parameters: * Provide the parameters directly in code as a json string. * Use .get_parameters_info() to get a an overview of all potential parameters for the selected workflow and information about the parameter defaults and ranges. * Use .get_input_parameters(aoi_type=\"bbox\", aoi_geometry=aoi) to construct the parameters with the provided aoi and all default parameters. Selecting the aoi_type is independent from the provided aoi, you can e.g. provide a irregular Polygon and still select aoi_type=\"bbox\", then the bounding box of the polygon will be selected. workflow . get_parameters_info () input_parameters = { \"sobloo-s2-l1c-aoiclipped:1\" : { \"bbox\" : [ 13.375966 , 52.515068 , 13.378314 , 52.516639 ], \"ids\" : None , \"time\" : \"2018-01-01T00:00:00+00:00/2020-12-31T23:59:59+00:00\" , \"limit\" : 1 , \"zoom_level\" : 14 , \"time_series\" : None , \"max_cloud_cover\" : 30 }, \"sharpening:1\" : { \"strength\" : \"medium\" } } input_parameters = workflow . construct_parameters ( geometry = aoi , geometry_operation = \"bbox\" , limit = 1 ) # Further update the input_parameters manually input_parameters [ \"sobloo-s2-l1c-aoiclipped:1\" ] . update ({ \"max_cloud_cover\" : 60 }) input_parameters Test & Run the workflow & download results \u00b6 # Run a test job to query data availability and check the configuration. # With this test query you will not be charged with any data or processing # credits, but have a preview of the job result. test_job = workflow . test_job ( input_parameters = input_parameters , track_status = True ) test_results = test_job . get_results_json () print ( test_results ) # Run the actual workflow. job = workflow . run_job ( input_parameters = input_parameters , track_status = True ) Download & Display results \u00b6 # Download job result. results_fp = job . download_results () job . plot_results () job . map_results ()","title":"Detailed Example"},{"location":"detailed-example/#detailed-example","text":"This overview of the most important functions repeats the previous 30-seconds-example, but in more detail and shows additional functionality and alternative steps.","title":"Detailed Example"},{"location":"detailed-example/#authenticate-access-project","text":"import up42 up42 . authenticate ( project_id = \"123\" , project_api_key = \"456\" ) #up42.authenticate(cfg_file=\"config.json\") project = up42 . initialize_project () project Get information about the available blocks to later construct your workflow. up42 . get_blocks ( basic = True )","title":"Authenticate &amp; access project"},{"location":"detailed-example/#create-or-access-the-workflow","text":"You can either create a new workflow, use project.get_workflows() to get all existing workflows within the project, or access an exisiting workflow directly via its workflow_id. Example: Sentinel 2 streaming & sharpening filter # Create a new, empty workflow. workflow = project . create_workflow ( name = \"30-seconds-workflow\" , use_existing = True ) workflow # Add workflow tasks - simple version. See above .get_blocks() result. input_tasks = [ 'sobloo-s2-l1c-aoiclipped' , 'sharpening' ] workflow . add_workflow_tasks ( input_tasks = input_tasks ) # You can also add workflow tasks via a specific block id. This is then tied to a specific block version, whereas adding it by block name will always # give you the latest block version. input_tasks = [ \"a2daaab4-196d-4226-a018-a810444dcad1\" , \"4ed70368-d4e1-4462-bef6-14e768049471\" ] workflow . add_workflow_tasks ( input_tasks = input_tasks ) # Check the added tasks. workflow . get_workflow_tasks ( basic = True ) # Alternative: Get all existing workflows within the project. all_workflows = project . get_workflows () workflow = all_workflows [ 0 ] workflow # Alternative: Directly access an existing workflow within the project by its workflow_id UP42_WORKFLOW_ID = \"7fb2ec8a-45be-41ad-a50f-98ba6b528b98\" workflow = up42 . initialize_workflow ( workflow_id = UP42_WORKFLOW_ID ) workflow","title":"Create or access the workflow"},{"location":"detailed-example/#select-the-aoi","text":"There are multiple ways to select an aoi: Provide aoi the geometry directly in code as a FeatureCollection, Feature, GeoDataFrame, shapely Polygon or list of bounds coordinates. Use .draw_aoi() to draw the aoi and export it as a geojson. Use .read_vector_file() to read a geojson, json, shapefile, kml or wkt file. Use .get_example_aoi() to read multiple provided sample aois. aoi = [ 13.375966 , 52.515068 , 13.378314 , 52.516639 ] aoi = workflow . read_vector_file ( \"data/aoi_berlin.geojson\" , as_dataframe = True ) aoi . head ( 1 ) #aoi = workflow.get_example_aoi(location=\"Berlin\") #workflow.draw_aoi()","title":"Select the aoi"},{"location":"detailed-example/#select-the-workflow-parameters","text":"There are also multiple ways to construct the workflow input parameters: * Provide the parameters directly in code as a json string. * Use .get_parameters_info() to get a an overview of all potential parameters for the selected workflow and information about the parameter defaults and ranges. * Use .get_input_parameters(aoi_type=\"bbox\", aoi_geometry=aoi) to construct the parameters with the provided aoi and all default parameters. Selecting the aoi_type is independent from the provided aoi, you can e.g. provide a irregular Polygon and still select aoi_type=\"bbox\", then the bounding box of the polygon will be selected. workflow . get_parameters_info () input_parameters = { \"sobloo-s2-l1c-aoiclipped:1\" : { \"bbox\" : [ 13.375966 , 52.515068 , 13.378314 , 52.516639 ], \"ids\" : None , \"time\" : \"2018-01-01T00:00:00+00:00/2020-12-31T23:59:59+00:00\" , \"limit\" : 1 , \"zoom_level\" : 14 , \"time_series\" : None , \"max_cloud_cover\" : 30 }, \"sharpening:1\" : { \"strength\" : \"medium\" } } input_parameters = workflow . construct_parameters ( geometry = aoi , geometry_operation = \"bbox\" , limit = 1 ) # Further update the input_parameters manually input_parameters [ \"sobloo-s2-l1c-aoiclipped:1\" ] . update ({ \"max_cloud_cover\" : 60 }) input_parameters","title":"Select the workflow parameters"},{"location":"detailed-example/#test-run-the-workflow-download-results","text":"# Run a test job to query data availability and check the configuration. # With this test query you will not be charged with any data or processing # credits, but have a preview of the job result. test_job = workflow . test_job ( input_parameters = input_parameters , track_status = True ) test_results = test_job . get_results_json () print ( test_results ) # Run the actual workflow. job = workflow . run_job ( input_parameters = input_parameters , track_status = True )","title":"Test &amp; Run the workflow &amp; download results"},{"location":"detailed-example/#download-display-results","text":"# Download job result. results_fp = job . download_results () job . plot_results () job . map_results ()","title":"Download &amp; Display results"},{"location":"examples-intro/","text":"Examples \u00b6 This section provides more extensive use cases for the UP42 Python SDK. All examples are provided as Jupyter notebooks in the examples folder . Radar Processing Airport monitoring with parallel jobs Flood Mapping \ud83d\uddbc\ufe0f Image mosaicking Catalog Quicklooks","title":"Examples"},{"location":"examples-intro/#examples","text":"This section provides more extensive use cases for the UP42 Python SDK. All examples are provided as Jupyter notebooks in the examples folder . Radar Processing Airport monitoring with parallel jobs Flood Mapping \ud83d\uddbc\ufe0f Image mosaicking Catalog Quicklooks","title":"Examples"},{"location":"installation/","text":"Installation \u00b6 User installation \u00b6 Install via pip . The package requires Python version > 3.6. pip install up42-py Update an existing installation to the newest version via: pip install up42-py --upgrade Optional: Install Jupyter Lab The UP42 Python SDK is even more comfortable to use in a Jupyter notebook ! To install Jupyter Lab: pip install jupyterlab Test the installation \u00b6 To test the successful installation, import it in Python: import up42 Success! Continue with the Authentication chapter ! Development installation \u00b6 The development installation is only necessary if you want to contribute to up42-py or its documentation. Please see the developer readme for the full installation instructions and further information.","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#user-installation","text":"Install via pip . The package requires Python version > 3.6. pip install up42-py Update an existing installation to the newest version via: pip install up42-py --upgrade Optional: Install Jupyter Lab The UP42 Python SDK is even more comfortable to use in a Jupyter notebook ! To install Jupyter Lab: pip install jupyterlab","title":"User installation"},{"location":"installation/#test-the-installation","text":"To test the successful installation, import it in Python: import up42 Success! Continue with the Authentication chapter !","title":"Test the installation"},{"location":"installation/#development-installation","text":"The development installation is only necessary if you want to contribute to up42-py or its documentation. Please see the developer readme for the full installation instructions and further information.","title":"Development installation"},{"location":"privacy-policy/","text":"Privacy Policy \u00b6 Last amended: September, 14 th , 2020 UP42 respects your privacy and is committed to transparent privacy practices. This Privacy Policy explains how UP42 GmbH (collectively \u201cUP42\u201c, or \u201cwe\u201c, or \u201cus\u201c, or \u201cour\u201c) collects, uses and shares your personal information in connection with your use of our website www.up42.com and explains your choices for how we handle your personal information. For convenience, the site and our services are collectively also referred to as the \u201cService.\u201d 1. CONTACT DETAILS OF THE CONTROLLER \u00b6 The website www.up42.com is provided by UP42 GmbH, Ohlauer Stra\u00dfe 43, 10999 Berlin. UP42 is also the controller within the meaning of the EU General Data Protection Regulation (GDPR) for the collection, processing and use of personal data of website visitors (hereinafter referred to as \u201cyou\u201d). Should you have any questions or suggestions regarding data protection, please do not hesitate to contact us. You are welcome to direct your data protection concerns to our data protection officer by sending an email to privacy@up42.com . Our full contact details are available here . 2. DATA PROCESSING WHEN YOU USE OUR WEBSITE \u00b6 2.1. Visiting the site. In the context of visiting the site personal data is only collected if this is necessary for technical reasons to use our website or if you use certain functions or services offered on our website, e.g. the application form. The following access data is automatically recorded every time our website is accessed: date and time of access (\u201ctime stamp\u201d) name of the file requested website from which the file was requested access status (e.g. file transferred, file not found) Browser type / version used operating system It is necessary to process this data to make it possible to visit the website and to guarantee the long-term functionality, availability and security of our systems. The legal basis for this data processing is Art. 6(1) (b) GDPR. 2.2. Registration for closed beta. You have the opportunity to register to our closed beta. This requires you to provide an email address where we can contact you. We also ask for your name so that we can address you. We would also ask you to let us know what you expect from our service, the geospatial data sources you are interested in and the processing algorithms you would like to use. Also, we would like to understand your background and role at your company. We process this registration data you provide in order to create an account for our closed beta. We will send you further information regarding the closed beta by email. The legal basis for this data processing is Art. 6(1) (b) GDPR. The data collected when you use the registration form will be stored for the period of the closed beta and the subsequent phase of the early stage of our service. 2.3. Registration and login. To use our service, you need to set up a user account for. This requires you to provide an email address, the first and last name, your company name and its legal structure and address. A password will be required to login to the UP42 Platform. We process this registration and login data in order to create and manage the UP42 account for you. The legal basis for this data processing is Art. 6(1) (b) GDPR. Using the UP42 platform. When you compile and manage projects on the UP42 platform, this project- and workflow-related data (e.g. integrated blocks and their characteristics, job and processing parameters, map information as well as workflow results) and information about the related use of the platform (e.g. timestamps, changes to project, settings and status) is stored in connection with your UP42 user account and used to calculate, pay and invoice your royalties. If you purchase geospatial offerings on the UP42 marketplace, you may need to provide payment data to enable the transaction. Depending on which payment method you chose, the data required for the respective transaction will be processed to a payment service provides. Some payment service providers collect personal data under their own responsibility. In this respect, the data protection policy of the respective payment service provider applies (see below). Stripe We use the services of Stripe, provided by Stripe Inc. 185 Berry Street, Suite 550, San Francisco, CA 94108, USA (\u201c Stripe \u201d). Stripe is an external payment-service provider for processing payments made to us. In connection with the processing of such data we store no personally identifiable data or financial information, such as credit card numbers. Instead, the data (particularly contact and transaction data) are passed directly to stripe, and its use of personal data is governed by its privacy statement. Stripe collects further data for its own purposes, e.g. for prevention of misuse, for further development of its products, and for marketing purposes. These further data collected through cookies and other technologies include, in particular, communication data (IP address, device identifier, browser version and information of the operating system). Some of Stripe\u2019s data processing takes place on servers in the USA. Should personal data be transmitted to the USE, Stripe has acceded to the EU-U.S. Privacy Shield . You will find more detailed Information in Stripe\u2019s Privacy Statement . 2.4. Support. We process information you provide in the support contact form to respond to your support request. In the context of this support request, we also collect your account name and other account data. We will process this data and, if necessary, data regarding workflows stored in your UP42 user account or other project- and workflow-related data to answer the request. The legal basis is Art. 6 (1) (b) GDPR. Zendesk For the purpose of solving your support request, we use Zendesk, a service provided by Zendesk Inc., 1019 Market Street, San Francisco, CA 94103, USA (\u201c Zendesk \u201d). Any of your support request will be handled through a ticket system provided by Zendesk. This ticket system allows use to deal with your support request effective and comprehensive. For this purpose, some of your personal data regarding your request, will be transmitted to Zendesk. Legal basis for this processing of your data is Art. 6 (1) (b) GDPR. If any of your data is transmitted to Zendesk server outside in the United States, Zendesk guarantees that your data will be handled in accordance to the GDPR. Zendesk has acceded to the EU-U.S. Privacy Shield . For more information about data processing and data privacy at Zendesk, please visit the Zendesk Privacy Policy .2.5. Sign-up forms and questionnaire. On our Website, you can find the opportunity to interact with us through the usage of sign-up forms and questionaires. Those will help us to provide better services to you. The usage of those forms and questionaires leads to the processing of some of your personal data, e.g. your contact details. Legal basis for the processing is our legitimate and shared interested to provide services to you, in accordance with Art. 6 (1) (f) GDPR. Zenflow To offer you those sign-up forms and questionaires, we use Zenflow, a service by Goflow IVS, Porcel\u00e6nshaven 24B, 2000 Frederiksberg, Denmark (\u201c Zenflow \u201d). Zenflow provides HTML based solutions to implement the above-mentioned features. By using the service of Zenflow, some of your personal data (e.g. your contact details and the answers you gave in a questionnaire) are processed by Zenflow. The processing will only occur in accordance with the GDPR and on the base of a sufficient contractual relationship between us and Zenflow. The standards of the GDPR are applicable for Zenflow. 2.5. UP42 newsletter. When registering for our closed beta you also have the opportunity to subscribe to our UP42 newsletter, which informs you regularly about our release notes, geospatial trends and updates regarding our service. When registering for the UP42 newsletter, we ask you to provide your email address so that we can send you the newsletter. For newsletter subscriptions we use the so-called double opt-in procedure, which means that we will only send you UP42 newsletters by email if you click on a link in our notification email to confirm that you are the owner of the email address provided. If you confirm your email address, we will store your email address, the time of registration and the IP address you used when registering until you unsubscribe from the newsletter. The sole purpose of storing this data is to be able to send you the newsletter and prove that you registered. You can unsubscribe from the UP42 newsletter at any time. A corresponding unsubscribe link can be found in every newsletter. It is of course also sufficient if you notify us using the contact details provided above or in the newsletter (e.g. by email or letter). The legal basis of the above processing is your consent pursuant to Art. 6(1)(a) GDPR. Mailchimp To provide you with the Newsletter we use Mailchimp. Mailchimp is a service by The Rocket Science Group LLC, 675 Ponce de Leon Ave NE, Atlanta, GA 30308, USA to send and manage E-Mail campaigns and Newsletters. For that purpose, your E-Mail-Address will be forwarded to Mailchimp. As Mailchimp operates from the United States, your personal data may be transferred to the United States. To ensure that your data is handled in Accordance with the GDPR, Mailchimp participates in the EU-U.S. Privacy Shield . For more information about data privacy at Mailchimp, please visit the Mailchimp Privacy Policy . 3. COOKIES, MARKETING AND ANALYTICS TOOLS \u00b6 3.1. Do Not Track Policy . Some web browsers have a \u201cDo Not Track\u201d feature. This feature lets you tell websites you visit that you do not want to have your online activity tracked. These features are not yet uniform across browsers. Our sites are not currently set up to respond to those signals. You can also decide to change your consent and revoke cookies on our website by clicking the button below. However, if you do not accept cookies, you may not be able to use some portions of our Service. Cookie Settings 3.2. General use of cookies. When you visit and use our website, we store a variety of cookies. Cookies are small text files stored in your web browser\u2019s memory which contain information that can be used to recognize you when you visit web servers later on. However, this does not mean that we are immediately aware of your identity. Cookies cannot execute any programs or transfer viruses to your computer. The primary purpose of our own cookies is rather to make using our service as time-saving and user-friendly as possible. We use cookies in particular - for load balancing; - to store language settings; - to store form data; - to note that information placed on our website has been displayed to you, so that it will not be displayed again the next time you visit the website. For example, we use so-called session cookies to recognize that you have already visited individual pages on our website. These cookies are deleted 30 minutes after you stop interacting with our website. In addition, to improve usability, we also use temporary cookies that are stored on your device for a specified period of time. If you visit our site again to take advantage of our services, it will automatically recognize that you have already been with us and what inputs and settings you have made, so you do not have to re-enter them. On the other hand, we use cookies to statistically record the use of our website and to evaluate it for the purpose of optimizing our offer. These cookies allow us to automatically recognize when you visit our site again that you have already been with us. We also use cookies for marketing purposes. These cookies store behavioral information about users obtained through the observance of their browsing habits, which allows a specific profile to be defined in order to show advertising on the basis of such profile. These cookies are automatically deleted after 14 months. We do this to be able to make your use of our website more convenient and personalized. The processing of the respective cookies is based on our aforementioned legitimate interests, meaning the legal basis is Art. 6(1) (f) GDPR. You can prevent the storage of cookies by adjusting your browser settings to disable the acceptance of cookies via this website. If you do not accept cookies, however, this may in some cases lead to considerable functional restrictions on our website. 3.3. Cookies and other technologies from third-party providers. In addition, we also use cookies and technologies from third-party providers for analysis and marketing purposes as part of the statistical recording and analysis of general usage behaviour based on access data as well as collected basic device information (e.g. browser type / version, used operating system) and the collected IP address of our website visitors. We use the results of such analyses to improve our website and services and adapt them to the actual needs of our users as well as for marketing reasons. The legal basis for the individual examples of data processing described below is your consent as in Art. 6 (1) a GDPR. You have the right to withdrawal your consent at any time. To do so, please go to the privacy settings: Privacy Settings 0. OneTrust. For the purpose of cookie- and consent-management, we use the tool OneTrust, a service provided by OneTrust, LLC, 1200 Abernathy Rd NE, Building 600, Atlanta, GA, USA and Dixon House, 1 Lloyd\u2018s Avenue, London EC3N 3DQ, United Kingdom (hereafter: OneTrust). OneTrust is used to provide you with the cookie-banner when visiting our homepage and to store and manage the consent options you decided on in regards to the use of cookies. To do so, OneTrust implements a cookie of its own on your device and receives data including your IP-Address and your chosen settings to provide its services. Legal basis for our use of OneTrust is our legitimate interest in providing a functional and legally certain service on our website, Art. 6 (1) f GDPR. You can object to that use at any time (see section \u201eyour rights\u201c) or change your browser settings to not accept JavaScript to prevent the use of the OneTrust-cookie. If set, the cookie will be deleted after one-year-period. If OneTrust transmits data to the United States in order to provide its services, an appropriate level of data privacy is secured as OneTrust is certified under the EU-U.S.-Privacy-Shield . For more information on data privacy at OneTrust, please visit the privacy notice . a. Google Analytics. Our website uses the web analytics service Google Analytics, provided by Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Ireland (\"Google\") for users from the European Economic Area, Switzerland and Liechtenstein and by Google LLC, 1600 Amphitheatre Parkway Mountain View, CA 94043, USA for all other users. Google Analytics uses cookies with a validity of 14 months to record your access data when you visit our website. On our behalf, Google combines the access data into pseudonymous user profiles and transmits it to a Google server in the USA. Your IP address is anonymised beforehand. We are therefore unable to determine which user profiles belong to a particular user. This means that we cannot identify you or determine how you use our website based on the information collected by Google. In cases where this involves transferring personal data to the USA, Google has also subjected itself to the EU-US Privacy Shield . Google has thus committed itself to ensuring the European data protection principles and level of data protection even in the context of data processing performed in the USA. On our behalf, Google uses the information generated by cookies for the purpose of evaluating the usage of our website, compiling reports on website activity, and providing us with other services relating to website usage and internet usage. For further information, please refer to the Google Analytics privacy policy. You may object to these web analytics activities by Google at any time. There are several ways to do this: You can configure your browser to block cookies from Google Analytics. You can adjust your advertising settings on Google: Google Ads Settings In the browsers Firefox, Internet Explorer and Chrome, you can install the deactivation plug-in provided by Google using the following link (this option does not work on mobile devices): Browser-Add-on For further information about Google Analytics, please refer to Google\u2019s privacy policy. b. Hotjar. We use Hotjar, a web analytics service from Hotjar Ltd., for the purpose of continuously improving our website and services. Hotjar Ltd. is headquartered in Julians Business Centre, 3, Elia Zammit Street, St Julians STJ 1000, Malta, Europe. Hotjar allows us to track mouse movements, mouse clicks and scroll movements while a visitor is active on our homepage. The user behaviour is reported in an aggregated format in so-called heatmaps. Furthermore, technical data such as browser type, language preferences, operating system and screen resolution, Incoming and outgoing links, geographic origin and your location (country only) are captured and evaluated for statistical purposes as well as to analyse how you visited our website. This information will only be processed under a pseudonym and will not be passed on to third parties by us or Hotjar. Personal data entered in forms on our website will be hidden and not collected by Hotjar. Additionally, users have the possibility to provide direct feedback (the feedback pane) through a plug-in offered by Hotjar which helps us improving our product offering. For more information refer to Hotjar's privacy policy . You may prevent Hotjar from collecting the above mentioned data on all websites operated by us or other providers that use Hotjar by opting out here . c. Google Ads. Our website uses \u201cGoogle Ads\u201d, a marketing service provided by Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Ireland (\"Google\"), to advertise our services within Google Search and the Google Search Network following your visit to our website. The service uses cookies and similar technologies for this purpose. For evaluation purposes, Google may transfer the data generated in this context to a Google-server in the USA and store it there. In the event that personal data is transferred to the USA, Google has subjected itself to the EU-US Privacy Shield . Google has thus committed itself to ensuring the European data protection principles and level of data protection even in the context of data processing occurring in the USA. If you use a Google Account, depending on the settings in your Google Account, Google can link your web and app browsing history to your Google Account and use information from your Google Account to show you personalised ads. If you do not want this information to be associated with your Google Account, you must log out of Google before visiting our website. You can configure your browser to reject cookies as described above. You can also disable the \u201cAds Personalisation\u201d button in your Google Ads Settings . In this case, Google will then only display general advertising which has not been selected based on information collected about you. Please refer to Google\u2019s Privacy Policy for further details. d. Bing Ads. Our website uses Bing Ads, a service of Microsoft Corporation, One Microsoft Way, Redmond, WA 98052-6399, USA (\u201cMicrosoft\u201d). Microsoft uses cookies and similar technologies to present you with advertisements which you may find relevant. The use of these technologies enables Microsoft and its partner websites to insert advertisements on the basis of previous visits to our or other websites on the internet. e. LinkedIn. We use the LinkedIn conversion tracking retargeting tool for marketing purposes, provided by LinkedIn Ireland, Wilton Plaza, Wilton Place, Dublin 2, Ireland (\u201cLinkedIn\u201d). A LinkedIn Insight Tag is integrated into our website, which enables LinkedIn to collect pseudonymous data about your visit and the use of our website and to provide us with corresponding aggregated statistics on this basis. In addition, this information is used to show you interest-based and relevant offers and recommendations after you have shown an interest in certain information and e.g. job vacancies on our website. This information is assigned via a cookie. You can prevent the storage of cookies by adjusting your browser settings. Alternatively, you can object to this form of data processing by using the following link to place an opt-out cookie, which will remain on your device until you delete the cookie. This option is available to both LinkedIn members and non-members. For further information, please refer to the LinkedIn privacy policy . f. Facebook conversion and retargeting tags. For marketing purposes our website uses what are known as conversion and retargeting tags (also called Facebook Pixels) from the social network Facebook, a service of Facebook, Inc., 1601 Willow Road, Menlo Park, California 94025, USA (\u201cFacebook\u201d). We use Facebook Pixels to analyze the general use of our website and to track the effectiveness of Facebook advertising (\u201cconversion\u201d). We may also use Facebook Pixels to show you individualized advertising messages based on your interest in our website and our services (\u201cretargeting\u201d). For this purpose, Facebook processes data that the service collects via cookies and similar technologies on our website. Facebook may transfer the data generated in this context to a server in the USA for evaluation and store it there. In exceptional cases where this involves transferring personal data to the USA, Facebook has also subjected itself to the EU-US Privacy Shield . Facebook has thus committed itself to ensuring the European data protection principles and level of data protection even in the context of data processing performed in the USA. If you are member of Facebook and have given Facebook the relevant permission in your account\u2019s privacy settings, Facebook may also link the information recorded about your visit to us to your member account and use it to deploy targeted Facebook ads. You can view and change the privacy settings of your Facebook profile at any time. If you are not a member of Facebook, you can prevent Facebook from processing your data by clicking on the deactivation button for the provider \u201cFacebook\u201d on the external TrustArc opt-out website. Alternatively, you can disable the Facebook Pixel on the Digital Advertising Alliance page at the following Link: here . If you disable data processing by Facebook, Facebook will only display general Facebook ads that are not selected based on information recorded about you. Please refer to Facebook\u2019s data policy for further details. g. Twitter Ads. On our website we use services of the short message service Twitter, Twitter International Company, One Cumberland Place, Fenian Street Dublin 2, D02 AX07 Ireland (\u201cTwitter\u201d). Twitter enables us to use visitor interaction pixels to deploy target group-based advertising, retargeting and conversion measurements for online advertising. This involves deploying offers for certain target groups based on a selection of general criteria, e.g. demographic characteristics, regions or interests. Twitter also allows us to display targeted ads based on a user\u2019s previous page views. For example, ads about our services can be shown to the respective user if that user has previously been interested in certain information or offers on our website. Twitter is certified under the EU-US Privacy Shield and is thus committed to complying with European data protection regulations. You can prevent this data processing by disabling the storage of cookies in your browser by adjusting the settings as described above. If you are a Twitter user, you can also prevent the aforementioned data processing in your Twitter account by adjusting the \u201cPersonalized ads\u201d setting in the \u201cPersonalization and Data\u201d area. On mobile devices, the aforementioned data processing can also be prevented using the system settings \u201cLimit Ad Tracking\u201d (iOS) or \u201cInterest-based ads\u201d (Android). For further information, please refer to the Twitter website . h. Google Tag Manager. Our website uses Google Tag Manager, a service provided by Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Ireland (\"Google\"). Google Tag Manager serves to manage tools for usage data analyses and other services, so-called website tags. A tag is an element that is stored in the source code of our website in order to record, for example, predefined uses and interactions. Google Tag Manager does not use cookies. Google Tag Manager enables us to integrate partners in the context of online advertising. If you opted-out of the processing for the other tools and third-party services described in this section, no data will be processed by Google Tag Manager. In some cases, the data is processed on a Google server in the USA. In exceptional cases where this involves transferring personal data to the USA, Google has also subjected itself to the EU-US Privacy Shield . Google has thus committed itself to ensuring the European data protection principles and level of data protection even in the context of data processing performed in the USA. For more details, please refer to the information provided by Google about Google Tag Manager . 3.4. Commercial E-Mails. We may send you commercial e-mail with business information or offers, if we have the right to do so. This right can arise from your consent or from the contractual relationship you have with us. The legal base for such mailing would then either be Art. 6 (1) (a) or Art. 6 (1) (b) GDPR. SendGrid To send the above-mentioned commercial e-mails we use SendGrid. SendGrid is a service by SendGrid, Inc., 1801 California Street, Suite 500, Denver, CO 80202, USA (\u201c SendGrid \u201d). We use SendGrid to provide you with the mentioned business information and offers. To conduct that service, SendGrid processes your personal data, such as your contact information or content of your e-mail communication with us. SendGrid will only do so on our behalf and on the base of a contractual relationship with us in accordance to the GDPR. If SendGrid processes your data on server in the United States, SendGrid guarantees, that such data processing is done in accordance with the GDPR. SendGrid has subjected itself under the EU-U.S. Privacy Shield . If you want more information about the data processing and data privacy at SendGrid, please visit SendGrid\u2019s data privacy policy . 1. Hosting a. Github Parts of this website are hosted on Servers of GitHub Inc., 88 Colin P Kelly Jr. St, San Francisco, CA 94107, USA (\u201cGitHub\u201d). If you use those pages, GitHub can have access to your technical information such as your ID-Address. All data processing by GitHub on behalf of UP42 is subject to legal binding contracts in accordance with the GDPR. More information on data privacy on GitHub can be found on the GitHub Privacy Policy ./ 4. LINKS TO OTHER WEBSITES AND ONLINE CONTENT \u00b6 Our website may contain links to websites and online content of other providers not affiliated with us. If you activate these links, we naturally no longer have any influence on which data is collected by the respective providers and which data they record. For more detailed information on data collection and use, please refer to the privacy policies of the respective providers. Since the collection and processing of data by third parties is beyond our control, we cannot assume any responsibility for this. 5. OUR SOCIAL MEDIA PROFILES \u00b6 5.1. Social media Profiles. We are represented in various social networks. - Facebook (Facebook Inc., 1601 Willow Road Menlo Park, CA 94025, USA), Privacy Policy - Twitter (Twitter, Inc., 1355 Market Street Suite 900 San Francisco, CA 94103, USA), Privacy Policy - Instagram (Instagram Inc., 181 South Park Street Suite 2 San Francisco, CA 94107, USA), Privacy Policy - LinkedIn (LinkedIn Corporation, 2029 Stierlin Court Mountain View, CA 94043, USA), Privacy Policy - Medium (A Medium Corporation, 760 Medium Street San Francisco, CA 94102, USA), Privacy Policy - On our website we link to our company profiles on the respective social networks. Please note, that when you activate a link to a social network, data is transferred to servers of the respective provider. If you are logged in to the respective social network at that moment with your username and password, the information that you are visiting our website will be transferred to the social network and the respective provider may assign this information to your user account. Basically, we have no way of influencing the data processing regarding the social networks. But we do receive statistics about usage and visits of our company profiles on the social networks (e.g., information about the number of views, interactions such as likes, comments and reteweets, and aggregated demographic and other information or statistics). For this purpose, we submit certain parameters regarding our company and the services and content we offer on our company profile to the social network specific. This information is used by the providers to create more detailed statistics. In addition, the providers may use data they collect when you visit the social network for their own purposes beyond our control. For more detailed information, please refer to the providers' privacy notice linked above. If we receive your personal data via our social media profiles (e.g. via direct messages), you are entitled to the rights set out in this privacy policy (see section 11 \"Your rights\"). You can send us your inquiries to gain access to stored personal data with regard to data processing in the context of our company profiles using contact data specified in section 1. We will then inform you about the data we have collected on our own and data which was transmitted to us to comply with the rights you have exercised against us. If you also intend to assert rights against the social network provider, the easiest way to do so is to directly contact the respective provider. The provider knows the details on the technical operation of the platform and the associated data processing as well as the concrete purposes of data processing and can put appropriate measures into practice to comply with your inquiry. The contact details can be found in the privacy notice linked above. We gladly support you in asserting your rights to the extent of our competence. The legal basis for linking and operating our company social media profiles is Art. 6(1) (f) GDPR based on our legitimate interest in our corporate communications in the respective social networks. 5.2. Implementation of Videos with Wistia. We use the option to implement videos on our Website. For this implementation, we use Wistia, a service by Wistia, Inc., 17 Tudor Street, Cambridge, MA 02139, USA (\u201c Wistia \u201d). When interacting with the videos, your personal data such as your IP-Address,\u201dcookie\u201d information and your requested page are processed by Wistia. The legal base for our use of Wistia is our legitimate interest in using Videos for our Website, in accordance to Art. 6 (1) (b) GDPR. Through Wistia, your data can be processed on servers in the United States. If this is done, Wistia guarantees to do such data processing in accordance with the GDPR. Wistia has subjected itself to the EU-U.S. Privacy Shield . You can configurate your browser as stated above to prohibit the use of cookies. For more information about the data processing and data privacy and Wistia and how to opt-out from the data processing, please visit the Wistia Privacy Policy . 6. DISCLOSURE OF DATA \u00b6 In principle, we will only pass on the data we collect if: - you have given your explicit consent pursuant to Art. 6(1) (a) GDPR; - disclosure is necessary pursuant to Art. 6(1) (f) GDPR in order to establish, exercise or defend legal claims and there is no reason to assume that you have an overriding legitimate interest in your data not being disclosed; - we are legally obliged to do so under Art. 6(1) \u00a9 GDPR; or - this is permitted by law and is required under Art. 6(1) (b) GDPR for the processing of contractual relationships with you or for taking steps at your request prior to entering into a contract. Part of the data processing may be carried out by our service providers. In addition to the service providers mentioned in this privacy policy, this may in particular include data centres that store our website and databases, IT service providers that maintain our systems or provide CRM functionalities and consulting firms. If we pass data on to our service providers, they may use the data exclusively for the fulfilment of their tasks. We have carefully selected and commissioned the service providers. They are contractually bound by our instructions, have appropriate technical and organisational measures in place to protect the rights of data subjects and are carefully monitored by us. In addition, data may be disclosed in connection with official requests, court orders and legal proceedings if this is necessary to pursue or enforce rights. 7. SECURITY \u00b6 The security of your personal information important to us. We take a number of organizational, technical and physical measures designed to protect the personal information we collect, both during transmission and once we receive it. Our security is subject to constant improvement and our privacy policies are constantly being revised. Please make sure you have the latest version. 8. PERSONAL DATA RETENTION \u00b6 We store personal data only as long as we are entitled to do so, and the processing purpose is not eliminated and there was no objection. For the duration of storage of personal data, the respective statutory retention period applies. After the deadline, the corresponding data will be routinely deleted, if they are no longer required to fulfill the contract or to initiate a contract. 9. THIRD COUNTRY TRANSFER \u00b6 The above agreements may result in your personal information being stored and processed in countries outside the European Union. As data protection laws in third countries differ from those in the EEA, we have taken measures to ensure an adequate level of privacy and data protection outside the EEA. This includes the contractual agreement, by EU standard contractual clauses to ensure and comply with the data protection principles of the European Commission. Please contact us if you would like to request a copy of the safeguards that guarantee an adequate level of data protection. 10. YOUR RIGHTS \u00b6 You have the right to information about how we process your personal data at any time. When providing this information, we will explain the data processing to you and provide you with an overview of the data stored about you. If data stored by us is incorrect or no longer up to date, you have the right to have this data corrected. You may also demand that your data be erased. Should the erasure not be possible in exceptional cases due to other legal regulations, the data will be blocked so that it is only available for that legal purpose. You are also entitled to have the processing of your data restricted, e.g. if you believe that the data we have stored is incorrect. You also have the right to data portability, which means that on request we will send you a digital copy of the personal data you have provided on the basis of consent or a contractual relationship. In order to assert your rights described here, you can contact us at any time using the contact details provided in Section 1 above. In addition, you have the right to object to data processing if it is based on Art. 6(1)(e) or (f) GDPR or for marketing purposes. Finally, you have the right to lodge a complaint with our competent data protection supervisory authority. You can assert this right by contacting a supervisory authority in the Member State of your habitual residence, your place of work or the place of the alleged infringement. The supervisory authority in Berlin is: Berlin Commissioner for Data Protection and Freedom of Information, Friedrichstr. 219, 10969 Berlin. Right of withdrawal and objection. Pursuant to Art. 7(3) GDPR, you have the right to withdraw the consent you gave us at any time. As a result of this, we will cease the data processing based on this consent with future effect. This withdrawal of your consent will not affect the lawfulness of the processing carried out on the basis of the consent prior to the withdrawal. If we process your data on the basis of legitimate interests pursuant to Art. 6(1)(f) GDPR, you have the right under Art. 21 GDPR to object to the processing of your data, and to give us reasons which arise from your particular situation which, in your opinion, show that your legitimate interests override ours. If your objection is to data processing for direct marketing purposes, you have a general right of objection, which we will implement without requiring you to give reasons. If you would like to make use of your right of withdrawal or objection, it is sufficient to simply notify us using the contact details provided above. 11. UPDATES TO THIS PRIVACY POLICY \u00b6 This privacy policy is currently valid. As a result of the further development of our website and offers thereof or due to changed legal or official requirements, it may be necessary to change this privacy policy. The current privacy policy can be viewed and printed by you at any time on the website at up42.com/legal/privacy-policy.","title":"Privacy Policy"},{"location":"privacy-policy/#privacy-policy","text":"Last amended: September, 14 th , 2020 UP42 respects your privacy and is committed to transparent privacy practices. This Privacy Policy explains how UP42 GmbH (collectively \u201cUP42\u201c, or \u201cwe\u201c, or \u201cus\u201c, or \u201cour\u201c) collects, uses and shares your personal information in connection with your use of our website www.up42.com and explains your choices for how we handle your personal information. For convenience, the site and our services are collectively also referred to as the \u201cService.\u201d","title":"Privacy Policy"},{"location":"privacy-policy/#1-contact-details-of-the-controller","text":"The website www.up42.com is provided by UP42 GmbH, Ohlauer Stra\u00dfe 43, 10999 Berlin. UP42 is also the controller within the meaning of the EU General Data Protection Regulation (GDPR) for the collection, processing and use of personal data of website visitors (hereinafter referred to as \u201cyou\u201d). Should you have any questions or suggestions regarding data protection, please do not hesitate to contact us. You are welcome to direct your data protection concerns to our data protection officer by sending an email to privacy@up42.com . Our full contact details are available here .","title":"1.   CONTACT DETAILS OF THE CONTROLLER"},{"location":"privacy-policy/#2-data-processing-when-you-use-our-website","text":"2.1. Visiting the site. In the context of visiting the site personal data is only collected if this is necessary for technical reasons to use our website or if you use certain functions or services offered on our website, e.g. the application form. The following access data is automatically recorded every time our website is accessed: date and time of access (\u201ctime stamp\u201d) name of the file requested website from which the file was requested access status (e.g. file transferred, file not found) Browser type / version used operating system It is necessary to process this data to make it possible to visit the website and to guarantee the long-term functionality, availability and security of our systems. The legal basis for this data processing is Art. 6(1) (b) GDPR. 2.2. Registration for closed beta. You have the opportunity to register to our closed beta. This requires you to provide an email address where we can contact you. We also ask for your name so that we can address you. We would also ask you to let us know what you expect from our service, the geospatial data sources you are interested in and the processing algorithms you would like to use. Also, we would like to understand your background and role at your company. We process this registration data you provide in order to create an account for our closed beta. We will send you further information regarding the closed beta by email. The legal basis for this data processing is Art. 6(1) (b) GDPR. The data collected when you use the registration form will be stored for the period of the closed beta and the subsequent phase of the early stage of our service. 2.3. Registration and login. To use our service, you need to set up a user account for. This requires you to provide an email address, the first and last name, your company name and its legal structure and address. A password will be required to login to the UP42 Platform. We process this registration and login data in order to create and manage the UP42 account for you. The legal basis for this data processing is Art. 6(1) (b) GDPR. Using the UP42 platform. When you compile and manage projects on the UP42 platform, this project- and workflow-related data (e.g. integrated blocks and their characteristics, job and processing parameters, map information as well as workflow results) and information about the related use of the platform (e.g. timestamps, changes to project, settings and status) is stored in connection with your UP42 user account and used to calculate, pay and invoice your royalties. If you purchase geospatial offerings on the UP42 marketplace, you may need to provide payment data to enable the transaction. Depending on which payment method you chose, the data required for the respective transaction will be processed to a payment service provides. Some payment service providers collect personal data under their own responsibility. In this respect, the data protection policy of the respective payment service provider applies (see below). Stripe We use the services of Stripe, provided by Stripe Inc. 185 Berry Street, Suite 550, San Francisco, CA 94108, USA (\u201c Stripe \u201d). Stripe is an external payment-service provider for processing payments made to us. In connection with the processing of such data we store no personally identifiable data or financial information, such as credit card numbers. Instead, the data (particularly contact and transaction data) are passed directly to stripe, and its use of personal data is governed by its privacy statement. Stripe collects further data for its own purposes, e.g. for prevention of misuse, for further development of its products, and for marketing purposes. These further data collected through cookies and other technologies include, in particular, communication data (IP address, device identifier, browser version and information of the operating system). Some of Stripe\u2019s data processing takes place on servers in the USA. Should personal data be transmitted to the USE, Stripe has acceded to the EU-U.S. Privacy Shield . You will find more detailed Information in Stripe\u2019s Privacy Statement . 2.4. Support. We process information you provide in the support contact form to respond to your support request. In the context of this support request, we also collect your account name and other account data. We will process this data and, if necessary, data regarding workflows stored in your UP42 user account or other project- and workflow-related data to answer the request. The legal basis is Art. 6 (1) (b) GDPR. Zendesk For the purpose of solving your support request, we use Zendesk, a service provided by Zendesk Inc., 1019 Market Street, San Francisco, CA 94103, USA (\u201c Zendesk \u201d). Any of your support request will be handled through a ticket system provided by Zendesk. This ticket system allows use to deal with your support request effective and comprehensive. For this purpose, some of your personal data regarding your request, will be transmitted to Zendesk. Legal basis for this processing of your data is Art. 6 (1) (b) GDPR. If any of your data is transmitted to Zendesk server outside in the United States, Zendesk guarantees that your data will be handled in accordance to the GDPR. Zendesk has acceded to the EU-U.S. Privacy Shield . For more information about data processing and data privacy at Zendesk, please visit the Zendesk Privacy Policy .2.5. Sign-up forms and questionnaire. On our Website, you can find the opportunity to interact with us through the usage of sign-up forms and questionaires. Those will help us to provide better services to you. The usage of those forms and questionaires leads to the processing of some of your personal data, e.g. your contact details. Legal basis for the processing is our legitimate and shared interested to provide services to you, in accordance with Art. 6 (1) (f) GDPR. Zenflow To offer you those sign-up forms and questionaires, we use Zenflow, a service by Goflow IVS, Porcel\u00e6nshaven 24B, 2000 Frederiksberg, Denmark (\u201c Zenflow \u201d). Zenflow provides HTML based solutions to implement the above-mentioned features. By using the service of Zenflow, some of your personal data (e.g. your contact details and the answers you gave in a questionnaire) are processed by Zenflow. The processing will only occur in accordance with the GDPR and on the base of a sufficient contractual relationship between us and Zenflow. The standards of the GDPR are applicable for Zenflow. 2.5. UP42 newsletter. When registering for our closed beta you also have the opportunity to subscribe to our UP42 newsletter, which informs you regularly about our release notes, geospatial trends and updates regarding our service. When registering for the UP42 newsletter, we ask you to provide your email address so that we can send you the newsletter. For newsletter subscriptions we use the so-called double opt-in procedure, which means that we will only send you UP42 newsletters by email if you click on a link in our notification email to confirm that you are the owner of the email address provided. If you confirm your email address, we will store your email address, the time of registration and the IP address you used when registering until you unsubscribe from the newsletter. The sole purpose of storing this data is to be able to send you the newsletter and prove that you registered. You can unsubscribe from the UP42 newsletter at any time. A corresponding unsubscribe link can be found in every newsletter. It is of course also sufficient if you notify us using the contact details provided above or in the newsletter (e.g. by email or letter). The legal basis of the above processing is your consent pursuant to Art. 6(1)(a) GDPR. Mailchimp To provide you with the Newsletter we use Mailchimp. Mailchimp is a service by The Rocket Science Group LLC, 675 Ponce de Leon Ave NE, Atlanta, GA 30308, USA to send and manage E-Mail campaigns and Newsletters. For that purpose, your E-Mail-Address will be forwarded to Mailchimp. As Mailchimp operates from the United States, your personal data may be transferred to the United States. To ensure that your data is handled in Accordance with the GDPR, Mailchimp participates in the EU-U.S. Privacy Shield . For more information about data privacy at Mailchimp, please visit the Mailchimp Privacy Policy .","title":"2.   DATA PROCESSING WHEN YOU USE OUR WEBSITE"},{"location":"privacy-policy/#3-cookies-marketing-and-analytics-tools","text":"3.1. Do Not Track Policy . Some web browsers have a \u201cDo Not Track\u201d feature. This feature lets you tell websites you visit that you do not want to have your online activity tracked. These features are not yet uniform across browsers. Our sites are not currently set up to respond to those signals. You can also decide to change your consent and revoke cookies on our website by clicking the button below. However, if you do not accept cookies, you may not be able to use some portions of our Service. Cookie Settings 3.2. General use of cookies. When you visit and use our website, we store a variety of cookies. Cookies are small text files stored in your web browser\u2019s memory which contain information that can be used to recognize you when you visit web servers later on. However, this does not mean that we are immediately aware of your identity. Cookies cannot execute any programs or transfer viruses to your computer. The primary purpose of our own cookies is rather to make using our service as time-saving and user-friendly as possible. We use cookies in particular - for load balancing; - to store language settings; - to store form data; - to note that information placed on our website has been displayed to you, so that it will not be displayed again the next time you visit the website. For example, we use so-called session cookies to recognize that you have already visited individual pages on our website. These cookies are deleted 30 minutes after you stop interacting with our website. In addition, to improve usability, we also use temporary cookies that are stored on your device for a specified period of time. If you visit our site again to take advantage of our services, it will automatically recognize that you have already been with us and what inputs and settings you have made, so you do not have to re-enter them. On the other hand, we use cookies to statistically record the use of our website and to evaluate it for the purpose of optimizing our offer. These cookies allow us to automatically recognize when you visit our site again that you have already been with us. We also use cookies for marketing purposes. These cookies store behavioral information about users obtained through the observance of their browsing habits, which allows a specific profile to be defined in order to show advertising on the basis of such profile. These cookies are automatically deleted after 14 months. We do this to be able to make your use of our website more convenient and personalized. The processing of the respective cookies is based on our aforementioned legitimate interests, meaning the legal basis is Art. 6(1) (f) GDPR. You can prevent the storage of cookies by adjusting your browser settings to disable the acceptance of cookies via this website. If you do not accept cookies, however, this may in some cases lead to considerable functional restrictions on our website. 3.3. Cookies and other technologies from third-party providers. In addition, we also use cookies and technologies from third-party providers for analysis and marketing purposes as part of the statistical recording and analysis of general usage behaviour based on access data as well as collected basic device information (e.g. browser type / version, used operating system) and the collected IP address of our website visitors. We use the results of such analyses to improve our website and services and adapt them to the actual needs of our users as well as for marketing reasons. The legal basis for the individual examples of data processing described below is your consent as in Art. 6 (1) a GDPR. You have the right to withdrawal your consent at any time. To do so, please go to the privacy settings: Privacy Settings 0. OneTrust. For the purpose of cookie- and consent-management, we use the tool OneTrust, a service provided by OneTrust, LLC, 1200 Abernathy Rd NE, Building 600, Atlanta, GA, USA and Dixon House, 1 Lloyd\u2018s Avenue, London EC3N 3DQ, United Kingdom (hereafter: OneTrust). OneTrust is used to provide you with the cookie-banner when visiting our homepage and to store and manage the consent options you decided on in regards to the use of cookies. To do so, OneTrust implements a cookie of its own on your device and receives data including your IP-Address and your chosen settings to provide its services. Legal basis for our use of OneTrust is our legitimate interest in providing a functional and legally certain service on our website, Art. 6 (1) f GDPR. You can object to that use at any time (see section \u201eyour rights\u201c) or change your browser settings to not accept JavaScript to prevent the use of the OneTrust-cookie. If set, the cookie will be deleted after one-year-period. If OneTrust transmits data to the United States in order to provide its services, an appropriate level of data privacy is secured as OneTrust is certified under the EU-U.S.-Privacy-Shield . For more information on data privacy at OneTrust, please visit the privacy notice . a. Google Analytics. Our website uses the web analytics service Google Analytics, provided by Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Ireland (\"Google\") for users from the European Economic Area, Switzerland and Liechtenstein and by Google LLC, 1600 Amphitheatre Parkway Mountain View, CA 94043, USA for all other users. Google Analytics uses cookies with a validity of 14 months to record your access data when you visit our website. On our behalf, Google combines the access data into pseudonymous user profiles and transmits it to a Google server in the USA. Your IP address is anonymised beforehand. We are therefore unable to determine which user profiles belong to a particular user. This means that we cannot identify you or determine how you use our website based on the information collected by Google. In cases where this involves transferring personal data to the USA, Google has also subjected itself to the EU-US Privacy Shield . Google has thus committed itself to ensuring the European data protection principles and level of data protection even in the context of data processing performed in the USA. On our behalf, Google uses the information generated by cookies for the purpose of evaluating the usage of our website, compiling reports on website activity, and providing us with other services relating to website usage and internet usage. For further information, please refer to the Google Analytics privacy policy. You may object to these web analytics activities by Google at any time. There are several ways to do this: You can configure your browser to block cookies from Google Analytics. You can adjust your advertising settings on Google: Google Ads Settings In the browsers Firefox, Internet Explorer and Chrome, you can install the deactivation plug-in provided by Google using the following link (this option does not work on mobile devices): Browser-Add-on For further information about Google Analytics, please refer to Google\u2019s privacy policy. b. Hotjar. We use Hotjar, a web analytics service from Hotjar Ltd., for the purpose of continuously improving our website and services. Hotjar Ltd. is headquartered in Julians Business Centre, 3, Elia Zammit Street, St Julians STJ 1000, Malta, Europe. Hotjar allows us to track mouse movements, mouse clicks and scroll movements while a visitor is active on our homepage. The user behaviour is reported in an aggregated format in so-called heatmaps. Furthermore, technical data such as browser type, language preferences, operating system and screen resolution, Incoming and outgoing links, geographic origin and your location (country only) are captured and evaluated for statistical purposes as well as to analyse how you visited our website. This information will only be processed under a pseudonym and will not be passed on to third parties by us or Hotjar. Personal data entered in forms on our website will be hidden and not collected by Hotjar. Additionally, users have the possibility to provide direct feedback (the feedback pane) through a plug-in offered by Hotjar which helps us improving our product offering. For more information refer to Hotjar's privacy policy . You may prevent Hotjar from collecting the above mentioned data on all websites operated by us or other providers that use Hotjar by opting out here . c. Google Ads. Our website uses \u201cGoogle Ads\u201d, a marketing service provided by Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Ireland (\"Google\"), to advertise our services within Google Search and the Google Search Network following your visit to our website. The service uses cookies and similar technologies for this purpose. For evaluation purposes, Google may transfer the data generated in this context to a Google-server in the USA and store it there. In the event that personal data is transferred to the USA, Google has subjected itself to the EU-US Privacy Shield . Google has thus committed itself to ensuring the European data protection principles and level of data protection even in the context of data processing occurring in the USA. If you use a Google Account, depending on the settings in your Google Account, Google can link your web and app browsing history to your Google Account and use information from your Google Account to show you personalised ads. If you do not want this information to be associated with your Google Account, you must log out of Google before visiting our website. You can configure your browser to reject cookies as described above. You can also disable the \u201cAds Personalisation\u201d button in your Google Ads Settings . In this case, Google will then only display general advertising which has not been selected based on information collected about you. Please refer to Google\u2019s Privacy Policy for further details. d. Bing Ads. Our website uses Bing Ads, a service of Microsoft Corporation, One Microsoft Way, Redmond, WA 98052-6399, USA (\u201cMicrosoft\u201d). Microsoft uses cookies and similar technologies to present you with advertisements which you may find relevant. The use of these technologies enables Microsoft and its partner websites to insert advertisements on the basis of previous visits to our or other websites on the internet. e. LinkedIn. We use the LinkedIn conversion tracking retargeting tool for marketing purposes, provided by LinkedIn Ireland, Wilton Plaza, Wilton Place, Dublin 2, Ireland (\u201cLinkedIn\u201d). A LinkedIn Insight Tag is integrated into our website, which enables LinkedIn to collect pseudonymous data about your visit and the use of our website and to provide us with corresponding aggregated statistics on this basis. In addition, this information is used to show you interest-based and relevant offers and recommendations after you have shown an interest in certain information and e.g. job vacancies on our website. This information is assigned via a cookie. You can prevent the storage of cookies by adjusting your browser settings. Alternatively, you can object to this form of data processing by using the following link to place an opt-out cookie, which will remain on your device until you delete the cookie. This option is available to both LinkedIn members and non-members. For further information, please refer to the LinkedIn privacy policy . f. Facebook conversion and retargeting tags. For marketing purposes our website uses what are known as conversion and retargeting tags (also called Facebook Pixels) from the social network Facebook, a service of Facebook, Inc., 1601 Willow Road, Menlo Park, California 94025, USA (\u201cFacebook\u201d). We use Facebook Pixels to analyze the general use of our website and to track the effectiveness of Facebook advertising (\u201cconversion\u201d). We may also use Facebook Pixels to show you individualized advertising messages based on your interest in our website and our services (\u201cretargeting\u201d). For this purpose, Facebook processes data that the service collects via cookies and similar technologies on our website. Facebook may transfer the data generated in this context to a server in the USA for evaluation and store it there. In exceptional cases where this involves transferring personal data to the USA, Facebook has also subjected itself to the EU-US Privacy Shield . Facebook has thus committed itself to ensuring the European data protection principles and level of data protection even in the context of data processing performed in the USA. If you are member of Facebook and have given Facebook the relevant permission in your account\u2019s privacy settings, Facebook may also link the information recorded about your visit to us to your member account and use it to deploy targeted Facebook ads. You can view and change the privacy settings of your Facebook profile at any time. If you are not a member of Facebook, you can prevent Facebook from processing your data by clicking on the deactivation button for the provider \u201cFacebook\u201d on the external TrustArc opt-out website. Alternatively, you can disable the Facebook Pixel on the Digital Advertising Alliance page at the following Link: here . If you disable data processing by Facebook, Facebook will only display general Facebook ads that are not selected based on information recorded about you. Please refer to Facebook\u2019s data policy for further details. g. Twitter Ads. On our website we use services of the short message service Twitter, Twitter International Company, One Cumberland Place, Fenian Street Dublin 2, D02 AX07 Ireland (\u201cTwitter\u201d). Twitter enables us to use visitor interaction pixels to deploy target group-based advertising, retargeting and conversion measurements for online advertising. This involves deploying offers for certain target groups based on a selection of general criteria, e.g. demographic characteristics, regions or interests. Twitter also allows us to display targeted ads based on a user\u2019s previous page views. For example, ads about our services can be shown to the respective user if that user has previously been interested in certain information or offers on our website. Twitter is certified under the EU-US Privacy Shield and is thus committed to complying with European data protection regulations. You can prevent this data processing by disabling the storage of cookies in your browser by adjusting the settings as described above. If you are a Twitter user, you can also prevent the aforementioned data processing in your Twitter account by adjusting the \u201cPersonalized ads\u201d setting in the \u201cPersonalization and Data\u201d area. On mobile devices, the aforementioned data processing can also be prevented using the system settings \u201cLimit Ad Tracking\u201d (iOS) or \u201cInterest-based ads\u201d (Android). For further information, please refer to the Twitter website . h. Google Tag Manager. Our website uses Google Tag Manager, a service provided by Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Ireland (\"Google\"). Google Tag Manager serves to manage tools for usage data analyses and other services, so-called website tags. A tag is an element that is stored in the source code of our website in order to record, for example, predefined uses and interactions. Google Tag Manager does not use cookies. Google Tag Manager enables us to integrate partners in the context of online advertising. If you opted-out of the processing for the other tools and third-party services described in this section, no data will be processed by Google Tag Manager. In some cases, the data is processed on a Google server in the USA. In exceptional cases where this involves transferring personal data to the USA, Google has also subjected itself to the EU-US Privacy Shield . Google has thus committed itself to ensuring the European data protection principles and level of data protection even in the context of data processing performed in the USA. For more details, please refer to the information provided by Google about Google Tag Manager . 3.4. Commercial E-Mails. We may send you commercial e-mail with business information or offers, if we have the right to do so. This right can arise from your consent or from the contractual relationship you have with us. The legal base for such mailing would then either be Art. 6 (1) (a) or Art. 6 (1) (b) GDPR. SendGrid To send the above-mentioned commercial e-mails we use SendGrid. SendGrid is a service by SendGrid, Inc., 1801 California Street, Suite 500, Denver, CO 80202, USA (\u201c SendGrid \u201d). We use SendGrid to provide you with the mentioned business information and offers. To conduct that service, SendGrid processes your personal data, such as your contact information or content of your e-mail communication with us. SendGrid will only do so on our behalf and on the base of a contractual relationship with us in accordance to the GDPR. If SendGrid processes your data on server in the United States, SendGrid guarantees, that such data processing is done in accordance with the GDPR. SendGrid has subjected itself under the EU-U.S. Privacy Shield . If you want more information about the data processing and data privacy at SendGrid, please visit SendGrid\u2019s data privacy policy . 1. Hosting a. Github Parts of this website are hosted on Servers of GitHub Inc., 88 Colin P Kelly Jr. St, San Francisco, CA 94107, USA (\u201cGitHub\u201d). If you use those pages, GitHub can have access to your technical information such as your ID-Address. All data processing by GitHub on behalf of UP42 is subject to legal binding contracts in accordance with the GDPR. More information on data privacy on GitHub can be found on the GitHub Privacy Policy ./","title":"3.   COOKIES, MARKETING AND ANALYTICS TOOLS"},{"location":"privacy-policy/#4-links-to-other-websites-and-online-content","text":"Our website may contain links to websites and online content of other providers not affiliated with us. If you activate these links, we naturally no longer have any influence on which data is collected by the respective providers and which data they record. For more detailed information on data collection and use, please refer to the privacy policies of the respective providers. Since the collection and processing of data by third parties is beyond our control, we cannot assume any responsibility for this.","title":"4.   LINKS TO OTHER WEBSITES AND ONLINE CONTENT"},{"location":"privacy-policy/#5-our-social-media-profiles","text":"5.1. Social media Profiles. We are represented in various social networks. - Facebook (Facebook Inc., 1601 Willow Road Menlo Park, CA 94025, USA), Privacy Policy - Twitter (Twitter, Inc., 1355 Market Street Suite 900 San Francisco, CA 94103, USA), Privacy Policy - Instagram (Instagram Inc., 181 South Park Street Suite 2 San Francisco, CA 94107, USA), Privacy Policy - LinkedIn (LinkedIn Corporation, 2029 Stierlin Court Mountain View, CA 94043, USA), Privacy Policy - Medium (A Medium Corporation, 760 Medium Street San Francisco, CA 94102, USA), Privacy Policy - On our website we link to our company profiles on the respective social networks. Please note, that when you activate a link to a social network, data is transferred to servers of the respective provider. If you are logged in to the respective social network at that moment with your username and password, the information that you are visiting our website will be transferred to the social network and the respective provider may assign this information to your user account. Basically, we have no way of influencing the data processing regarding the social networks. But we do receive statistics about usage and visits of our company profiles on the social networks (e.g., information about the number of views, interactions such as likes, comments and reteweets, and aggregated demographic and other information or statistics). For this purpose, we submit certain parameters regarding our company and the services and content we offer on our company profile to the social network specific. This information is used by the providers to create more detailed statistics. In addition, the providers may use data they collect when you visit the social network for their own purposes beyond our control. For more detailed information, please refer to the providers' privacy notice linked above. If we receive your personal data via our social media profiles (e.g. via direct messages), you are entitled to the rights set out in this privacy policy (see section 11 \"Your rights\"). You can send us your inquiries to gain access to stored personal data with regard to data processing in the context of our company profiles using contact data specified in section 1. We will then inform you about the data we have collected on our own and data which was transmitted to us to comply with the rights you have exercised against us. If you also intend to assert rights against the social network provider, the easiest way to do so is to directly contact the respective provider. The provider knows the details on the technical operation of the platform and the associated data processing as well as the concrete purposes of data processing and can put appropriate measures into practice to comply with your inquiry. The contact details can be found in the privacy notice linked above. We gladly support you in asserting your rights to the extent of our competence. The legal basis for linking and operating our company social media profiles is Art. 6(1) (f) GDPR based on our legitimate interest in our corporate communications in the respective social networks. 5.2. Implementation of Videos with Wistia. We use the option to implement videos on our Website. For this implementation, we use Wistia, a service by Wistia, Inc., 17 Tudor Street, Cambridge, MA 02139, USA (\u201c Wistia \u201d). When interacting with the videos, your personal data such as your IP-Address,\u201dcookie\u201d information and your requested page are processed by Wistia. The legal base for our use of Wistia is our legitimate interest in using Videos for our Website, in accordance to Art. 6 (1) (b) GDPR. Through Wistia, your data can be processed on servers in the United States. If this is done, Wistia guarantees to do such data processing in accordance with the GDPR. Wistia has subjected itself to the EU-U.S. Privacy Shield . You can configurate your browser as stated above to prohibit the use of cookies. For more information about the data processing and data privacy and Wistia and how to opt-out from the data processing, please visit the Wistia Privacy Policy .","title":"5.   OUR SOCIAL MEDIA PROFILES"},{"location":"privacy-policy/#6-disclosure-of-data","text":"In principle, we will only pass on the data we collect if: - you have given your explicit consent pursuant to Art. 6(1) (a) GDPR; - disclosure is necessary pursuant to Art. 6(1) (f) GDPR in order to establish, exercise or defend legal claims and there is no reason to assume that you have an overriding legitimate interest in your data not being disclosed; - we are legally obliged to do so under Art. 6(1) \u00a9 GDPR; or - this is permitted by law and is required under Art. 6(1) (b) GDPR for the processing of contractual relationships with you or for taking steps at your request prior to entering into a contract. Part of the data processing may be carried out by our service providers. In addition to the service providers mentioned in this privacy policy, this may in particular include data centres that store our website and databases, IT service providers that maintain our systems or provide CRM functionalities and consulting firms. If we pass data on to our service providers, they may use the data exclusively for the fulfilment of their tasks. We have carefully selected and commissioned the service providers. They are contractually bound by our instructions, have appropriate technical and organisational measures in place to protect the rights of data subjects and are carefully monitored by us. In addition, data may be disclosed in connection with official requests, court orders and legal proceedings if this is necessary to pursue or enforce rights.","title":"6.   DISCLOSURE OF DATA"},{"location":"privacy-policy/#7-security","text":"The security of your personal information important to us. We take a number of organizational, technical and physical measures designed to protect the personal information we collect, both during transmission and once we receive it. Our security is subject to constant improvement and our privacy policies are constantly being revised. Please make sure you have the latest version.","title":"7.   SECURITY"},{"location":"privacy-policy/#8-personal-data-retention","text":"We store personal data only as long as we are entitled to do so, and the processing purpose is not eliminated and there was no objection. For the duration of storage of personal data, the respective statutory retention period applies. After the deadline, the corresponding data will be routinely deleted, if they are no longer required to fulfill the contract or to initiate a contract.","title":"8.   PERSONAL DATA RETENTION"},{"location":"privacy-policy/#9-third-country-transfer","text":"The above agreements may result in your personal information being stored and processed in countries outside the European Union. As data protection laws in third countries differ from those in the EEA, we have taken measures to ensure an adequate level of privacy and data protection outside the EEA. This includes the contractual agreement, by EU standard contractual clauses to ensure and comply with the data protection principles of the European Commission. Please contact us if you would like to request a copy of the safeguards that guarantee an adequate level of data protection.","title":"9.   THIRD COUNTRY TRANSFER"},{"location":"privacy-policy/#10-your-rights","text":"You have the right to information about how we process your personal data at any time. When providing this information, we will explain the data processing to you and provide you with an overview of the data stored about you. If data stored by us is incorrect or no longer up to date, you have the right to have this data corrected. You may also demand that your data be erased. Should the erasure not be possible in exceptional cases due to other legal regulations, the data will be blocked so that it is only available for that legal purpose. You are also entitled to have the processing of your data restricted, e.g. if you believe that the data we have stored is incorrect. You also have the right to data portability, which means that on request we will send you a digital copy of the personal data you have provided on the basis of consent or a contractual relationship. In order to assert your rights described here, you can contact us at any time using the contact details provided in Section 1 above. In addition, you have the right to object to data processing if it is based on Art. 6(1)(e) or (f) GDPR or for marketing purposes. Finally, you have the right to lodge a complaint with our competent data protection supervisory authority. You can assert this right by contacting a supervisory authority in the Member State of your habitual residence, your place of work or the place of the alleged infringement. The supervisory authority in Berlin is: Berlin Commissioner for Data Protection and Freedom of Information, Friedrichstr. 219, 10969 Berlin. Right of withdrawal and objection. Pursuant to Art. 7(3) GDPR, you have the right to withdraw the consent you gave us at any time. As a result of this, we will cease the data processing based on this consent with future effect. This withdrawal of your consent will not affect the lawfulness of the processing carried out on the basis of the consent prior to the withdrawal. If we process your data on the basis of legitimate interests pursuant to Art. 6(1)(f) GDPR, you have the right under Art. 21 GDPR to object to the processing of your data, and to give us reasons which arise from your particular situation which, in your opinion, show that your legitimate interests override ours. If your objection is to data processing for direct marketing purposes, you have a general right of objection, which we will implement without requiring you to give reasons. If you would like to make use of your right of withdrawal or objection, it is sufficient to simply notify us using the contact details provided above.","title":"10.  YOUR RIGHTS"},{"location":"privacy-policy/#11-updates-to-this-privacy-policy","text":"This privacy policy is currently valid. As a result of the further development of our website and offers thereof or due to changed legal or official requirements, it may be necessary to change this privacy policy. The current privacy policy can be viewed and printed by you at any time on the website at up42.com/legal/privacy-policy.","title":"11.  UPDATES TO THIS PRIVACY POLICY"},{"location":"structure/","text":"Structure \u00b6 Hierachy \u00b6 The Python SDK uses seven object classes, representing the hierarchical structure of UP42 : Project > Workflow > Job > JobTask JobCollection Catalog Tools Each object can spawn elements of one level below , e.g. project = up42.initialize_project() workflow = Project().create_workflow() job = workflow.run_job() Functionality \u00b6 An overview of the functionality of each object (also see the code reference ): Available Functionality up42 .initialize_project() .initalize_workflow() .initalize_job() .initalize_jobtask() .initalize_catalog() Project .create_workflow() .get_workflows() .get_jobs() .get_project_settings() .update_project_settings() Workflow .add_workflow_tasks() .construct_parameters() .test_job() .run_job() `.construct_parameters_parallel() .test_jobs_parallel() .run_jobs_parallel() .get_jobs() .get_workflow_tasks() `.get_compatible_blocks() .get_parameters_info() .update_name() .delete() Job .download_results() .plot_results() .map_results() .get_status() .track_status() .cancel_job() .get_results_json() .get_logs() .download_quicklooks() .upload_results_to_bucket() .get_jobtasks() .get_jobtasks_results_json() JobTask .get_results_json() .download_results() .download_quicklooks() JobCollection .download_results() .get_jobs_infos() .get_jobs_status() .apply() Catalog .construct_parameters() .search() .download_quicklooks() Tools .get_blocks() .get_block_details() .read_vector_file() .get_example_aoi() .draw_aoi() .plot_coverage() .plot_quicklooks() .plot_results() .validate_manifest() Object Initialization \u00b6 If a workflow etc. already exists on UP42, you can initialize and access it directly using its id : Initialize Object Project up42 . authenticate ( project_id = \"123\" , project_api_key = \"456\" ) project = up42 . initialize_project () Workflow UP42_WORKFLOW_ID = \"7fb2ec8a-45be-41ad-a50f-98ba6b528b98\" workflow = up42 . initialize_workflow ( workflow_id = UP42_WORKFLOW_ID ) Job UP42_JOB_ID = \"de5806aa-5ef1-4dc9-ab1d-06d7ec1a5021\" job = up42 . initialize_job ( job_id = UP42_JOB_ID ) JobTask UP42_JOBTASK_ID = \"3f772637-09aa-4164-bded-692fcd746d20\" jobtask = up42 . initialize_jobtask ( jobtask_id = UP42_JOBTASK_ID , job_id = UP42_JOB_ID ) Catalog catalog = up42 . initialize_catalog () Tools The tools' functionalities can be accessed from any of the up42 objects, e.g. up42 . get_example_aoi () # workflow.get_example_aoi() # job.get_example_aoi()","title":"Structure"},{"location":"structure/#structure","text":"","title":"Structure"},{"location":"structure/#hierachy","text":"The Python SDK uses seven object classes, representing the hierarchical structure of UP42 : Project > Workflow > Job > JobTask JobCollection Catalog Tools Each object can spawn elements of one level below , e.g. project = up42.initialize_project() workflow = Project().create_workflow() job = workflow.run_job()","title":"Hierachy"},{"location":"structure/#functionality","text":"An overview of the functionality of each object (also see the code reference ): Available Functionality up42 .initialize_project() .initalize_workflow() .initalize_job() .initalize_jobtask() .initalize_catalog() Project .create_workflow() .get_workflows() .get_jobs() .get_project_settings() .update_project_settings() Workflow .add_workflow_tasks() .construct_parameters() .test_job() .run_job() `.construct_parameters_parallel() .test_jobs_parallel() .run_jobs_parallel() .get_jobs() .get_workflow_tasks() `.get_compatible_blocks() .get_parameters_info() .update_name() .delete() Job .download_results() .plot_results() .map_results() .get_status() .track_status() .cancel_job() .get_results_json() .get_logs() .download_quicklooks() .upload_results_to_bucket() .get_jobtasks() .get_jobtasks_results_json() JobTask .get_results_json() .download_results() .download_quicklooks() JobCollection .download_results() .get_jobs_infos() .get_jobs_status() .apply() Catalog .construct_parameters() .search() .download_quicklooks() Tools .get_blocks() .get_block_details() .read_vector_file() .get_example_aoi() .draw_aoi() .plot_coverage() .plot_quicklooks() .plot_results() .validate_manifest()","title":"Functionality"},{"location":"structure/#object-initialization","text":"If a workflow etc. already exists on UP42, you can initialize and access it directly using its id : Initialize Object Project up42 . authenticate ( project_id = \"123\" , project_api_key = \"456\" ) project = up42 . initialize_project () Workflow UP42_WORKFLOW_ID = \"7fb2ec8a-45be-41ad-a50f-98ba6b528b98\" workflow = up42 . initialize_workflow ( workflow_id = UP42_WORKFLOW_ID ) Job UP42_JOB_ID = \"de5806aa-5ef1-4dc9-ab1d-06d7ec1a5021\" job = up42 . initialize_job ( job_id = UP42_JOB_ID ) JobTask UP42_JOBTASK_ID = \"3f772637-09aa-4164-bded-692fcd746d20\" jobtask = up42 . initialize_jobtask ( jobtask_id = UP42_JOBTASK_ID , job_id = UP42_JOB_ID ) Catalog catalog = up42 . initialize_catalog () Tools The tools' functionalities can be accessed from any of the up42 objects, e.g. up42 . get_example_aoi () # workflow.get_example_aoi() # job.get_example_aoi()","title":"Object Initialization"},{"location":"support-faq/","text":"Support & FAQ \u00b6 Contact \u00b6 Please contact us via Email support@up42.com or open a github issue . Related links \u00b6 UP42 Website UP42 Python SDK Repository UP42 Github Repositories UP42 Documentation UP42 blockutils - Developer tools to easily create custom UP42 data & processing blocks UP42 mosaicking - Scripts to create image mosaics using UP42 FAQ \u00b6 Can I contribute to the SDK? \u00b6 Yes, contributions and bug fixes are very welcome. Please see the developer readme for further instructions.","title":"FAQ & Support"},{"location":"support-faq/#support-faq","text":"","title":"Support &amp; FAQ"},{"location":"support-faq/#contact","text":"Please contact us via Email support@up42.com or open a github issue .","title":"Contact"},{"location":"support-faq/#related-links","text":"UP42 Website UP42 Python SDK Repository UP42 Github Repositories UP42 Documentation UP42 blockutils - Developer tools to easily create custom UP42 data & processing blocks UP42 mosaicking - Scripts to create image mosaics using UP42","title":"Related links"},{"location":"support-faq/#faq","text":"","title":"FAQ"},{"location":"support-faq/#can-i-contribute-to-the-sdk","text":"Yes, contributions and bug fixes are very welcome. Please see the developer readme for further instructions.","title":"Can I contribute to the SDK?"},{"location":"examples/airports-parallel/","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } pre { line-height: 125%; margin: 0; } td.linenos pre { color: #000000; background-color: #f0f0f0; padding: 0 5px 0 5px; } span.linenos { color: #000000; background-color: #f0f0f0; padding: 0 5px 0 5px; } td.linenos pre.special { color: #000000; background-color: #ffffc0; padding: 0 5px 0 5px; } span.linenos.special { color: #000000; background-color: #ffffc0; padding: 0 5px 0 5px; } .highlight-ipynb .hll { background-color: #ffffcc } .highlight-ipynb { background: #f8f8f8; } .highlight-ipynb .c { color: #408080; font-style: italic } /* Comment */ .highlight-ipynb .err { border: 1px solid #FF0000 } /* Error */ .highlight-ipynb .k { color: #008000; font-weight: bold } /* Keyword */ .highlight-ipynb .o { color: #666666 } /* Operator */ .highlight-ipynb .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight-ipynb .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight-ipynb .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight-ipynb .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight-ipynb .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight-ipynb .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight-ipynb .gd { color: #A00000 } /* Generic.Deleted */ .highlight-ipynb .ge { font-style: italic } /* Generic.Emph */ .highlight-ipynb .gr { color: #FF0000 } /* Generic.Error */ .highlight-ipynb .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight-ipynb .gi { color: #00A000 } /* Generic.Inserted */ .highlight-ipynb .go { color: #888888 } /* Generic.Output */ .highlight-ipynb .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight-ipynb .gs { font-weight: bold } /* Generic.Strong */ .highlight-ipynb .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight-ipynb .gt { color: #0044DD } /* Generic.Traceback */ .highlight-ipynb .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight-ipynb .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight-ipynb .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight-ipynb .kp { color: #008000 } /* Keyword.Pseudo */ .highlight-ipynb .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight-ipynb .kt { color: #B00040 } /* Keyword.Type */ .highlight-ipynb .m { color: #666666 } /* Literal.Number */ .highlight-ipynb .s { color: #BA2121 } /* Literal.String */ .highlight-ipynb .na { color: #7D9029 } /* Name.Attribute */ .highlight-ipynb .nb { color: #008000 } /* Name.Builtin */ .highlight-ipynb .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight-ipynb .no { color: #880000 } /* Name.Constant */ .highlight-ipynb .nd { color: #AA22FF } /* Name.Decorator */ .highlight-ipynb .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight-ipynb .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight-ipynb .nf { color: #0000FF } /* Name.Function */ .highlight-ipynb .nl { color: #A0A000 } /* Name.Label */ .highlight-ipynb .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight-ipynb .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight-ipynb .nv { color: #19177C } /* Name.Variable */ .highlight-ipynb .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight-ipynb .w { color: #bbbbbb } /* Text.Whitespace */ .highlight-ipynb .mb { color: #666666 } /* Literal.Number.Bin */ .highlight-ipynb .mf { color: #666666 } /* Literal.Number.Float */ .highlight-ipynb .mh { color: #666666 } /* Literal.Number.Hex */ .highlight-ipynb .mi { color: #666666 } /* Literal.Number.Integer */ .highlight-ipynb .mo { color: #666666 } /* Literal.Number.Oct */ .highlight-ipynb .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight-ipynb .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight-ipynb .sc { color: #BA2121 } /* Literal.String.Char */ .highlight-ipynb .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight-ipynb .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight-ipynb .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight-ipynb .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight-ipynb .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight-ipynb .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight-ipynb .sx { color: #008000 } /* Literal.String.Other */ .highlight-ipynb .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight-ipynb .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight-ipynb .ss { color: #19177C } /* Literal.String.Symbol */ .highlight-ipynb .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight-ipynb .fm { color: #0000FF } /* Name.Function.Magic */ .highlight-ipynb .vc { color: #19177C } /* Name.Variable.Class */ .highlight-ipynb .vg { color: #19177C } /* Name.Variable.Global */ .highlight-ipynb .vi { color: #19177C } /* Name.Variable.Instance */ .highlight-ipynb .vm { color: #19177C } /* Name.Variable.Magic */ .highlight-ipynb .il { color: #666666 } /* Literal.Number.Integer.Long */ .rendered_html a{text-decoration:inherit !important}.rendered_html :link{text-decoration:inherit !important}.rendered_html :visited{text-decoration:inherit !important}pre code{background-color:inherit !important}.highlight{color:#000000}.highlight code{color:#000000}.highlight .n{color:#333333}.highlight .p{color:#000000}.text_cell .prompt{display:none !important}div.input_prompt{padding:0.2em 0.4em}div.output_prompt{padding:0.4em}.text_cell{margin:0 !important;padding:0 !important;border:none !important}.text_cell_render{margin:0 !important;padding:0 !important;border:none !important}.rendered_html *+p{margin-top:inherit !important}.anchor-link{display:none !important}.code_cell{margin:0 !important;padding:5px 0 !important;border:none !important}.celltoolbar{border:thin solid #CFCFCF;border-bottom:none;background:#EEE;border-radius:2px 2px 0px 0px;width:100%;height:29px;padding-right:4px;box-orient:horizontal;box-align:stretch;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;box-pack:end;-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;display:-webkit-flex}.celltoolbar .tags_button_container{display:-webkit-box;display:-ms-flexbox;display:flex}.celltoolbar .tags_button_container .tag-container{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;overflow:hidden;position:relative}.celltoolbar .tags_button_container .tag-container .cell-tag{background-color:#fff;white-space:nowrap;margin:3px 4px;padding:0 4px;border-radius:1px;border:1px solid #ccc;-webkit-box-shadow:none;box-shadow:none;width:inherit;font-size:13px;font-family:\"Helvetica Neue\", Helvetica, Arial, sans-serif;height:22px;line-height:22px;display:inline-block}div.input_area>div.highlight{margin:0.25em 0.4em !important}.code_cell pre{font-size:12px !important}.output_html table.dataframe{font-family:Arial, sans-serif;font-size:13px;line-height:20px}.output_html table.dataframe th,td{padding:4px;text-align:left}.bk-plot-wrapper tbody tr{background:none !important}.bk-plot-wrapper tbody tr:hover{background:none !important} /*# sourceMappingURL=jupyter-fixes.min.css.map */ MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ], displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ], processEscapes: true, processEnvironments: true }, // Center justify equations in code and markdown cells. Elsewhere // we use CSS to left justify single line equations in code cells. displayAlign: 'center', \"HTML-CSS\": { styles: {'.MathJax_Display': {\"margin\": 0}}, linebreaks: { automatic: true } } }); Parallel Jobs \u00b6 Example: Airport monitoring \u00b6 Get a Sentinel-2 clipped image for 10 airports in a country. Run all jobs in parallel Visualize the results In [1]: import up42 import pandas as pd import geopandas as gpd from pathlib import Path Random airports in Spain \u00b6 Airport locations scrapped from: https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat In [2]: country = \"Spain\" dat = \"https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat\" airports = pd . read_table ( dat , sep = \",\" , usecols = [ 0 , 1 , 3 , 6 , 7 ], names = [ \"uid\" , 'airport' , \"country\" , \"lat\" , \"lon\" ]) airports = airports [ airports . country == country ] airports = gpd . GeoDataFrame ( airports , geometry = gpd . points_from_xy ( airports . lon , airports . lat )) world = gpd . read_file ( gpd . datasets . get_path ( 'naturalearth_lowres' )) world = world [ world . name == country ] airports = airports [ airports . within ( world . iloc [ 0 ] . geometry )] display ( airports . head ()) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } uid airport country lat lon geometry 1180 1211 Albacete-Los Llanos Airport Spain 38.948502 -1.863520 POINT (-1.86352 38.94850) 1181 1212 Alicante International Airport Spain 38.282200 -0.558156 POINT (-0.55816 38.28220) 1182 1213 Almer\u00eda International Airport Spain 36.843899 -2.370100 POINT (-2.37010 36.84390) 1183 1214 Asturias Airport Spain 43.563599 -6.034620 POINT (-6.03462 43.56360) 1184 1215 C\u00f3rdoba Airport Spain 37.841999 -4.848880 POINT (-4.84888 37.84200) In [3]: airports = airports . sample ( 6 ) In [4]: # Visualize locations ax = world . plot ( figsize = ( 10 , 10 ), color = 'white' , edgecolor = 'black' ) airports . plot ( markersize = 20 , ax = ax , color = \"r\" ) Out[4]: <AxesSubplot:> In [5]: # Buffer airport point locations by roughly 100m airports . geometry = airports . geometry . buffer ( 0.001 ) Prepare UP42 workflows \u00b6 Create a new project on UP42 or use an existing one. In [6]: # Authenticate with UP42 up42 . authenticate ( project_id = \"12345\" , project_api_key = \"6889\" ) #up42.authenticate(cfg_file=\"config.json\") project = up42 . initialize_project () 2020-08-07 10:04:37,852 - up42.auth - INFO - Authentication with UP42 successful! 2020-08-07 10:04:37,853 - up42 - INFO - Working on Project with project_id 75d25f7a-426d-495f-8cfa-e54a57d2da74 In [7]: # Increase the parallel job limit for the project. # Only works when you have added your credit card information to the UP42 account. project . update_project_settings ( max_concurrent_jobs = 10 ) 2020-08-07 10:04:39,248 - up42.project - INFO - Updated project settings: [{'name': 'JOB_QUERY_MAX_AOI_SIZE', 'value': '100'}, {'name': 'MAX_CONCURRENT_JOBS', 'value': '10'}, {'name': 'JOB_QUERY_LIMIT_PARAMETER_MAX_VALUE', 'value': '10'}] In [8]: workflow = project . create_workflow ( \"workflow_airports\" , use_existing = True ) 2020-08-07 10:04:39,255 - up42.project - INFO - Getting existing workflows in project ... 2020-08-07 10:04:39,627 - up42.project - INFO - Got 3 workflows for project 75d25f7a-426d-495f-8cfa-e54a57d2da74. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:01<00:00, 2.73it/s] 2020-08-07 10:04:40,749 - up42.project - INFO - Using existing workflow: workflow_airports - 4022cf7c-fa26-4dd4-a2c6-b37583cacc27 In [9]: # Fill the workflow with tasks #blocks = up42.get_blocks(basic=True) selected_block = \"sobloo-s2-l1c-aoiclipped\" workflow . add_workflow_tasks ([ selected_block ]) workflow . get_workflow_tasks ( basic = True ) 2020-08-07 10:04:42,249 - up42.workflow - INFO - Added tasks to workflow: [{'name': 'sobloo-s2-l1c-aoiclipped:1', 'parentName': None, 'blockId': 'a2daaab4-196d-4226-a018-a810444dcad1'}] 2020-08-07 10:04:42,697 - up42.workflow - INFO - Got 1 tasks/blocks in workflow 4022cf7c-fa26-4dd4-a2c6-b37583cacc27. Out[9]: {'sobloo-s2-l1c-aoiclipped:1': '10b80b0d-9b99-4a2d-b5a4-2cbd8331cc0d'} Run jobs in parallel \u00b6 Queries & downloads one image per airport in parallel. Crude, this will soon be available in the API in one simple command! In [10]: # Run jobs in parallel up42 . settings ( log = False ) input_parameters_list = workflow . construct_parameters_parallel ( geometries = airports . geometry . to_list (), interval_dates = [( \"2018-01-01\" , \"2020-12-31\" )], geometry_operation = \"bbox\" ) # Adjust cloud cover parameter for params in input_parameters_list : params [ f \" { selected_block } :1\" ][ \"max_cloud_cover\" ] = 10 2020-08-07 10:04:42,703 - up42 - INFO - Logging disabled - use up42.settings(log=True) to reactivate. In [11]: real_jobs = workflow . run_jobs_parallel ( input_parameters_list = input_parameters_list ) In [ ]: real_jobs . download_results () In [13]: # Visualize downloaded results real_jobs . plot_results () In [ ]:","title":"Airport monitoring"},{"location":"examples/airports-parallel/#parallel-jobs","text":"","title":"Parallel Jobs"},{"location":"examples/airports-parallel/#example-airport-monitoring","text":"Get a Sentinel-2 clipped image for 10 airports in a country. Run all jobs in parallel Visualize the results In [1]: import up42 import pandas as pd import geopandas as gpd from pathlib import Path","title":"Example: Airport monitoring"},{"location":"examples/airports-parallel/#random-airports-in-spain","text":"Airport locations scrapped from: https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat In [2]: country = \"Spain\" dat = \"https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat\" airports = pd . read_table ( dat , sep = \",\" , usecols = [ 0 , 1 , 3 , 6 , 7 ], names = [ \"uid\" , 'airport' , \"country\" , \"lat\" , \"lon\" ]) airports = airports [ airports . country == country ] airports = gpd . GeoDataFrame ( airports , geometry = gpd . points_from_xy ( airports . lon , airports . lat )) world = gpd . read_file ( gpd . datasets . get_path ( 'naturalearth_lowres' )) world = world [ world . name == country ] airports = airports [ airports . within ( world . iloc [ 0 ] . geometry )] display ( airports . head ()) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } uid airport country lat lon geometry 1180 1211 Albacete-Los Llanos Airport Spain 38.948502 -1.863520 POINT (-1.86352 38.94850) 1181 1212 Alicante International Airport Spain 38.282200 -0.558156 POINT (-0.55816 38.28220) 1182 1213 Almer\u00eda International Airport Spain 36.843899 -2.370100 POINT (-2.37010 36.84390) 1183 1214 Asturias Airport Spain 43.563599 -6.034620 POINT (-6.03462 43.56360) 1184 1215 C\u00f3rdoba Airport Spain 37.841999 -4.848880 POINT (-4.84888 37.84200) In [3]: airports = airports . sample ( 6 ) In [4]: # Visualize locations ax = world . plot ( figsize = ( 10 , 10 ), color = 'white' , edgecolor = 'black' ) airports . plot ( markersize = 20 , ax = ax , color = \"r\" ) Out[4]: <AxesSubplot:> In [5]: # Buffer airport point locations by roughly 100m airports . geometry = airports . geometry . buffer ( 0.001 )","title":"Random airports in Spain"},{"location":"examples/airports-parallel/#prepare-up42-workflows","text":"Create a new project on UP42 or use an existing one. In [6]: # Authenticate with UP42 up42 . authenticate ( project_id = \"12345\" , project_api_key = \"6889\" ) #up42.authenticate(cfg_file=\"config.json\") project = up42 . initialize_project () 2020-08-07 10:04:37,852 - up42.auth - INFO - Authentication with UP42 successful! 2020-08-07 10:04:37,853 - up42 - INFO - Working on Project with project_id 75d25f7a-426d-495f-8cfa-e54a57d2da74 In [7]: # Increase the parallel job limit for the project. # Only works when you have added your credit card information to the UP42 account. project . update_project_settings ( max_concurrent_jobs = 10 ) 2020-08-07 10:04:39,248 - up42.project - INFO - Updated project settings: [{'name': 'JOB_QUERY_MAX_AOI_SIZE', 'value': '100'}, {'name': 'MAX_CONCURRENT_JOBS', 'value': '10'}, {'name': 'JOB_QUERY_LIMIT_PARAMETER_MAX_VALUE', 'value': '10'}] In [8]: workflow = project . create_workflow ( \"workflow_airports\" , use_existing = True ) 2020-08-07 10:04:39,255 - up42.project - INFO - Getting existing workflows in project ... 2020-08-07 10:04:39,627 - up42.project - INFO - Got 3 workflows for project 75d25f7a-426d-495f-8cfa-e54a57d2da74. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:01<00:00, 2.73it/s] 2020-08-07 10:04:40,749 - up42.project - INFO - Using existing workflow: workflow_airports - 4022cf7c-fa26-4dd4-a2c6-b37583cacc27 In [9]: # Fill the workflow with tasks #blocks = up42.get_blocks(basic=True) selected_block = \"sobloo-s2-l1c-aoiclipped\" workflow . add_workflow_tasks ([ selected_block ]) workflow . get_workflow_tasks ( basic = True ) 2020-08-07 10:04:42,249 - up42.workflow - INFO - Added tasks to workflow: [{'name': 'sobloo-s2-l1c-aoiclipped:1', 'parentName': None, 'blockId': 'a2daaab4-196d-4226-a018-a810444dcad1'}] 2020-08-07 10:04:42,697 - up42.workflow - INFO - Got 1 tasks/blocks in workflow 4022cf7c-fa26-4dd4-a2c6-b37583cacc27. Out[9]: {'sobloo-s2-l1c-aoiclipped:1': '10b80b0d-9b99-4a2d-b5a4-2cbd8331cc0d'}","title":"Prepare UP42 workflows"},{"location":"examples/airports-parallel/#run-jobs-in-parallel","text":"Queries & downloads one image per airport in parallel. Crude, this will soon be available in the API in one simple command! In [10]: # Run jobs in parallel up42 . settings ( log = False ) input_parameters_list = workflow . construct_parameters_parallel ( geometries = airports . geometry . to_list (), interval_dates = [( \"2018-01-01\" , \"2020-12-31\" )], geometry_operation = \"bbox\" ) # Adjust cloud cover parameter for params in input_parameters_list : params [ f \" { selected_block } :1\" ][ \"max_cloud_cover\" ] = 10 2020-08-07 10:04:42,703 - up42 - INFO - Logging disabled - use up42.settings(log=True) to reactivate. In [11]: real_jobs = workflow . run_jobs_parallel ( input_parameters_list = input_parameters_list ) In [ ]: real_jobs . download_results () In [13]: # Visualize downloaded results real_jobs . plot_results () In [ ]:","title":"Run jobs in parallel"},{"location":"examples/flood_mapping/","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } pre { line-height: 125%; margin: 0; } td.linenos pre { color: #000000; background-color: #f0f0f0; padding: 0 5px 0 5px; } span.linenos { color: #000000; background-color: #f0f0f0; padding: 0 5px 0 5px; } td.linenos pre.special { color: #000000; background-color: #ffffc0; padding: 0 5px 0 5px; } span.linenos.special { color: #000000; background-color: #ffffc0; padding: 0 5px 0 5px; } .highlight-ipynb .hll { background-color: #ffffcc } .highlight-ipynb { background: #f8f8f8; } .highlight-ipynb .c { color: #408080; font-style: italic } /* Comment */ .highlight-ipynb .err { border: 1px solid #FF0000 } /* Error */ .highlight-ipynb .k { color: #008000; font-weight: bold } /* Keyword */ .highlight-ipynb .o { color: #666666 } /* Operator */ .highlight-ipynb .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight-ipynb .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight-ipynb .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight-ipynb .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight-ipynb .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight-ipynb .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight-ipynb .gd { color: #A00000 } /* Generic.Deleted */ .highlight-ipynb .ge { font-style: italic } /* Generic.Emph */ .highlight-ipynb .gr { color: #FF0000 } /* Generic.Error */ .highlight-ipynb .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight-ipynb .gi { color: #00A000 } /* Generic.Inserted */ .highlight-ipynb .go { color: #888888 } /* Generic.Output */ .highlight-ipynb .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight-ipynb .gs { font-weight: bold } /* Generic.Strong */ .highlight-ipynb .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight-ipynb .gt { color: #0044DD } /* Generic.Traceback */ .highlight-ipynb .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight-ipynb .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight-ipynb .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight-ipynb .kp { color: #008000 } /* Keyword.Pseudo */ .highlight-ipynb .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight-ipynb .kt { color: #B00040 } /* Keyword.Type */ .highlight-ipynb .m { color: #666666 } /* Literal.Number */ .highlight-ipynb .s { color: #BA2121 } /* Literal.String */ .highlight-ipynb .na { color: #7D9029 } /* Name.Attribute */ .highlight-ipynb .nb { color: #008000 } /* Name.Builtin */ .highlight-ipynb .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight-ipynb .no { color: #880000 } /* Name.Constant */ .highlight-ipynb .nd { color: #AA22FF } /* Name.Decorator */ .highlight-ipynb .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight-ipynb .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight-ipynb .nf { color: #0000FF } /* Name.Function */ .highlight-ipynb .nl { color: #A0A000 } /* Name.Label */ .highlight-ipynb .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight-ipynb .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight-ipynb .nv { color: #19177C } /* Name.Variable */ .highlight-ipynb .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight-ipynb .w { color: #bbbbbb } /* Text.Whitespace */ .highlight-ipynb .mb { color: #666666 } /* Literal.Number.Bin */ .highlight-ipynb .mf { color: #666666 } /* Literal.Number.Float */ .highlight-ipynb .mh { color: #666666 } /* Literal.Number.Hex */ .highlight-ipynb .mi { color: #666666 } /* Literal.Number.Integer */ .highlight-ipynb .mo { color: #666666 } /* Literal.Number.Oct */ .highlight-ipynb .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight-ipynb .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight-ipynb .sc { color: #BA2121 } /* Literal.String.Char */ .highlight-ipynb .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight-ipynb .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight-ipynb .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight-ipynb .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight-ipynb .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight-ipynb .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight-ipynb .sx { color: #008000 } /* Literal.String.Other */ .highlight-ipynb .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight-ipynb .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight-ipynb .ss { color: #19177C } /* Literal.String.Symbol */ .highlight-ipynb .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight-ipynb .fm { color: #0000FF } /* Name.Function.Magic */ .highlight-ipynb .vc { color: #19177C } /* Name.Variable.Class */ .highlight-ipynb .vg { color: #19177C } /* Name.Variable.Global */ .highlight-ipynb .vi { color: #19177C } /* Name.Variable.Instance */ .highlight-ipynb .vm { color: #19177C } /* Name.Variable.Magic */ .highlight-ipynb .il { color: #666666 } /* Literal.Number.Integer.Long */ .rendered_html a{text-decoration:inherit !important}.rendered_html :link{text-decoration:inherit !important}.rendered_html :visited{text-decoration:inherit !important}pre code{background-color:inherit !important}.highlight{color:#000000}.highlight code{color:#000000}.highlight .n{color:#333333}.highlight .p{color:#000000}.text_cell .prompt{display:none !important}div.input_prompt{padding:0.2em 0.4em}div.output_prompt{padding:0.4em}.text_cell{margin:0 !important;padding:0 !important;border:none !important}.text_cell_render{margin:0 !important;padding:0 !important;border:none !important}.rendered_html *+p{margin-top:inherit !important}.anchor-link{display:none !important}.code_cell{margin:0 !important;padding:5px 0 !important;border:none !important}.celltoolbar{border:thin solid #CFCFCF;border-bottom:none;background:#EEE;border-radius:2px 2px 0px 0px;width:100%;height:29px;padding-right:4px;box-orient:horizontal;box-align:stretch;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;box-pack:end;-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;display:-webkit-flex}.celltoolbar .tags_button_container{display:-webkit-box;display:-ms-flexbox;display:flex}.celltoolbar .tags_button_container .tag-container{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;overflow:hidden;position:relative}.celltoolbar .tags_button_container .tag-container .cell-tag{background-color:#fff;white-space:nowrap;margin:3px 4px;padding:0 4px;border-radius:1px;border:1px solid #ccc;-webkit-box-shadow:none;box-shadow:none;width:inherit;font-size:13px;font-family:\"Helvetica Neue\", Helvetica, Arial, sans-serif;height:22px;line-height:22px;display:inline-block}div.input_area>div.highlight{margin:0.25em 0.4em !important}.code_cell pre{font-size:12px !important}.output_html table.dataframe{font-family:Arial, sans-serif;font-size:13px;line-height:20px}.output_html table.dataframe th,td{padding:4px;text-align:left}.bk-plot-wrapper tbody tr{background:none !important}.bk-plot-wrapper tbody tr:hover{background:none !important} /*# sourceMappingURL=jupyter-fixes.min.css.map */ MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ], displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ], processEscapes: true, processEnvironments: true }, // Center justify equations in code and markdown cells. Elsewhere // we use CSS to left justify single line equations in code cells. displayAlign: 'center', \"HTML-CSS\": { styles: {'.MathJax_Display': {\"margin\": 0}}, linebreaks: { automatic: true } } }); Flood Impact Mapping with UP42 \u00b6 In the following tutorial we will map the impact of the flooding in urban area using UP42 python SDK and OpenStreetMap data. This notebook is intended to show how your existing GIS analysis and workflows can seemlessly be integrated with UP42 Python SDK in a few lines of code. The notebook is divided in following sections: Download Sentinel-2 AOI clipped GeoTiff with Sentinel-2 L1C MSI AOI clipped data block Calculate Modified Normalized Water Index (MNDWI) Convert MNDWI raster mask to vector mask Extract building footprints polygons from OSM using UP42 OSM Data Block Plot the impacted buildings with Folium In [1]: # imports import os from functools import partial import geopandas as gpd import matplotlib.pyplot as plt import numpy as np import pandas as pd import pyproj import rasterio as rio from rasterio import features from rasterio.plot import reshape_as_raster , show from shapely.geometry import LineString , MultiPolygon , Point , Polygon , box from shapely.geometry import shape as shapely_shp from shapely.ops import cascaded_union , transform import folium import up42 In [2]: # allows for ignoring errors + division by zero np . seterr ( divide = 'ignore' , invalid = 'ignore' ) Out[2]: {'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'} Set-up data directory to work with. This is optional though. The SDK creates a directory in the project folder for you! In [3]: sentinel_dir = \"./results/sentinel/\" Download data from UP42 platform \u00b6 In [4]: # authenticate up42 . authenticate ( cfg_file = \"config.json\" ) 2020-07-31 10:39:59,659 - up42.auth - INFO - Got credentials from config file. 2020-07-31 10:39:59,925 - up42.auth - INFO - Authentication with UP42 successful! In [5]: project = up42 . initialize_project () # init workflow workflow = project . create_workflow ( name = \"flooding_sentinel\" ) 2020-07-31 10:39:59,931 - up42 - INFO - Working on Project with project_id 14d0c2e7-bcb1-499c-880f-e3e3ac4dee11 2020-07-31 10:40:00,778 - up42.project - INFO - Created new workflow: 8cd776d6-71ec-4a1e-b54d-340130bf07fa. Following will fetch the data from UP42 platform corresponding the AOI and parameters we passed into the function. The area of interest is based on 2019 flooding events in Mid-West, USA in 2019. Bellevue In [6]: input_tasks = [ 'sentinelhub-s2-aoiclipped' ] # Update workflow object with our desired data block as input_task(s) workflow . add_workflow_tasks ( input_tasks = input_tasks ) # read aoi aoi = workflow . read_vector_file ( \"data/aoi_bellevue_US.geojson\" , as_dataframe = True ) # construct input parameters input_parameters = workflow . construct_parameters ( geometry = aoi , geometry_operation = \"contains\" , start_date = \"2019-03-21\" , end_date = \"2019-03-21\" , limit = 1 ) # run the actual job job = workflow . run_job ( input_parameters = input_parameters , track_status = True ) 2020-07-31 10:40:03,369 - up42.workflow - INFO - Added tasks to workflow: [{'name': 'sentinelhub-s2-aoiclipped:1', 'parentName': None, 'blockId': 'c4758545-4b74-4318-ae1f-d5ba72f234ca'}] 2020-07-31 10:40:04,116 - up42.workflow - INFO - Selected input_parameters: {'sentinelhub-s2-aoiclipped:1': {'time': '2019-03-21T00:00:00Z/2019-03-21T00:00:00Z', 'limit': 1, 'zoom_level': 14, 'contains': {'type': 'Polygon', 'coordinates': (((-95.929012, 41.114021), (-95.928326, 41.124884), (-95.922832, 41.132642), (-95.906868, 41.123978), (-95.900517, 41.116995), (-95.88747, 41.119452), (-95.878887, 41.119064), (-95.875969, 41.110787), (-95.880947, 41.106519), (-95.901203, 41.102121), (-95.916824, 41.106649), (-95.929012, 41.114021)),)}}}. 2020-07-31 10:40:05,618 - up42.workflow - INFO - Created and running new job: 11c00140-a930-4555-81b2-8f5022cdf4d1. 2020-07-31 10:40:06,063 - up42.job - INFO - Tracking job status continuously, reporting every 30 seconds... 2020-07-31 10:40:28,470 - up42.job - INFO - Job finished successfully! - 11c00140-a930-4555-81b2-8f5022cdf4d1 In [7]: # download results and quicklooks to results/sentinel/ folder in current directory job . download_results ( sentinel_dir ) job . download_quicklooks ( sentinel_dir ) 2020-07-31 10:40:33,482 - up42.job - INFO - Downloading results of job 11c00140-a930-4555-81b2-8f5022cdf4d1 2020-07-31 10:40:33,485 - up42.job - INFO - Download directory: results/sentinel 4244it [00:00, 405195.11it/s] 2020-07-31 10:40:35,655 - up42.utils - INFO - Download successful of 2 files to output_directory 'results/sentinel': ['7ed7ab02-3097-4038-80c8-10a4d3b3f1db.tif', 'data.json'] 2020-07-31 10:40:36,600 - up42.jobtask - INFO - Download directory: results/sentinel 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 1.81it/s] Out[7]: ['results/sentinel/quicklook_7ed7ab02-3097-4038-80c8-10a4d3b3f1db.jpg'] You should see a new folder named result/sentinel/ being created in the current working directory with .tif and meatadata file data.json . Additionally, we downloaded quicklooks .jpg with job.download_quicklooks() . This will come handy later while visualising on a folium map. NOTE: The SDK automatically creates the download directory if not already exists. In [8]: # store results and quicklook paths to separate variables raster_path = [ i for i in job . results if i . endswith ( '.tif' )][ 0 ] metadata_path = [ i for i in job . results if i . endswith ( '.json' )][ 0 ] In [9]: # similarly store path for quicklook ql_path = job . quicklooks [ 0 ] Now, that we have downloaded the necessary data let's move on to the next steps! In [10]: raster_path , metadata_path Out[10]: ('results/sentinel/7ed7ab02-3097-4038-80c8-10a4d3b3f1db.tif', 'results/sentinel/data.json') Calculate MNDWI \u00b6 The Modified Normalized Difference Water Index (MNDWI) uses green and SWIR bands for the enhancement of open water features. It also diminishes built-up area features that are often correlated with open water in other indices. MNDWI = (Green - SWIR) / (Green + SWIR) Green = pixel values from the green band SWIR = pixel values from the short-wave infrared band Reference : http://space4water.org/taxonomy/term/1246 In [11]: def normalize ( array ): \"\"\"Normalizes numpy arrays into scale 0.0 - 1.0\"\"\" array_min , array_max = array . min (), array . max () return (( array - array_min ) / ( array_max - array_min )) In [12]: def calc_mndwi ( green_band , swir_band ): mndwi = ( green_band - swir_band ) / ( green_band + swir_band ) return mndwi . astype ( np . float32 ) In [13]: with rio . open ( raster_path ) as src : green = src . read ( 3 ) swir = src . read ( 11 ) # normalize band arrays green_n = normalize ( green ) swir_n = normalize ( swir ) # get bounds,crs and transform src_bounds = src . bounds src_crs = src . crs src_transform = src . transform # compute MNDWI mndwi = calc_mndwi ( green_band = green_n , swir_band = swir_n ) Let's quickly plot and see how it looks like In [14]: plt . figure ( figsize = ( 10 , 7 )) plt . imshow ( mndwi , cmap = 'terrain_r' ) # Add colorbar to show the index plt . colorbar (); As we can see the water area is depicted in blue where as land area is brown(-ish) color Create Vector Mask \u00b6 Now that we have computed MNDWI, next step is to isolate boundaries of flooded area from whole image. This means, Apply a deterministic decision boundary / threshold to NDWI values Translate the threshold values into boolean value mask (1/0) Convert raster into vector boundary (multipolygon) According the NDWI-wikipedia : For the second variant of the NDWI, another threshold can also be found in that avoids creating false alarms in urban areas: < 0.3 - Non-water >= 0.3 - Water Meaning all the values that are >= 0.3 will be mapped to value true and < 0.3 to false respectively. In [15]: # create numpy mask mndwi_msk = ( mndwi >= 0.3 ) Pixel to shapely geom \u00b6 In [16]: mypoly = [] for vec , val in features . shapes ( source = mndwi_msk . astype ( np . float32 ), transform = src_transform ): mypoly . append ({ 'geom' : shapely_shp ( vec ), 'value' : val }) Now, let's convert this to GeoDataFrame as it will be easy to do vector based operations as well as to create viz. In [17]: # to gdf submerged = gpd . GeoDataFrame ( mypoly , crs = src_crs , geometry = 'geom' ) In [18]: # value counts submerged [ 'value' ] . value_counts () Out[18]: 1.0 203 0.0 138 Name: value, dtype: int64 We see that submerged have two unique values (0.0, 1.0). However, 1.0 corresponds to water so it makes sense to filter out land-area from gdf. In [19]: # filter by water area submerged = submerged [ submerged [ 'value' ] > 0 ] In [20]: # shape should be 203 based on value count cell above submerged . shape [ 0 ] Out[20]: 203 In [21]: # quick plot submerged . plot ( figsize = ( 15 , 10 )); Now that we have vectorized boundaries of flooded area which we will use to intersect with building footprint polygons from OSM. It is better to collapse all individual polygons into a single Multipolygon geometry. Also, note the x and y axis values!! ( HINT: crs) In [22]: boundary = cascaded_union ( list ( submerged [ 'geom' ])) Retrieve Building Footprints from OSM \u00b6 In this section, we will now retrieve building footprints from OpenStreetMap. At UP42, we recently developed an OpenStreetMap Data Block which is available on our marketplace. As hinted before, the coordinate system of Sentinel-2 data is in EPSG:3857 and the OSM query is done in EPSG:4326 . Therefore, we'll need to perform some coordinate transformation here for both the OSM data retrieval as well as plotting the results with Folium. Let's define the transform. In [23]: # transform crs crs_project = partial ( pyproj . transform , pyproj . Proj ( init = 'epsg:3857' ), # source coordinate system pyproj . Proj ( init = 'epsg:4326' ) # destination coordinate system ) In [24]: # read bounds from dataset and transform to wgs84 osm_poly = transform ( crs_project , box ( * src_bounds )) In the next part, we will create a new workflow within the scope of same project that we initialized and authenticated in earlier part. In [25]: workflow_osm = project . create_workflow ( name = \"flooding_osm\" ) # input task name for the OSM input_tasks_osm = [ 'openstreetmap' ] # Update workflow object with our desired data block as input_task(s) workflow_osm . add_workflow_tasks ( input_tasks = input_tasks_osm ) # read aoi aoi = workflow_osm . read_vector_file ( \"data/aoi_bellevue_US.geojson\" , as_dataframe = True ) # construct input parameters input_parameters = workflow_osm . construct_parameters ( geometry = aoi , geometry_operation = \"bbox\" , start_date = \"2019-03-21\" , end_date = \"2021-03-21\" ) 2020-07-31 10:40:39,504 - up42.project - INFO - Created new workflow: 41dbab0f-4792-441c-8bbe-05a538d520d2. 2020-07-31 10:40:41,547 - up42.workflow - INFO - Added tasks to workflow: [{'name': 'openstreetmap:1', 'parentName': None, 'blockId': '2c688ca6-f256-4989-b6a2-f2fed0f6e812'}] The job is almost ready to be run. If you notice carefully, the end_date parameter is in the future. The block converts the future date to today's date. We have constructed the input_parameters but we haven't yet mentioned that we want to retrieve building_footprints from OSM. Currently, the the block offers retrieval of 4 feature types by providing keywords listed in the table below. OSM feature Input Parameter ( osm_tags ) Roads street_network Water bodies water_bodies Building footprints building_footprints Land use land_use Here, the variable input_parameters is nothing but a native python dict . We can add osm_tag = [\"building_footprints\"] to this dictionary. The key osm_tag can be a list of all above tags as well. In [26]: # add osm_tags to input_parameters input_parameters [ 'openstreetmap:1' ][ \"osm_tags\" ] = [ \"building_footprints\" ] In [27]: # run the job job_osm = workflow_osm . run_job ( input_parameters = input_parameters , track_status = True ) 2020-07-31 10:40:42,047 - up42.workflow - INFO - Selected input_parameters: {'openstreetmap:1': {'time': '2019-03-21T00:00:00Z/2021-03-21T00:00:00Z', 'bbox': [-95.929012, 41.102121, -95.875969, 41.132642], 'osm_tags': ['building_footprints']}}. 2020-07-31 10:40:43,242 - up42.workflow - INFO - Created and running new job: 9a06fe58-89c1-4c29-a909-d8327857bee1. 2020-07-31 10:40:43,703 - up42.job - INFO - Tracking job status continuously, reporting every 30 seconds... 2020-07-31 10:41:00,556 - up42.job - INFO - Job finished successfully! - 9a06fe58-89c1-4c29-a909-d8327857bee1 In [28]: # define download directory osm_dir = \"./results/osm/\" # download results job_osm . download_results ( osm_dir ) 2020-07-31 10:41:05,567 - up42.job - INFO - Downloading results of job 9a06fe58-89c1-4c29-a909-d8327857bee1 2020-07-31 10:41:05,568 - up42.job - INFO - Download directory: results/osm 26it [00:00, 27685.17it/s] 2020-07-31 10:41:06,562 - up42.utils - INFO - Download successful of 2 files to output_directory 'results/osm': ['building_footprints_2020-07-31T08:39:02Z.geojson', 'data.json'] Out[28]: ['results/osm/building_footprints_2020-07-31T08:39:02Z.geojson', 'results/osm/data.json'] In [29]: building_footprints_path = [ i for i in job_osm . results if \"building_footprints\" in i ][ 0 ] building_footprints_path Out[29]: 'results/osm/building_footprints_2020-07-31T08:39:02Z.geojson' In [30]: gdf = gpd . read_file ( building_footprints_path ) # reproject to EPSG:3857 gdf_proj = gdf . to_crs ( src_crs ) In [31]: gdf_proj . plot ( figsize = ( 15 , 10 )); Notice that the coordinates, here, are in (lat, lon). Now, that data is extracted, we can transform it to the crs of the dataset. Doing this right now prevents any inconsistencies (with plotting, intersecting etc.) at later point as well as ensures sanity!! In [32]: gdf_proj . head ( 1 ) Out[32]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } type id tags geometry 0 way 32811010 {'building': 'hangar', 'layer': '1'} POLYGON ((-10675793.142 5028506.241, -10675786... Extract Flood Impacted buildings \u00b6 Until this point, we set the stage for actual task. Basically, the building footprints that intersects the Multipolygon (one we created from MNDWI) are effected building and those that are not are not-effected buildings! In [33]: effected = gdf_proj [ gdf_proj [ 'geometry' ] . intersects ( boundary )] # change coordinate system for plotting effected . to_crs ( crs = 'EPSG:4326' , inplace = True ) /Users/prayag.thakkar/Envs/up42-py/lib/python3.7/site-packages/geopandas/geodataframe.py:183: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy frame[geo_column_name] = level In [34]: not_effected = gdf_proj [ ~ gdf_proj [ 'geometry' ] . intersects ( boundary )] # change coordinate system for plotting not_effected . to_crs ( crs = 'EPSG:4326' , inplace = True ) /Users/prayag.thakkar/Envs/up42-py/lib/python3.7/site-packages/geopandas/geodataframe.py:183: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy frame[geo_column_name] = level In [35]: # quick sanity check gdf_proj . shape [ 0 ] == ( effected . shape [ 0 ] + not_effected . shape [ 0 ]) Out[35]: True It's time for plotting. We will use Folium library for displaying our results. Of course, it requires a bit of massaging before we get to the plotting Plotting \u00b6 In [36]: # bbox centroid serves as the center point for the folium map bbox_centroid = list (( osm_poly . centroid ) . coords [:][ 0 ]) bbox_centroid = [ bbox_centroid [ - 1 ], bbox_centroid [ 0 ]] bbox_centroid Out[36]: [41.12074089370247, -95.899658203125] In [37]: # extracts bounds for image overlay lon_min , lat_min , lon_max , lat_max = osm_poly . bounds In [38]: style1 = { 'fillColor' : '#228B22' , 'color' : 'red' } style2 = { 'fillColor' : '#00FFFFFF' , 'color' : '#00FFFFFF' } In [39]: # init folium map m = folium . Map ( bbox_centroid , zoom_start = 15 ) # add effected buildings folium . GeoJson ( effected . to_json (), style_function = lambda x : style1 ) . add_to ( m ); # add not_effected buildings folium . GeoJson ( not_effected . to_json (), style_function = lambda x : style2 ) . add_to ( m ); # add raster png quicklook folium . raster_layers . ImageOverlay ( image = ql_path , bounds = [[ lat_min , lon_min ], [ lat_max , lon_max ]], opacity = 0.8 ) . add_to ( m ); In [40]: folium . LayerControl () . add_to ( m ) m Out[40]: Make this Notebook Trusted to load map: File -> Trust Notebook As we can see the buildings impacted by flooding in red and those that are not impacted are in blue. It should be noted that success of the analysis depends on the availability of the data in OSM!! In [42]: m . save ( \"/Users/prayag.thakkar/Desktop/folium_map.html\" ) In [ ]:","title":"Flood mapping"},{"location":"examples/flood_mapping/#flood-impact-mapping-with-up42","text":"In the following tutorial we will map the impact of the flooding in urban area using UP42 python SDK and OpenStreetMap data. This notebook is intended to show how your existing GIS analysis and workflows can seemlessly be integrated with UP42 Python SDK in a few lines of code. The notebook is divided in following sections: Download Sentinel-2 AOI clipped GeoTiff with Sentinel-2 L1C MSI AOI clipped data block Calculate Modified Normalized Water Index (MNDWI) Convert MNDWI raster mask to vector mask Extract building footprints polygons from OSM using UP42 OSM Data Block Plot the impacted buildings with Folium In [1]: # imports import os from functools import partial import geopandas as gpd import matplotlib.pyplot as plt import numpy as np import pandas as pd import pyproj import rasterio as rio from rasterio import features from rasterio.plot import reshape_as_raster , show from shapely.geometry import LineString , MultiPolygon , Point , Polygon , box from shapely.geometry import shape as shapely_shp from shapely.ops import cascaded_union , transform import folium import up42 In [2]: # allows for ignoring errors + division by zero np . seterr ( divide = 'ignore' , invalid = 'ignore' ) Out[2]: {'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'} Set-up data directory to work with. This is optional though. The SDK creates a directory in the project folder for you! In [3]: sentinel_dir = \"./results/sentinel/\"","title":"Flood Impact Mapping with UP42"},{"location":"examples/flood_mapping/#download-data-from-up42-platform","text":"In [4]: # authenticate up42 . authenticate ( cfg_file = \"config.json\" ) 2020-07-31 10:39:59,659 - up42.auth - INFO - Got credentials from config file. 2020-07-31 10:39:59,925 - up42.auth - INFO - Authentication with UP42 successful! In [5]: project = up42 . initialize_project () # init workflow workflow = project . create_workflow ( name = \"flooding_sentinel\" ) 2020-07-31 10:39:59,931 - up42 - INFO - Working on Project with project_id 14d0c2e7-bcb1-499c-880f-e3e3ac4dee11 2020-07-31 10:40:00,778 - up42.project - INFO - Created new workflow: 8cd776d6-71ec-4a1e-b54d-340130bf07fa. Following will fetch the data from UP42 platform corresponding the AOI and parameters we passed into the function. The area of interest is based on 2019 flooding events in Mid-West, USA in 2019. Bellevue In [6]: input_tasks = [ 'sentinelhub-s2-aoiclipped' ] # Update workflow object with our desired data block as input_task(s) workflow . add_workflow_tasks ( input_tasks = input_tasks ) # read aoi aoi = workflow . read_vector_file ( \"data/aoi_bellevue_US.geojson\" , as_dataframe = True ) # construct input parameters input_parameters = workflow . construct_parameters ( geometry = aoi , geometry_operation = \"contains\" , start_date = \"2019-03-21\" , end_date = \"2019-03-21\" , limit = 1 ) # run the actual job job = workflow . run_job ( input_parameters = input_parameters , track_status = True ) 2020-07-31 10:40:03,369 - up42.workflow - INFO - Added tasks to workflow: [{'name': 'sentinelhub-s2-aoiclipped:1', 'parentName': None, 'blockId': 'c4758545-4b74-4318-ae1f-d5ba72f234ca'}] 2020-07-31 10:40:04,116 - up42.workflow - INFO - Selected input_parameters: {'sentinelhub-s2-aoiclipped:1': {'time': '2019-03-21T00:00:00Z/2019-03-21T00:00:00Z', 'limit': 1, 'zoom_level': 14, 'contains': {'type': 'Polygon', 'coordinates': (((-95.929012, 41.114021), (-95.928326, 41.124884), (-95.922832, 41.132642), (-95.906868, 41.123978), (-95.900517, 41.116995), (-95.88747, 41.119452), (-95.878887, 41.119064), (-95.875969, 41.110787), (-95.880947, 41.106519), (-95.901203, 41.102121), (-95.916824, 41.106649), (-95.929012, 41.114021)),)}}}. 2020-07-31 10:40:05,618 - up42.workflow - INFO - Created and running new job: 11c00140-a930-4555-81b2-8f5022cdf4d1. 2020-07-31 10:40:06,063 - up42.job - INFO - Tracking job status continuously, reporting every 30 seconds... 2020-07-31 10:40:28,470 - up42.job - INFO - Job finished successfully! - 11c00140-a930-4555-81b2-8f5022cdf4d1 In [7]: # download results and quicklooks to results/sentinel/ folder in current directory job . download_results ( sentinel_dir ) job . download_quicklooks ( sentinel_dir ) 2020-07-31 10:40:33,482 - up42.job - INFO - Downloading results of job 11c00140-a930-4555-81b2-8f5022cdf4d1 2020-07-31 10:40:33,485 - up42.job - INFO - Download directory: results/sentinel 4244it [00:00, 405195.11it/s] 2020-07-31 10:40:35,655 - up42.utils - INFO - Download successful of 2 files to output_directory 'results/sentinel': ['7ed7ab02-3097-4038-80c8-10a4d3b3f1db.tif', 'data.json'] 2020-07-31 10:40:36,600 - up42.jobtask - INFO - Download directory: results/sentinel 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 1.81it/s] Out[7]: ['results/sentinel/quicklook_7ed7ab02-3097-4038-80c8-10a4d3b3f1db.jpg'] You should see a new folder named result/sentinel/ being created in the current working directory with .tif and meatadata file data.json . Additionally, we downloaded quicklooks .jpg with job.download_quicklooks() . This will come handy later while visualising on a folium map. NOTE: The SDK automatically creates the download directory if not already exists. In [8]: # store results and quicklook paths to separate variables raster_path = [ i for i in job . results if i . endswith ( '.tif' )][ 0 ] metadata_path = [ i for i in job . results if i . endswith ( '.json' )][ 0 ] In [9]: # similarly store path for quicklook ql_path = job . quicklooks [ 0 ] Now, that we have downloaded the necessary data let's move on to the next steps! In [10]: raster_path , metadata_path Out[10]: ('results/sentinel/7ed7ab02-3097-4038-80c8-10a4d3b3f1db.tif', 'results/sentinel/data.json')","title":"Download data from UP42 platform"},{"location":"examples/flood_mapping/#calculate-mndwi","text":"The Modified Normalized Difference Water Index (MNDWI) uses green and SWIR bands for the enhancement of open water features. It also diminishes built-up area features that are often correlated with open water in other indices. MNDWI = (Green - SWIR) / (Green + SWIR) Green = pixel values from the green band SWIR = pixel values from the short-wave infrared band Reference : http://space4water.org/taxonomy/term/1246 In [11]: def normalize ( array ): \"\"\"Normalizes numpy arrays into scale 0.0 - 1.0\"\"\" array_min , array_max = array . min (), array . max () return (( array - array_min ) / ( array_max - array_min )) In [12]: def calc_mndwi ( green_band , swir_band ): mndwi = ( green_band - swir_band ) / ( green_band + swir_band ) return mndwi . astype ( np . float32 ) In [13]: with rio . open ( raster_path ) as src : green = src . read ( 3 ) swir = src . read ( 11 ) # normalize band arrays green_n = normalize ( green ) swir_n = normalize ( swir ) # get bounds,crs and transform src_bounds = src . bounds src_crs = src . crs src_transform = src . transform # compute MNDWI mndwi = calc_mndwi ( green_band = green_n , swir_band = swir_n ) Let's quickly plot and see how it looks like In [14]: plt . figure ( figsize = ( 10 , 7 )) plt . imshow ( mndwi , cmap = 'terrain_r' ) # Add colorbar to show the index plt . colorbar (); As we can see the water area is depicted in blue where as land area is brown(-ish) color","title":"Calculate MNDWI"},{"location":"examples/flood_mapping/#create-vector-mask","text":"Now that we have computed MNDWI, next step is to isolate boundaries of flooded area from whole image. This means, Apply a deterministic decision boundary / threshold to NDWI values Translate the threshold values into boolean value mask (1/0) Convert raster into vector boundary (multipolygon) According the NDWI-wikipedia : For the second variant of the NDWI, another threshold can also be found in that avoids creating false alarms in urban areas: < 0.3 - Non-water >= 0.3 - Water Meaning all the values that are >= 0.3 will be mapped to value true and < 0.3 to false respectively. In [15]: # create numpy mask mndwi_msk = ( mndwi >= 0.3 )","title":"Create Vector Mask"},{"location":"examples/flood_mapping/#pixel-to-shapely-geom","text":"In [16]: mypoly = [] for vec , val in features . shapes ( source = mndwi_msk . astype ( np . float32 ), transform = src_transform ): mypoly . append ({ 'geom' : shapely_shp ( vec ), 'value' : val }) Now, let's convert this to GeoDataFrame as it will be easy to do vector based operations as well as to create viz. In [17]: # to gdf submerged = gpd . GeoDataFrame ( mypoly , crs = src_crs , geometry = 'geom' ) In [18]: # value counts submerged [ 'value' ] . value_counts () Out[18]: 1.0 203 0.0 138 Name: value, dtype: int64 We see that submerged have two unique values (0.0, 1.0). However, 1.0 corresponds to water so it makes sense to filter out land-area from gdf. In [19]: # filter by water area submerged = submerged [ submerged [ 'value' ] > 0 ] In [20]: # shape should be 203 based on value count cell above submerged . shape [ 0 ] Out[20]: 203 In [21]: # quick plot submerged . plot ( figsize = ( 15 , 10 )); Now that we have vectorized boundaries of flooded area which we will use to intersect with building footprint polygons from OSM. It is better to collapse all individual polygons into a single Multipolygon geometry. Also, note the x and y axis values!! ( HINT: crs) In [22]: boundary = cascaded_union ( list ( submerged [ 'geom' ]))","title":"Pixel to shapely geom"},{"location":"examples/flood_mapping/#retrieve-building-footprints-from-osm","text":"In this section, we will now retrieve building footprints from OpenStreetMap. At UP42, we recently developed an OpenStreetMap Data Block which is available on our marketplace. As hinted before, the coordinate system of Sentinel-2 data is in EPSG:3857 and the OSM query is done in EPSG:4326 . Therefore, we'll need to perform some coordinate transformation here for both the OSM data retrieval as well as plotting the results with Folium. Let's define the transform. In [23]: # transform crs crs_project = partial ( pyproj . transform , pyproj . Proj ( init = 'epsg:3857' ), # source coordinate system pyproj . Proj ( init = 'epsg:4326' ) # destination coordinate system ) In [24]: # read bounds from dataset and transform to wgs84 osm_poly = transform ( crs_project , box ( * src_bounds )) In the next part, we will create a new workflow within the scope of same project that we initialized and authenticated in earlier part. In [25]: workflow_osm = project . create_workflow ( name = \"flooding_osm\" ) # input task name for the OSM input_tasks_osm = [ 'openstreetmap' ] # Update workflow object with our desired data block as input_task(s) workflow_osm . add_workflow_tasks ( input_tasks = input_tasks_osm ) # read aoi aoi = workflow_osm . read_vector_file ( \"data/aoi_bellevue_US.geojson\" , as_dataframe = True ) # construct input parameters input_parameters = workflow_osm . construct_parameters ( geometry = aoi , geometry_operation = \"bbox\" , start_date = \"2019-03-21\" , end_date = \"2021-03-21\" ) 2020-07-31 10:40:39,504 - up42.project - INFO - Created new workflow: 41dbab0f-4792-441c-8bbe-05a538d520d2. 2020-07-31 10:40:41,547 - up42.workflow - INFO - Added tasks to workflow: [{'name': 'openstreetmap:1', 'parentName': None, 'blockId': '2c688ca6-f256-4989-b6a2-f2fed0f6e812'}] The job is almost ready to be run. If you notice carefully, the end_date parameter is in the future. The block converts the future date to today's date. We have constructed the input_parameters but we haven't yet mentioned that we want to retrieve building_footprints from OSM. Currently, the the block offers retrieval of 4 feature types by providing keywords listed in the table below. OSM feature Input Parameter ( osm_tags ) Roads street_network Water bodies water_bodies Building footprints building_footprints Land use land_use Here, the variable input_parameters is nothing but a native python dict . We can add osm_tag = [\"building_footprints\"] to this dictionary. The key osm_tag can be a list of all above tags as well. In [26]: # add osm_tags to input_parameters input_parameters [ 'openstreetmap:1' ][ \"osm_tags\" ] = [ \"building_footprints\" ] In [27]: # run the job job_osm = workflow_osm . run_job ( input_parameters = input_parameters , track_status = True ) 2020-07-31 10:40:42,047 - up42.workflow - INFO - Selected input_parameters: {'openstreetmap:1': {'time': '2019-03-21T00:00:00Z/2021-03-21T00:00:00Z', 'bbox': [-95.929012, 41.102121, -95.875969, 41.132642], 'osm_tags': ['building_footprints']}}. 2020-07-31 10:40:43,242 - up42.workflow - INFO - Created and running new job: 9a06fe58-89c1-4c29-a909-d8327857bee1. 2020-07-31 10:40:43,703 - up42.job - INFO - Tracking job status continuously, reporting every 30 seconds... 2020-07-31 10:41:00,556 - up42.job - INFO - Job finished successfully! - 9a06fe58-89c1-4c29-a909-d8327857bee1 In [28]: # define download directory osm_dir = \"./results/osm/\" # download results job_osm . download_results ( osm_dir ) 2020-07-31 10:41:05,567 - up42.job - INFO - Downloading results of job 9a06fe58-89c1-4c29-a909-d8327857bee1 2020-07-31 10:41:05,568 - up42.job - INFO - Download directory: results/osm 26it [00:00, 27685.17it/s] 2020-07-31 10:41:06,562 - up42.utils - INFO - Download successful of 2 files to output_directory 'results/osm': ['building_footprints_2020-07-31T08:39:02Z.geojson', 'data.json'] Out[28]: ['results/osm/building_footprints_2020-07-31T08:39:02Z.geojson', 'results/osm/data.json'] In [29]: building_footprints_path = [ i for i in job_osm . results if \"building_footprints\" in i ][ 0 ] building_footprints_path Out[29]: 'results/osm/building_footprints_2020-07-31T08:39:02Z.geojson' In [30]: gdf = gpd . read_file ( building_footprints_path ) # reproject to EPSG:3857 gdf_proj = gdf . to_crs ( src_crs ) In [31]: gdf_proj . plot ( figsize = ( 15 , 10 )); Notice that the coordinates, here, are in (lat, lon). Now, that data is extracted, we can transform it to the crs of the dataset. Doing this right now prevents any inconsistencies (with plotting, intersecting etc.) at later point as well as ensures sanity!! In [32]: gdf_proj . head ( 1 ) Out[32]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } type id tags geometry 0 way 32811010 {'building': 'hangar', 'layer': '1'} POLYGON ((-10675793.142 5028506.241, -10675786...","title":"Retrieve Building Footprints from OSM"},{"location":"examples/flood_mapping/#extract-flood-impacted-buildings","text":"Until this point, we set the stage for actual task. Basically, the building footprints that intersects the Multipolygon (one we created from MNDWI) are effected building and those that are not are not-effected buildings! In [33]: effected = gdf_proj [ gdf_proj [ 'geometry' ] . intersects ( boundary )] # change coordinate system for plotting effected . to_crs ( crs = 'EPSG:4326' , inplace = True ) /Users/prayag.thakkar/Envs/up42-py/lib/python3.7/site-packages/geopandas/geodataframe.py:183: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy frame[geo_column_name] = level In [34]: not_effected = gdf_proj [ ~ gdf_proj [ 'geometry' ] . intersects ( boundary )] # change coordinate system for plotting not_effected . to_crs ( crs = 'EPSG:4326' , inplace = True ) /Users/prayag.thakkar/Envs/up42-py/lib/python3.7/site-packages/geopandas/geodataframe.py:183: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy frame[geo_column_name] = level In [35]: # quick sanity check gdf_proj . shape [ 0 ] == ( effected . shape [ 0 ] + not_effected . shape [ 0 ]) Out[35]: True It's time for plotting. We will use Folium library for displaying our results. Of course, it requires a bit of massaging before we get to the plotting","title":"Extract Flood Impacted buildings"},{"location":"examples/flood_mapping/#plotting","text":"In [36]: # bbox centroid serves as the center point for the folium map bbox_centroid = list (( osm_poly . centroid ) . coords [:][ 0 ]) bbox_centroid = [ bbox_centroid [ - 1 ], bbox_centroid [ 0 ]] bbox_centroid Out[36]: [41.12074089370247, -95.899658203125] In [37]: # extracts bounds for image overlay lon_min , lat_min , lon_max , lat_max = osm_poly . bounds In [38]: style1 = { 'fillColor' : '#228B22' , 'color' : 'red' } style2 = { 'fillColor' : '#00FFFFFF' , 'color' : '#00FFFFFF' } In [39]: # init folium map m = folium . Map ( bbox_centroid , zoom_start = 15 ) # add effected buildings folium . GeoJson ( effected . to_json (), style_function = lambda x : style1 ) . add_to ( m ); # add not_effected buildings folium . GeoJson ( not_effected . to_json (), style_function = lambda x : style2 ) . add_to ( m ); # add raster png quicklook folium . raster_layers . ImageOverlay ( image = ql_path , bounds = [[ lat_min , lon_min ], [ lat_max , lon_max ]], opacity = 0.8 ) . add_to ( m ); In [40]: folium . LayerControl () . add_to ( m ) m Out[40]: Make this Notebook Trusted to load map: File -> Trust Notebook As we can see the buildings impacted by flooding in red and those that are not impacted are in blue. It should be noted that success of the analysis depends on the availability of the data in OSM!! In [42]: m . save ( \"/Users/prayag.thakkar/Desktop/folium_map.html\" ) In [ ]:","title":"Plotting"},{"location":"examples/map-quicklooks/","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } pre { line-height: 125%; margin: 0; } td.linenos pre { color: #000000; background-color: #f0f0f0; padding: 0 5px 0 5px; } span.linenos { color: #000000; background-color: #f0f0f0; padding: 0 5px 0 5px; } td.linenos pre.special { color: #000000; background-color: #ffffc0; padding: 0 5px 0 5px; } span.linenos.special { color: #000000; background-color: #ffffc0; padding: 0 5px 0 5px; } .highlight-ipynb .hll { background-color: #ffffcc } .highlight-ipynb { background: #f8f8f8; } .highlight-ipynb .c { color: #408080; font-style: italic } /* Comment */ .highlight-ipynb .err { border: 1px solid #FF0000 } /* Error */ .highlight-ipynb .k { color: #008000; font-weight: bold } /* Keyword */ .highlight-ipynb .o { color: #666666 } /* Operator */ .highlight-ipynb .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight-ipynb .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight-ipynb .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight-ipynb .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight-ipynb .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight-ipynb .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight-ipynb .gd { color: #A00000 } /* Generic.Deleted */ .highlight-ipynb .ge { font-style: italic } /* Generic.Emph */ .highlight-ipynb .gr { color: #FF0000 } /* Generic.Error */ .highlight-ipynb .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight-ipynb .gi { color: #00A000 } /* Generic.Inserted */ .highlight-ipynb .go { color: #888888 } /* Generic.Output */ .highlight-ipynb .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight-ipynb .gs { font-weight: bold } /* Generic.Strong */ .highlight-ipynb .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight-ipynb .gt { color: #0044DD } /* Generic.Traceback */ .highlight-ipynb .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight-ipynb .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight-ipynb .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight-ipynb .kp { color: #008000 } /* Keyword.Pseudo */ .highlight-ipynb .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight-ipynb .kt { color: #B00040 } /* Keyword.Type */ .highlight-ipynb .m { color: #666666 } /* Literal.Number */ .highlight-ipynb .s { color: #BA2121 } /* Literal.String */ .highlight-ipynb .na { color: #7D9029 } /* Name.Attribute */ .highlight-ipynb .nb { color: #008000 } /* Name.Builtin */ .highlight-ipynb .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight-ipynb .no { color: #880000 } /* Name.Constant */ .highlight-ipynb .nd { color: #AA22FF } /* Name.Decorator */ .highlight-ipynb .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight-ipynb .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight-ipynb .nf { color: #0000FF } /* Name.Function */ .highlight-ipynb .nl { color: #A0A000 } /* Name.Label */ .highlight-ipynb .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight-ipynb .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight-ipynb .nv { color: #19177C } /* Name.Variable */ .highlight-ipynb .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight-ipynb .w { color: #bbbbbb } /* Text.Whitespace */ .highlight-ipynb .mb { color: #666666 } /* Literal.Number.Bin */ .highlight-ipynb .mf { color: #666666 } /* Literal.Number.Float */ .highlight-ipynb .mh { color: #666666 } /* Literal.Number.Hex */ .highlight-ipynb .mi { color: #666666 } /* Literal.Number.Integer */ .highlight-ipynb .mo { color: #666666 } /* Literal.Number.Oct */ .highlight-ipynb .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight-ipynb .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight-ipynb .sc { color: #BA2121 } /* Literal.String.Char */ .highlight-ipynb .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight-ipynb .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight-ipynb .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight-ipynb .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight-ipynb .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight-ipynb .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight-ipynb .sx { color: #008000 } /* Literal.String.Other */ .highlight-ipynb .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight-ipynb .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight-ipynb .ss { color: #19177C } /* Literal.String.Symbol */ .highlight-ipynb .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight-ipynb .fm { color: #0000FF } /* Name.Function.Magic */ .highlight-ipynb .vc { color: #19177C } /* Name.Variable.Class */ .highlight-ipynb .vg { color: #19177C } /* Name.Variable.Global */ .highlight-ipynb .vi { color: #19177C } /* Name.Variable.Instance */ .highlight-ipynb .vm { color: #19177C } /* Name.Variable.Magic */ .highlight-ipynb .il { color: #666666 } /* Literal.Number.Integer.Long */ .rendered_html a{text-decoration:inherit !important}.rendered_html :link{text-decoration:inherit !important}.rendered_html :visited{text-decoration:inherit !important}pre code{background-color:inherit !important}.highlight{color:#000000}.highlight code{color:#000000}.highlight .n{color:#333333}.highlight .p{color:#000000}.text_cell .prompt{display:none !important}div.input_prompt{padding:0.2em 0.4em}div.output_prompt{padding:0.4em}.text_cell{margin:0 !important;padding:0 !important;border:none !important}.text_cell_render{margin:0 !important;padding:0 !important;border:none !important}.rendered_html *+p{margin-top:inherit !important}.anchor-link{display:none !important}.code_cell{margin:0 !important;padding:5px 0 !important;border:none !important}.celltoolbar{border:thin solid #CFCFCF;border-bottom:none;background:#EEE;border-radius:2px 2px 0px 0px;width:100%;height:29px;padding-right:4px;box-orient:horizontal;box-align:stretch;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;box-pack:end;-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;display:-webkit-flex}.celltoolbar .tags_button_container{display:-webkit-box;display:-ms-flexbox;display:flex}.celltoolbar .tags_button_container .tag-container{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;overflow:hidden;position:relative}.celltoolbar .tags_button_container .tag-container .cell-tag{background-color:#fff;white-space:nowrap;margin:3px 4px;padding:0 4px;border-radius:1px;border:1px solid #ccc;-webkit-box-shadow:none;box-shadow:none;width:inherit;font-size:13px;font-family:\"Helvetica Neue\", Helvetica, Arial, sans-serif;height:22px;line-height:22px;display:inline-block}div.input_area>div.highlight{margin:0.25em 0.4em !important}.code_cell pre{font-size:12px !important}.output_html table.dataframe{font-family:Arial, sans-serif;font-size:13px;line-height:20px}.output_html table.dataframe th,td{padding:4px;text-align:left}.bk-plot-wrapper tbody tr{background:none !important}.bk-plot-wrapper tbody tr:hover{background:none !important} /*# sourceMappingURL=jupyter-fixes.min.css.map */ MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ], displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ], processEscapes: true, processEnvironments: true }, // Center justify equations in code and markdown cells. Elsewhere // we use CSS to left justify single line equations in code cells. displayAlign: 'center', \"HTML-CSS\": { styles: {'.MathJax_Display': {\"margin\": 0}}, linebreaks: { automatic: true } } }); Quciklooks mapping \u00b6 Choose an area for checking available pleiades imagary. Search the area via catalog search. Download quicklooks for images that cover the selected area. Visualize the results via map_quicklooks function. In [1]: import up42 In [2]: up42 . authenticate ( project_id = \"1234\" , project_api_key = \"ABCD\" ) catalog = up42 . initialize_catalog () 2020-09-11 11:18:17,245 - up42.auth - INFO - Authentication with UP42 successful! In [3]: aoi = up42 . read_vector_file ( \"dakar.geojson\" , as_dataframe = False ) In [4]: search_parameters = catalog . construct_parameters ( geometry = aoi , start_date = \"2018-01-01\" , end_date = \"2020-12-31\" , sensors = [ \"pleiades\" ], max_cloudcover = 20 , sortby = \"cloudCoverage\" , limit = 10 ) search_results = catalog . search ( search_parameters = search_parameters ) 2020-09-11 11:18:23,881 - up42.catalog - INFO - Searching catalog with search_parameters: {'datetime': '2018-01-01T00:00:00Z/2020-12-31T00:00:00Z', 'intersects': {'type': 'Polygon', 'coordinates': (((-17.529857, 14.741202), (-17.528703, 14.748847), (-17.52686, 14.751031), (-17.522855, 14.748707), (-17.519673, 14.748374), (-17.518791, 14.750683), (-17.517314, 14.750686), (-17.516981, 14.751799), (-17.510855, 14.750763), (-17.509799, 14.751426), (-17.509903, 14.753229), (-17.508237, 14.754202), (-17.503933, 14.754674), (-17.503399, 14.756024), (-17.496004, 14.755294), (-17.492911, 14.756651), (-17.491767, 14.758595), (-17.489119, 14.758018), (-17.487241, 14.76154), (-17.485135, 14.761315), (-17.483361, 14.764372), (-17.48083, 14.76595), (-17.478857, 14.765801), (-17.473266, 14.762048), (-17.461401, 14.762555), (-17.440347, 14.766725), (-17.429603, 14.77182), (-17.412524, 14.777208), (-17.41046, 14.77862), (-17.343999, 14.804732), (-17.343829, 14.805709), (-17.310555, 14.818605), (-17.255434, 14.845886), (-17.254439, 14.845243), (-17.248441, 14.832004), (-17.240612, 14.830767), (-17.239068, 14.829787), (-17.235797, 14.826557), (-17.232959, 14.819383), (-17.226866, 14.810643), (-17.219122, 14.808075), (-17.216676, 14.806354), (-17.214365, 14.807102), (-17.207416, 14.824354), (-17.200816, 14.830315), (-17.196088, 14.831584), (-17.190219, 14.830581), (-17.178819, 14.834769), (-17.175198, 14.834709), (-17.171926, 14.833118), (-17.166685, 14.839382), (-17.158144, 14.843267), (-17.154579, 14.843201), (-17.148855, 14.840737), (-17.141668, 14.840113), (-17.138938, 14.838773), (-17.134266, 14.833396), (-17.132867, 14.827086), (-17.133597, 14.820229), (-17.137929, 14.810701), (-17.143664, 14.805293), (-17.153636, 14.801379), (-17.149757, 14.796664), (-17.148465, 14.791971), (-17.148735, 14.788806), (-17.153869, 14.777451), (-17.159334, 14.772907), (-17.164054, 14.771688), (-17.171164, 14.772886), (-17.177877, 14.777262), (-17.182848, 14.774767), (-17.194034, 14.774889), (-17.200946, 14.772362), (-17.20641, 14.768068), (-17.21 2020-09-11 11:18:24,633 - up42.catalog - INFO - 10 results returned. In [5]: catalog . download_quicklooks ( image_ids = search_results . id . to_list (), sensor = \"pleiades\" ) 2020-09-11 11:18:26,211 - up42.catalog - INFO - Getting quicklooks from provider oneatlas for image_ids: ['2a581680-17e4-4a61-8aa9-9e47e1bf36bb', 'e02b9c94-12ab-4c8a-851d-72716f92fc66', 'c33d3001-5068-4469-bf8e-9b4bc4429ac8', '5a0ef1b8-47d3-4185-adb7-cfd1f1919ab4', '4e635fe1-fe59-46ca-b4ec-a89be5d760f2', 'b23f1aee-2f9d-42f7-9289-5d1869ddb419', 'f8c03432-cec1-41b7-a203-4d871a03290f', 'eb0247e6-caf3-437d-9d58-593c8e2a08f8', '16e18e15-c941-4aae-97cd-d67b18dc9f6e'] 2020-09-11 11:18:26,213 - up42.catalog - INFO - Download directory: /Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:05<00:00, 1.66it/s] Out[5]: ['/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_2a581680-17e4-4a61-8aa9-9e47e1bf36bb.jpg', '/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_e02b9c94-12ab-4c8a-851d-72716f92fc66.jpg', '/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_c33d3001-5068-4469-bf8e-9b4bc4429ac8.jpg', '/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_5a0ef1b8-47d3-4185-adb7-cfd1f1919ab4.jpg', '/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_4e635fe1-fe59-46ca-b4ec-a89be5d760f2.jpg', '/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_b23f1aee-2f9d-42f7-9289-5d1869ddb419.jpg', '/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_f8c03432-cec1-41b7-a203-4d871a03290f.jpg', '/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_eb0247e6-caf3-437d-9d58-593c8e2a08f8.jpg', '/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_16e18e15-c941-4aae-97cd-d67b18dc9f6e.jpg'] In [6]: a = catalog . map_quicklooks ( scenes = search_results , aoi = aoi , save_html = \".\" ) In [7]: a Out[7]: Make this Notebook Trusted to load map: File -> Trust Notebook In [ ]:","title":"Quicklooks mapping"},{"location":"examples/map-quicklooks/#quciklooks-mapping","text":"Choose an area for checking available pleiades imagary. Search the area via catalog search. Download quicklooks for images that cover the selected area. Visualize the results via map_quicklooks function. In [1]: import up42 In [2]: up42 . authenticate ( project_id = \"1234\" , project_api_key = \"ABCD\" ) catalog = up42 . initialize_catalog () 2020-09-11 11:18:17,245 - up42.auth - INFO - Authentication with UP42 successful! In [3]: aoi = up42 . read_vector_file ( \"dakar.geojson\" , as_dataframe = False ) In [4]: search_parameters = catalog . construct_parameters ( geometry = aoi , start_date = \"2018-01-01\" , end_date = \"2020-12-31\" , sensors = [ \"pleiades\" ], max_cloudcover = 20 , sortby = \"cloudCoverage\" , limit = 10 ) search_results = catalog . search ( search_parameters = search_parameters ) 2020-09-11 11:18:23,881 - up42.catalog - INFO - Searching catalog with search_parameters: {'datetime': '2018-01-01T00:00:00Z/2020-12-31T00:00:00Z', 'intersects': {'type': 'Polygon', 'coordinates': (((-17.529857, 14.741202), (-17.528703, 14.748847), (-17.52686, 14.751031), (-17.522855, 14.748707), (-17.519673, 14.748374), (-17.518791, 14.750683), (-17.517314, 14.750686), (-17.516981, 14.751799), (-17.510855, 14.750763), (-17.509799, 14.751426), (-17.509903, 14.753229), (-17.508237, 14.754202), (-17.503933, 14.754674), (-17.503399, 14.756024), (-17.496004, 14.755294), (-17.492911, 14.756651), (-17.491767, 14.758595), (-17.489119, 14.758018), (-17.487241, 14.76154), (-17.485135, 14.761315), (-17.483361, 14.764372), (-17.48083, 14.76595), (-17.478857, 14.765801), (-17.473266, 14.762048), (-17.461401, 14.762555), (-17.440347, 14.766725), (-17.429603, 14.77182), (-17.412524, 14.777208), (-17.41046, 14.77862), (-17.343999, 14.804732), (-17.343829, 14.805709), (-17.310555, 14.818605), (-17.255434, 14.845886), (-17.254439, 14.845243), (-17.248441, 14.832004), (-17.240612, 14.830767), (-17.239068, 14.829787), (-17.235797, 14.826557), (-17.232959, 14.819383), (-17.226866, 14.810643), (-17.219122, 14.808075), (-17.216676, 14.806354), (-17.214365, 14.807102), (-17.207416, 14.824354), (-17.200816, 14.830315), (-17.196088, 14.831584), (-17.190219, 14.830581), (-17.178819, 14.834769), (-17.175198, 14.834709), (-17.171926, 14.833118), (-17.166685, 14.839382), (-17.158144, 14.843267), (-17.154579, 14.843201), (-17.148855, 14.840737), (-17.141668, 14.840113), (-17.138938, 14.838773), (-17.134266, 14.833396), (-17.132867, 14.827086), (-17.133597, 14.820229), (-17.137929, 14.810701), (-17.143664, 14.805293), (-17.153636, 14.801379), (-17.149757, 14.796664), (-17.148465, 14.791971), (-17.148735, 14.788806), (-17.153869, 14.777451), (-17.159334, 14.772907), (-17.164054, 14.771688), (-17.171164, 14.772886), (-17.177877, 14.777262), (-17.182848, 14.774767), (-17.194034, 14.774889), (-17.200946, 14.772362), (-17.20641, 14.768068), (-17.21 2020-09-11 11:18:24,633 - up42.catalog - INFO - 10 results returned. In [5]: catalog . download_quicklooks ( image_ids = search_results . id . to_list (), sensor = \"pleiades\" ) 2020-09-11 11:18:26,211 - up42.catalog - INFO - Getting quicklooks from provider oneatlas for image_ids: ['2a581680-17e4-4a61-8aa9-9e47e1bf36bb', 'e02b9c94-12ab-4c8a-851d-72716f92fc66', 'c33d3001-5068-4469-bf8e-9b4bc4429ac8', '5a0ef1b8-47d3-4185-adb7-cfd1f1919ab4', '4e635fe1-fe59-46ca-b4ec-a89be5d760f2', 'b23f1aee-2f9d-42f7-9289-5d1869ddb419', 'f8c03432-cec1-41b7-a203-4d871a03290f', 'eb0247e6-caf3-437d-9d58-593c8e2a08f8', '16e18e15-c941-4aae-97cd-d67b18dc9f6e'] 2020-09-11 11:18:26,213 - up42.catalog - INFO - Download directory: /Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:05<00:00, 1.66it/s] Out[5]: ['/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_2a581680-17e4-4a61-8aa9-9e47e1bf36bb.jpg', '/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_e02b9c94-12ab-4c8a-851d-72716f92fc66.jpg', '/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_c33d3001-5068-4469-bf8e-9b4bc4429ac8.jpg', '/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_5a0ef1b8-47d3-4185-adb7-cfd1f1919ab4.jpg', '/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_4e635fe1-fe59-46ca-b4ec-a89be5d760f2.jpg', '/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_b23f1aee-2f9d-42f7-9289-5d1869ddb419.jpg', '/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_f8c03432-cec1-41b7-a203-4d871a03290f.jpg', '/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_eb0247e6-caf3-437d-9d58-593c8e2a08f8.jpg', '/Users/nikoo.ekhtiari/Documents/up42-py/examples/project_8da6a795-d3ee-4175-a202-932a52e385e4/catalog/quicklook_16e18e15-c941-4aae-97cd-d67b18dc9f6e.jpg'] In [6]: a = catalog . map_quicklooks ( scenes = search_results , aoi = aoi , save_html = \".\" ) In [7]: a Out[7]: Make this Notebook Trusted to load map: File -> Trust Notebook In [ ]:","title":"Quciklooks mapping"},{"location":"examples/radar_processing_1/","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI escape sequences */ /* The color values are a mix of http://www.xcolors.net/dl/baskerville-ivorylight and http://www.xcolors.net/dl/euphrasia */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-default-inverse-fg { color: #FFFFFF; } .ansi-default-inverse-bg { background-color: #000000; } .ansi-bold { font-weight: bold; } .ansi-underline { text-decoration: underline; } /* The following styles are deprecated an will be removed in a future version */ .ansibold { font-weight: bold; } .ansi-inverse { outline: 0.5px dotted; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; position: relative; overflow: visible; } div.cell:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: transparent; } div.cell.jupyter-soft-selected { border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: #ababab; } div.cell.selected:before, div.cell.selected.jupyter-soft-selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #42A5F5; } @media print { div.cell.selected, div.cell.selected.jupyter-soft-selected { border-color: transparent; } } .edit_mode div.cell.selected { border-color: #66BB6A; } .edit_mode div.cell.selected:before { position: absolute; display: block; top: -1px; left: -1px; width: 5px; height: calc(100% + 2px); content: ''; background: #66BB6A; } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ /* Note that this should set vertical padding only, since CodeMirror assumes that horizontal padding will be set on CodeMirror pre */ padding: 0.4em 0; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only, use .CodeMirror-lines for vertical */ padding: 0 0.4em; border: 0; border-radius: 0; } .CodeMirror-cursor { border-left: 1.4px solid black; } @media screen and (min-width: 2138px) and (max-width: 4319px) { .CodeMirror-cursor { border-left: 2px solid black; } } @media screen and (min-width: 4320px) { .CodeMirror-cursor { border-left: 4px solid black; } } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } div.output_area .mglyph > img { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 1px 0 1px 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html ul:not(.list-inline), .rendered_html ol:not(.list-inline) { padding-left: 2em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html tbody tr:nth-child(odd) { background: #f5f5f5; } .rendered_html tbody tr:hover { background: rgba(66, 165, 245, 0.2); } .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, .rendered_html * + .alert { margin-top: 1em; } [dir=\"rtl\"] div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.rendered .rendered_html tr, .text_cell.rendered .rendered_html th, .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .text_cell .dropzone .input_area { border: 2px dashed #bababa; margin: -1px; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } pre { line-height: 125%; margin: 0; } td.linenos pre { color: #000000; background-color: #f0f0f0; padding: 0 5px 0 5px; } span.linenos { color: #000000; background-color: #f0f0f0; padding: 0 5px 0 5px; } td.linenos pre.special { color: #000000; background-color: #ffffc0; padding: 0 5px 0 5px; } span.linenos.special { color: #000000; background-color: #ffffc0; padding: 0 5px 0 5px; } .highlight-ipynb .hll { background-color: #ffffcc } .highlight-ipynb { background: #f8f8f8; } .highlight-ipynb .c { color: #408080; font-style: italic } /* Comment */ .highlight-ipynb .err { border: 1px solid #FF0000 } /* Error */ .highlight-ipynb .k { color: #008000; font-weight: bold } /* Keyword */ .highlight-ipynb .o { color: #666666 } /* Operator */ .highlight-ipynb .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight-ipynb .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight-ipynb .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight-ipynb .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight-ipynb .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight-ipynb .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight-ipynb .gd { color: #A00000 } /* Generic.Deleted */ .highlight-ipynb .ge { font-style: italic } /* Generic.Emph */ .highlight-ipynb .gr { color: #FF0000 } /* Generic.Error */ .highlight-ipynb .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight-ipynb .gi { color: #00A000 } /* Generic.Inserted */ .highlight-ipynb .go { color: #888888 } /* Generic.Output */ .highlight-ipynb .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight-ipynb .gs { font-weight: bold } /* Generic.Strong */ .highlight-ipynb .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight-ipynb .gt { color: #0044DD } /* Generic.Traceback */ .highlight-ipynb .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight-ipynb .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight-ipynb .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight-ipynb .kp { color: #008000 } /* Keyword.Pseudo */ .highlight-ipynb .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight-ipynb .kt { color: #B00040 } /* Keyword.Type */ .highlight-ipynb .m { color: #666666 } /* Literal.Number */ .highlight-ipynb .s { color: #BA2121 } /* Literal.String */ .highlight-ipynb .na { color: #7D9029 } /* Name.Attribute */ .highlight-ipynb .nb { color: #008000 } /* Name.Builtin */ .highlight-ipynb .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight-ipynb .no { color: #880000 } /* Name.Constant */ .highlight-ipynb .nd { color: #AA22FF } /* Name.Decorator */ .highlight-ipynb .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight-ipynb .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight-ipynb .nf { color: #0000FF } /* Name.Function */ .highlight-ipynb .nl { color: #A0A000 } /* Name.Label */ .highlight-ipynb .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight-ipynb .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight-ipynb .nv { color: #19177C } /* Name.Variable */ .highlight-ipynb .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight-ipynb .w { color: #bbbbbb } /* Text.Whitespace */ .highlight-ipynb .mb { color: #666666 } /* Literal.Number.Bin */ .highlight-ipynb .mf { color: #666666 } /* Literal.Number.Float */ .highlight-ipynb .mh { color: #666666 } /* Literal.Number.Hex */ .highlight-ipynb .mi { color: #666666 } /* Literal.Number.Integer */ .highlight-ipynb .mo { color: #666666 } /* Literal.Number.Oct */ .highlight-ipynb .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight-ipynb .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight-ipynb .sc { color: #BA2121 } /* Literal.String.Char */ .highlight-ipynb .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight-ipynb .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight-ipynb .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight-ipynb .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight-ipynb .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight-ipynb .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight-ipynb .sx { color: #008000 } /* Literal.String.Other */ .highlight-ipynb .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight-ipynb .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight-ipynb .ss { color: #19177C } /* Literal.String.Symbol */ .highlight-ipynb .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight-ipynb .fm { color: #0000FF } /* Name.Function.Magic */ .highlight-ipynb .vc { color: #19177C } /* Name.Variable.Class */ .highlight-ipynb .vg { color: #19177C } /* Name.Variable.Global */ .highlight-ipynb .vi { color: #19177C } /* Name.Variable.Instance */ .highlight-ipynb .vm { color: #19177C } /* Name.Variable.Magic */ .highlight-ipynb .il { color: #666666 } /* Literal.Number.Integer.Long */ .rendered_html a{text-decoration:inherit !important}.rendered_html :link{text-decoration:inherit !important}.rendered_html :visited{text-decoration:inherit !important}pre code{background-color:inherit !important}.highlight{color:#000000}.highlight code{color:#000000}.highlight .n{color:#333333}.highlight .p{color:#000000}.text_cell .prompt{display:none !important}div.input_prompt{padding:0.2em 0.4em}div.output_prompt{padding:0.4em}.text_cell{margin:0 !important;padding:0 !important;border:none !important}.text_cell_render{margin:0 !important;padding:0 !important;border:none !important}.rendered_html *+p{margin-top:inherit !important}.anchor-link{display:none !important}.code_cell{margin:0 !important;padding:5px 0 !important;border:none !important}.celltoolbar{border:thin solid #CFCFCF;border-bottom:none;background:#EEE;border-radius:2px 2px 0px 0px;width:100%;height:29px;padding-right:4px;box-orient:horizontal;box-align:stretch;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;box-pack:end;-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;display:-webkit-flex}.celltoolbar .tags_button_container{display:-webkit-box;display:-ms-flexbox;display:flex}.celltoolbar .tags_button_container .tag-container{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;overflow:hidden;position:relative}.celltoolbar .tags_button_container .tag-container .cell-tag{background-color:#fff;white-space:nowrap;margin:3px 4px;padding:0 4px;border-radius:1px;border:1px solid #ccc;-webkit-box-shadow:none;box-shadow:none;width:inherit;font-size:13px;font-family:\"Helvetica Neue\", Helvetica, Arial, sans-serif;height:22px;line-height:22px;display:inline-block}div.input_area>div.highlight{margin:0.25em 0.4em !important}.code_cell pre{font-size:12px !important}.output_html table.dataframe{font-family:Arial, sans-serif;font-size:13px;line-height:20px}.output_html table.dataframe th,td{padding:4px;text-align:left}.bk-plot-wrapper tbody tr{background:none !important}.bk-plot-wrapper tbody tr:hover{background:none !important} /*# sourceMappingURL=jupyter-fixes.min.css.map */ MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ], displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ], processEscapes: true, processEnvironments: true }, // Center justify equations in code and markdown cells. Elsewhere // we use CSS to left justify single line equations in code cells. displayAlign: 'center', \"HTML-CSS\": { styles: {'.MathJax_Display': {\"margin\": 0}}, linebreaks: { automatic: true } } }); Example: Radar processing \u00b6 The processing of radar data - often referred to as SAR data, which stands for Synthetice Aperture Radar - is a topic of its own and quite different from optical data that uses Red, Green, Blue, NIR and similar bands. This is the first of a series of jupyter notebooks where example SAR workflows will be explained that can be run on UP42. All of the examples are based on a specific type of analysis which is called polarimetry and processes one image at a time. In comparison to polarimetric there also is interferometric analysis which leverages the information encoded in suitable pairs of radar image. In this notebook we want to have a look at the Sentinel-1 GRD full scene block, followed by SNAP Sentinel-1 Polarimetric Processing. Polarimetric SAR Processing turns a Sentinel-1 GRD image into a multichannel GeoTIFF that is ready for analysis. Prepare workflow Define aoi and input parameters Run Job Visualize results In [1]: import up42 In [3]: # Authenticate with UP42 up42 . authenticate ( cfg_file = \"config.json\" ) #up42.authenticate(project_id=12345, project_api_key=12345) 2020-05-26 14:19:56,546 - up42.auth - INFO - Got credentials from config file. 2020-05-26 14:19:57,155 - up42.auth - INFO - Authentication with UP42 successful! Prepare UP42 workflows \u00b6 Create a new project on UP42 or use an existing one. In [5]: S1_SNAP_project = up42 . initialize_project () 2020-05-26 14:20:10,960 - up42 - INFO - Working on Project with project_id d3ea9123-2b89-4975-be16-e978fed8329c Create workflow and check available blocks and data In [6]: workflow = S1_SNAP_project . create_workflow ( name = \"S1-GRD_SNAP\" , use_existing = True ) print ( up42 . get_blocks ( basic = True )) 2020-05-26 14:20:14,765 - up42.project - INFO - Getting existing workflows in project ... 2020-05-26 14:20:15,434 - up42.project - INFO - Got 12 workflows for project d3ea9123-2b89-4975-be16-e978fed8329c. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12/12 [00:07<00:00, 1.52it/s] 2020-05-26 14:20:23,341 - up42.project - INFO - Using existing workflow: S1-GRD_SNAP, 1585a205-3907-4905-bd02-057a17c3cf84. 2020-05-26 14:20:24,728 - up42.tools - INFO - Getting blocks name and id, use basic=False for all block details. {'tiling': 'd350aa0b-ac31-4021-bbe6-fd8da366740a', 'oneatlas-spot-aoiclipped': '0f15e07f-efcc-4598-939b-18aade349c57', 'oneatlas-pleiades-aoiclipped': 'f026874d-e95e-4293-b811-7667130e054d', 'sobloo-s1-grd-fullscene': '4524e2de-c780-488d-9818-fe68dad9f095', 'sobloo-s2-l1c-fullscene': '604988cb-8252-4161-bf28-f6fb63d7371c', 'snap-polarimetric': '320158d6-8f93-4484-a828-e1fb64f677ff', 'sentinelhub-s2-aoiclipped': 'c4758545-4b74-4318-ae1f-d5ba72f234ca', 'sentinelhub-landsat8-aoiclipped': 'e0b133ae-7b9c-435c-99ac-c4527cc8d9cf', 'sobloo-s1-slc-fullscene': 'cf822545-c73c-467b-8f43-5311dbefe03f', 'nasa-modis': '61279eb8-02e1-4b7a-ac3d-1f62d19d3484', 's2-superresolution': '4872fef8-aec8-4dec-adcb-560ee4430a2b', 'oneatlas-pleiades-fullscene': '8487adcd-a4d7-4cb7-b826-75a533e1f330', 'oneatlas-spot-fullscene': 'aa62113f-0dd1-40a3-a004-954c9d087071', 'data-conversion': '470eedda-5f62-433c-8562-98eb8783af87', 'pansharpen': '2f24c662-c129-409f-a7c3-afa16a4c78cb', 'sobloo-s1-grd-aoiclipped': 'a956166f-c0ed-4670-8a43-87bed8d222f3', 'hello-world': '77899bd0-40de-4aa7-b67e-513a5655afcb', 'ndvi': 'aecb81ef-1c92-4b2e-aa25-55ccebe2f90a', 'sobloo-s2-l1c-aoiclipped': 'a2daaab4-196d-4226-a018-a810444dcad1', 'sobloo-s3': 'fee13ec1-a067-4d6a-95dc-a4fef458f4f4', 'sobloo-s5p': 'cba7c59b-548d-48bf-8920-c20d7d316dfd', 'kmeans-clustering': 'adf21e0a-98bf-41a9-a2cc-a59898a461ba', 'vectorising': '295bf286-0748-474f-aa38-c1ac35151204', 'crs-conversion': '18e6772f-cf33-4955-b7e4-61df8a108fd9', 'sharpening': '4ed70368-d4e1-4462-bef6-14e768049471', 'zonal-statistics': 'a5b8b938-6fd6-4bac-92cd-dffd7f3169aa', 'superresolution': '6c914299-7203-40ad-9b89-de0b4e827bd0', 's5p-lvl3': '9a593e06-eca0-49e0-8b8c-6fe95f699f9d', 'hexagon-aerial-30cm': '0b04d9f7-3a8e-4467-9fb8-1e8343c9469a', 'hexagon-aerial-15cm': '36fe7d3a-4671-424b-bd54-918dd21cfde1', 'ship-identification': '20a3bd1e-3f27-40cf-9915-8fa3d5024ade', 'ais-hvp': '7394287a-2458-4204-be62-36b6d264bcfe', 'ais-hvt': '67eb1763-abeb-4188-b135-f6a0d669d759', 'meteomatics': 'ed0beedb-111b-4285-aa2d-f876a4c16a32', 'oneatlas-pleiades-primary': 'd1e5e0de-71fa-4488-9c0e-3f22ac74a2b6', 'tiled-k-means': '45c0284a-5cd7-4bc0-9d6c-db05f7271036', 'data-conversion-netcdf': 'c358d5af-7819-4ecf-b8b3-629d5d3ba319', 'data-conversion-dimap': '25f42430-d108-4ea4-a81d-2c2b3fff7d11', 'aws-s2-l2a': '73f1b9e0-83de-4cbd-addf-5e0d23ed65d4', 'nextmapone-3m': '56a0ac08-69a5-491a-993d-63e3b9da315c', 'nextmapone-6m': 'f87dd9f3-fc14-48b1-b77d-d695fb65fcc4', 'nextmapone-1m': 'bfd43fbc-b662-4874-9147-658a55bf9edc'} In [7]: # Fill the workflow with tasks input_tasks = [ 'sobloo-s1-grd-fullscene' , 'snap-polarimetric' ] workflow . add_workflow_tasks ( input_tasks = input_tasks ) workflow . get_parameters_info () 2020-05-26 14:21:03,273 - up42.workflow - INFO - Added tasks to workflow: [{'name': 'sobloo-s1-grd-fullscene:1', 'parentName': None, 'blockId': '4524e2de-c780-488d-9818-fe68dad9f095'}, {'name': 'snap-polarimetric:1', 'parentName': 'sobloo-s1-grd-fullscene:1', 'blockId': '320158d6-8f93-4484-a828-e1fb64f677ff'}] 2020-05-26 14:21:04,000 - up42.workflow - INFO - Got 2 tasks/blocks in workflow 1585a205-3907-4905-bd02-057a17c3cf84. Out[7]: {'sobloo-s1-grd-fullscene:1': {'ids': {'type': 'array', 'default': None}, 'bbox': {'type': 'array', 'default': None}, 'time': {'type': 'dateRange', 'default': '2018-01-01T00:00:00+00:00/2020-12-31T23:59:59+00:00'}, 'limit': {'type': 'integer', 'default': 1, 'minimum': 1}, 'contains': {'type': 'geometry'}, 'intersects': {'type': 'geometry'}, 'time_series': {'type': 'array', 'default': None}, 'orbit_direction': {'type': 'string', 'default': None}, 'acquisition_mode': {'type': 'string', 'default': None}}, 'snap-polarimetric:1': {'bbox': {'type': 'array', 'default': None}, 'mask': {'type': 'array', 'items': {'enum': ['land', 'sea'], 'type': 'string'}, 'default': None}, 'contains': {'type': 'geometry', 'default': None}, 'intersects': {'type': 'geometry', 'default': None}, 'clip_to_aoi': {'type': 'boolean', 'default': False}, 'tcorrection': {'type': 'boolean', 'default': True}, 'linear_to_db': {'type': 'boolean', 'default': True}, 'polarisations': {'type': 'array', 'items': {'enum': ['VV', 'VH'], 'type': 'string'}, 'default': ['VV'], 'required': False, 'description': 'Requested polarisations for the output'}, 'speckle_filter': {'type': 'boolean', 'default': True}, 'calibration_band': {'type': 'array', 'default': ['sigma']}}} Define aoi and input parameters \u00b6 The S1 GRD block always delivers the complete images as they are delivered in SAFE format which cannot be clipped. The image can be clipped though by the SNAP polarimetric processing blocks. For this it is necessary to supply the same geometry (in this case a bbox) to that block as well. In [8]: input_parameters = { \"sobloo-s1-grd-fullscene:1\" : { \"bbox\" : [ 13.371037 , 52.512799 , 13.382624 , 52.518747 ], \"ids\" : None , \"time\" : \"2018-01-01T00:00:00+00:00/2020-12-31T23:59:59+00:00\" , \"limit\" : 1 , \"zoom_level\" : 14 , }, \"snap-polarimetric:1\" : { \"bbox\" : [ 13.371037 , 52.512799 , 13.382624 , 52.518747 ], \"mask\" : None , \"contains\" : None , \"intersects\" : None , \"clip_to_aoi\" : True , \"tcorrection\" : True , \"linear_to_db\" : True , \"polarisations\" : [ \"VV\" ], \"speckle_filter\" : True , \"calibration_band\" : [ \"sigma\" ] } } Run test query \u00b6 Run a test job to query data availability and check the configuration. In [9]: test_job = workflow . test_job ( input_parameters = input_parameters , track_status = True ) test_results = test_job . get_results_json () print ( test_results ) 2020-05-26 14:21:14,155 - up42.workflow - INFO - +++++++++++++++++++++++++++++++++ 2020-05-26 14:21:14,157 - up42.workflow - INFO - Running this job as Test Query... 2020-05-26 14:21:14,157 - up42.workflow - INFO - +++++++++++++++++++++++++++++++++ 2020-05-26 14:21:14,158 - up42.workflow - INFO - Selected input_parameters: {'sobloo-s1-grd-fullscene:1': {'bbox': [13.371037, 52.512799, 13.382624, 52.518747], 'ids': None, 'time': '2018-01-01T00:00:00+00:00/2020-12-31T23:59:59+00:00', 'limit': 1, 'zoom_level': 14}, 'snap-polarimetric:1': {'bbox': [13.371037, 52.512799, 13.382624, 52.518747], 'mask': None, 'contains': None, 'intersects': None, 'clip_to_aoi': True, 'tcorrection': True, 'linear_to_db': True, 'polarisations': ['VV'], 'speckle_filter': True, 'calibration_band': ['sigma']}, 'config': {'mode': 'DRY_RUN'}}. 2020-05-26 14:21:15,659 - up42.workflow - INFO - Created and running new job: 28c72c74-a5dc-46e3-bb70-f6efad3f910c. 2020-05-26 14:21:16,144 - up42.job - INFO - Tracking job status continuously, reporting every 30 seconds... 2020-05-26 14:21:39,235 - up42.job - INFO - Job finished successfully! - 28c72c74-a5dc-46e3-bb70-f6efad3f910c 2020-05-26 14:21:44,956 - up42.job - INFO - Retrieved 1 features. {'type': 'FeatureCollection', 'features': [{'type': 'Feature', 'bbox': [12.306028, 52.168652, 16.66515, 54.078037], 'id': '5a0bcc6b-8316-45c9-9106-8de8e27e5753', 'geometry': {'type': 'Polygon', 'coordinates': [[[16.151102, 52.168652], [16.66515, 53.660217], [12.685362, 54.078037], [12.306028, 52.5835], [16.151102, 52.168652]]]}, 'properties': {'attachments': [], 'visibility': {'deleted': False}, 'illumination': {}, 'production': {'levelCode': 'L1', 'ongoing': False, 'timeliness': 'Fast-24h'}, 'archive': {'offLine': False, 'filename': 'S1A_IW_GRDH_1SDV_20200525T051659_20200525T051724_032717_03CA2F_DB50.SAFE', 'size': 1689, 'format': 'SAFE', 'onLine': False}, 'spatialCoverage': {'verticality': {}, 'geometry': {'geographicBoundingPolygon': {'coordinates': [[[16.151102, 52.168652], [16.66515, 53.660217], [12.685362, 54.078037], [12.306028, 52.5835], [16.151102, 52.168652]]], 'type': 'Polygon'}, 'global': False, 'centerPoint': {'lon': 14.45556570632881, 'lat': 53.12652491313295}}}, 'quality': {'qualified': False}, 'target': {}, 'timeStamp': 1590383819131, 'uid': '5a0bcc6b-8316-45c9-9106-8de8e27e5753', 'identification': {'profile': 'Image', 'externalId': 'S1A_IW_GRDH_1SDV_20200525T051659_20200525T051724_032717_03CA2F_DB50', 'collection': 'Sentinel-1', 'type': 'GRD', 'dataset': {}}, 'transmission': {}, 'contentDescription': {}, 'provider': {}, 'acquisition': {'endViewingDate': 1590383844129, 'mission': 'Sentinel-1', 'missionId': 'A', 'missionCode': 'S1A', 'beginViewingDate': 1590383819131, 'missionName': 'Sentinel-1A', 'polarization': 'VV VH', 'type': 'NOMINAL', 'sensorMode': 'IW', 'sensorId': 'SAR-C SAR'}, 'orbit': {'relativeNumber': 95, 'lastRelativeNumber': 95, 'lastNumber': 32717, 'direction': 'DESCENDING'}, 'state': {'resources': {'thumbnail': True, 'quicklook': True}, 'services': {'wmts': False, 'download': 'internal', 'wcs': False, 'wms': False}, 'insertionDate': 1590395388355}, 'attitude': {}}}]} Run the job \u00b6 In [10]: job = workflow . run_job ( input_parameters = input_parameters , track_status = True ) 2020-05-26 14:21:44,963 - up42.workflow - INFO - Selected input_parameters: {'sobloo-s1-grd-fullscene:1': {'bbox': [13.371037, 52.512799, 13.382624, 52.518747], 'ids': None, 'time': '2018-01-01T00:00:00+00:00/2020-12-31T23:59:59+00:00', 'limit': 1, 'zoom_level': 14}, 'snap-polarimetric:1': {'bbox': [13.371037, 52.512799, 13.382624, 52.518747], 'mask': None, 'contains': None, 'intersects': None, 'clip_to_aoi': True, 'tcorrection': True, 'linear_to_db': True, 'polarisations': ['VV'], 'speckle_filter': True, 'calibration_band': ['sigma']}}. 2020-05-26 14:21:46,310 - up42.workflow - INFO - Created and running new job: 2e0e9cf0-8d80-439a-bc50-179543641ea9. 2020-05-26 14:21:46,734 - up42.job - INFO - Tracking job status continuously, reporting every 30 seconds... 2020-05-26 14:22:21,006 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:23:06,480 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:23:40,185 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:24:13,848 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:24:47,455 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:25:21,147 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:25:54,825 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:26:28,527 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:27:02,484 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:27:36,284 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:28:09,935 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:28:42,827 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:29:15,409 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:29:48,015 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:30:20,694 - up42.job - INFO - Job finished successfully! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 Visualize the results \u00b6 In [12]: # Download results: job . download_results () # Visualize downloaded results job . plot_results () Next processing steps \u00b6 The output of the workflow is a GeoTIFF file which can be processed by different algorithms. It is for example possible to apply raster tiling and then do some machine learning based analysis at the end.","title":"Radar processing"},{"location":"examples/radar_processing_1/#example-radar-processing","text":"The processing of radar data - often referred to as SAR data, which stands for Synthetice Aperture Radar - is a topic of its own and quite different from optical data that uses Red, Green, Blue, NIR and similar bands. This is the first of a series of jupyter notebooks where example SAR workflows will be explained that can be run on UP42. All of the examples are based on a specific type of analysis which is called polarimetry and processes one image at a time. In comparison to polarimetric there also is interferometric analysis which leverages the information encoded in suitable pairs of radar image. In this notebook we want to have a look at the Sentinel-1 GRD full scene block, followed by SNAP Sentinel-1 Polarimetric Processing. Polarimetric SAR Processing turns a Sentinel-1 GRD image into a multichannel GeoTIFF that is ready for analysis. Prepare workflow Define aoi and input parameters Run Job Visualize results In [1]: import up42 In [3]: # Authenticate with UP42 up42 . authenticate ( cfg_file = \"config.json\" ) #up42.authenticate(project_id=12345, project_api_key=12345) 2020-05-26 14:19:56,546 - up42.auth - INFO - Got credentials from config file. 2020-05-26 14:19:57,155 - up42.auth - INFO - Authentication with UP42 successful!","title":"Example: Radar processing"},{"location":"examples/radar_processing_1/#prepare-up42-workflows","text":"Create a new project on UP42 or use an existing one. In [5]: S1_SNAP_project = up42 . initialize_project () 2020-05-26 14:20:10,960 - up42 - INFO - Working on Project with project_id d3ea9123-2b89-4975-be16-e978fed8329c Create workflow and check available blocks and data In [6]: workflow = S1_SNAP_project . create_workflow ( name = \"S1-GRD_SNAP\" , use_existing = True ) print ( up42 . get_blocks ( basic = True )) 2020-05-26 14:20:14,765 - up42.project - INFO - Getting existing workflows in project ... 2020-05-26 14:20:15,434 - up42.project - INFO - Got 12 workflows for project d3ea9123-2b89-4975-be16-e978fed8329c. 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 12/12 [00:07<00:00, 1.52it/s] 2020-05-26 14:20:23,341 - up42.project - INFO - Using existing workflow: S1-GRD_SNAP, 1585a205-3907-4905-bd02-057a17c3cf84. 2020-05-26 14:20:24,728 - up42.tools - INFO - Getting blocks name and id, use basic=False for all block details. {'tiling': 'd350aa0b-ac31-4021-bbe6-fd8da366740a', 'oneatlas-spot-aoiclipped': '0f15e07f-efcc-4598-939b-18aade349c57', 'oneatlas-pleiades-aoiclipped': 'f026874d-e95e-4293-b811-7667130e054d', 'sobloo-s1-grd-fullscene': '4524e2de-c780-488d-9818-fe68dad9f095', 'sobloo-s2-l1c-fullscene': '604988cb-8252-4161-bf28-f6fb63d7371c', 'snap-polarimetric': '320158d6-8f93-4484-a828-e1fb64f677ff', 'sentinelhub-s2-aoiclipped': 'c4758545-4b74-4318-ae1f-d5ba72f234ca', 'sentinelhub-landsat8-aoiclipped': 'e0b133ae-7b9c-435c-99ac-c4527cc8d9cf', 'sobloo-s1-slc-fullscene': 'cf822545-c73c-467b-8f43-5311dbefe03f', 'nasa-modis': '61279eb8-02e1-4b7a-ac3d-1f62d19d3484', 's2-superresolution': '4872fef8-aec8-4dec-adcb-560ee4430a2b', 'oneatlas-pleiades-fullscene': '8487adcd-a4d7-4cb7-b826-75a533e1f330', 'oneatlas-spot-fullscene': 'aa62113f-0dd1-40a3-a004-954c9d087071', 'data-conversion': '470eedda-5f62-433c-8562-98eb8783af87', 'pansharpen': '2f24c662-c129-409f-a7c3-afa16a4c78cb', 'sobloo-s1-grd-aoiclipped': 'a956166f-c0ed-4670-8a43-87bed8d222f3', 'hello-world': '77899bd0-40de-4aa7-b67e-513a5655afcb', 'ndvi': 'aecb81ef-1c92-4b2e-aa25-55ccebe2f90a', 'sobloo-s2-l1c-aoiclipped': 'a2daaab4-196d-4226-a018-a810444dcad1', 'sobloo-s3': 'fee13ec1-a067-4d6a-95dc-a4fef458f4f4', 'sobloo-s5p': 'cba7c59b-548d-48bf-8920-c20d7d316dfd', 'kmeans-clustering': 'adf21e0a-98bf-41a9-a2cc-a59898a461ba', 'vectorising': '295bf286-0748-474f-aa38-c1ac35151204', 'crs-conversion': '18e6772f-cf33-4955-b7e4-61df8a108fd9', 'sharpening': '4ed70368-d4e1-4462-bef6-14e768049471', 'zonal-statistics': 'a5b8b938-6fd6-4bac-92cd-dffd7f3169aa', 'superresolution': '6c914299-7203-40ad-9b89-de0b4e827bd0', 's5p-lvl3': '9a593e06-eca0-49e0-8b8c-6fe95f699f9d', 'hexagon-aerial-30cm': '0b04d9f7-3a8e-4467-9fb8-1e8343c9469a', 'hexagon-aerial-15cm': '36fe7d3a-4671-424b-bd54-918dd21cfde1', 'ship-identification': '20a3bd1e-3f27-40cf-9915-8fa3d5024ade', 'ais-hvp': '7394287a-2458-4204-be62-36b6d264bcfe', 'ais-hvt': '67eb1763-abeb-4188-b135-f6a0d669d759', 'meteomatics': 'ed0beedb-111b-4285-aa2d-f876a4c16a32', 'oneatlas-pleiades-primary': 'd1e5e0de-71fa-4488-9c0e-3f22ac74a2b6', 'tiled-k-means': '45c0284a-5cd7-4bc0-9d6c-db05f7271036', 'data-conversion-netcdf': 'c358d5af-7819-4ecf-b8b3-629d5d3ba319', 'data-conversion-dimap': '25f42430-d108-4ea4-a81d-2c2b3fff7d11', 'aws-s2-l2a': '73f1b9e0-83de-4cbd-addf-5e0d23ed65d4', 'nextmapone-3m': '56a0ac08-69a5-491a-993d-63e3b9da315c', 'nextmapone-6m': 'f87dd9f3-fc14-48b1-b77d-d695fb65fcc4', 'nextmapone-1m': 'bfd43fbc-b662-4874-9147-658a55bf9edc'} In [7]: # Fill the workflow with tasks input_tasks = [ 'sobloo-s1-grd-fullscene' , 'snap-polarimetric' ] workflow . add_workflow_tasks ( input_tasks = input_tasks ) workflow . get_parameters_info () 2020-05-26 14:21:03,273 - up42.workflow - INFO - Added tasks to workflow: [{'name': 'sobloo-s1-grd-fullscene:1', 'parentName': None, 'blockId': '4524e2de-c780-488d-9818-fe68dad9f095'}, {'name': 'snap-polarimetric:1', 'parentName': 'sobloo-s1-grd-fullscene:1', 'blockId': '320158d6-8f93-4484-a828-e1fb64f677ff'}] 2020-05-26 14:21:04,000 - up42.workflow - INFO - Got 2 tasks/blocks in workflow 1585a205-3907-4905-bd02-057a17c3cf84. Out[7]: {'sobloo-s1-grd-fullscene:1': {'ids': {'type': 'array', 'default': None}, 'bbox': {'type': 'array', 'default': None}, 'time': {'type': 'dateRange', 'default': '2018-01-01T00:00:00+00:00/2020-12-31T23:59:59+00:00'}, 'limit': {'type': 'integer', 'default': 1, 'minimum': 1}, 'contains': {'type': 'geometry'}, 'intersects': {'type': 'geometry'}, 'time_series': {'type': 'array', 'default': None}, 'orbit_direction': {'type': 'string', 'default': None}, 'acquisition_mode': {'type': 'string', 'default': None}}, 'snap-polarimetric:1': {'bbox': {'type': 'array', 'default': None}, 'mask': {'type': 'array', 'items': {'enum': ['land', 'sea'], 'type': 'string'}, 'default': None}, 'contains': {'type': 'geometry', 'default': None}, 'intersects': {'type': 'geometry', 'default': None}, 'clip_to_aoi': {'type': 'boolean', 'default': False}, 'tcorrection': {'type': 'boolean', 'default': True}, 'linear_to_db': {'type': 'boolean', 'default': True}, 'polarisations': {'type': 'array', 'items': {'enum': ['VV', 'VH'], 'type': 'string'}, 'default': ['VV'], 'required': False, 'description': 'Requested polarisations for the output'}, 'speckle_filter': {'type': 'boolean', 'default': True}, 'calibration_band': {'type': 'array', 'default': ['sigma']}}}","title":"Prepare UP42 workflows"},{"location":"examples/radar_processing_1/#define-aoi-and-input-parameters","text":"The S1 GRD block always delivers the complete images as they are delivered in SAFE format which cannot be clipped. The image can be clipped though by the SNAP polarimetric processing blocks. For this it is necessary to supply the same geometry (in this case a bbox) to that block as well. In [8]: input_parameters = { \"sobloo-s1-grd-fullscene:1\" : { \"bbox\" : [ 13.371037 , 52.512799 , 13.382624 , 52.518747 ], \"ids\" : None , \"time\" : \"2018-01-01T00:00:00+00:00/2020-12-31T23:59:59+00:00\" , \"limit\" : 1 , \"zoom_level\" : 14 , }, \"snap-polarimetric:1\" : { \"bbox\" : [ 13.371037 , 52.512799 , 13.382624 , 52.518747 ], \"mask\" : None , \"contains\" : None , \"intersects\" : None , \"clip_to_aoi\" : True , \"tcorrection\" : True , \"linear_to_db\" : True , \"polarisations\" : [ \"VV\" ], \"speckle_filter\" : True , \"calibration_band\" : [ \"sigma\" ] } }","title":"Define aoi and input parameters"},{"location":"examples/radar_processing_1/#run-test-query","text":"Run a test job to query data availability and check the configuration. In [9]: test_job = workflow . test_job ( input_parameters = input_parameters , track_status = True ) test_results = test_job . get_results_json () print ( test_results ) 2020-05-26 14:21:14,155 - up42.workflow - INFO - +++++++++++++++++++++++++++++++++ 2020-05-26 14:21:14,157 - up42.workflow - INFO - Running this job as Test Query... 2020-05-26 14:21:14,157 - up42.workflow - INFO - +++++++++++++++++++++++++++++++++ 2020-05-26 14:21:14,158 - up42.workflow - INFO - Selected input_parameters: {'sobloo-s1-grd-fullscene:1': {'bbox': [13.371037, 52.512799, 13.382624, 52.518747], 'ids': None, 'time': '2018-01-01T00:00:00+00:00/2020-12-31T23:59:59+00:00', 'limit': 1, 'zoom_level': 14}, 'snap-polarimetric:1': {'bbox': [13.371037, 52.512799, 13.382624, 52.518747], 'mask': None, 'contains': None, 'intersects': None, 'clip_to_aoi': True, 'tcorrection': True, 'linear_to_db': True, 'polarisations': ['VV'], 'speckle_filter': True, 'calibration_band': ['sigma']}, 'config': {'mode': 'DRY_RUN'}}. 2020-05-26 14:21:15,659 - up42.workflow - INFO - Created and running new job: 28c72c74-a5dc-46e3-bb70-f6efad3f910c. 2020-05-26 14:21:16,144 - up42.job - INFO - Tracking job status continuously, reporting every 30 seconds... 2020-05-26 14:21:39,235 - up42.job - INFO - Job finished successfully! - 28c72c74-a5dc-46e3-bb70-f6efad3f910c 2020-05-26 14:21:44,956 - up42.job - INFO - Retrieved 1 features. {'type': 'FeatureCollection', 'features': [{'type': 'Feature', 'bbox': [12.306028, 52.168652, 16.66515, 54.078037], 'id': '5a0bcc6b-8316-45c9-9106-8de8e27e5753', 'geometry': {'type': 'Polygon', 'coordinates': [[[16.151102, 52.168652], [16.66515, 53.660217], [12.685362, 54.078037], [12.306028, 52.5835], [16.151102, 52.168652]]]}, 'properties': {'attachments': [], 'visibility': {'deleted': False}, 'illumination': {}, 'production': {'levelCode': 'L1', 'ongoing': False, 'timeliness': 'Fast-24h'}, 'archive': {'offLine': False, 'filename': 'S1A_IW_GRDH_1SDV_20200525T051659_20200525T051724_032717_03CA2F_DB50.SAFE', 'size': 1689, 'format': 'SAFE', 'onLine': False}, 'spatialCoverage': {'verticality': {}, 'geometry': {'geographicBoundingPolygon': {'coordinates': [[[16.151102, 52.168652], [16.66515, 53.660217], [12.685362, 54.078037], [12.306028, 52.5835], [16.151102, 52.168652]]], 'type': 'Polygon'}, 'global': False, 'centerPoint': {'lon': 14.45556570632881, 'lat': 53.12652491313295}}}, 'quality': {'qualified': False}, 'target': {}, 'timeStamp': 1590383819131, 'uid': '5a0bcc6b-8316-45c9-9106-8de8e27e5753', 'identification': {'profile': 'Image', 'externalId': 'S1A_IW_GRDH_1SDV_20200525T051659_20200525T051724_032717_03CA2F_DB50', 'collection': 'Sentinel-1', 'type': 'GRD', 'dataset': {}}, 'transmission': {}, 'contentDescription': {}, 'provider': {}, 'acquisition': {'endViewingDate': 1590383844129, 'mission': 'Sentinel-1', 'missionId': 'A', 'missionCode': 'S1A', 'beginViewingDate': 1590383819131, 'missionName': 'Sentinel-1A', 'polarization': 'VV VH', 'type': 'NOMINAL', 'sensorMode': 'IW', 'sensorId': 'SAR-C SAR'}, 'orbit': {'relativeNumber': 95, 'lastRelativeNumber': 95, 'lastNumber': 32717, 'direction': 'DESCENDING'}, 'state': {'resources': {'thumbnail': True, 'quicklook': True}, 'services': {'wmts': False, 'download': 'internal', 'wcs': False, 'wms': False}, 'insertionDate': 1590395388355}, 'attitude': {}}}]}","title":"Run test query"},{"location":"examples/radar_processing_1/#run-the-job","text":"In [10]: job = workflow . run_job ( input_parameters = input_parameters , track_status = True ) 2020-05-26 14:21:44,963 - up42.workflow - INFO - Selected input_parameters: {'sobloo-s1-grd-fullscene:1': {'bbox': [13.371037, 52.512799, 13.382624, 52.518747], 'ids': None, 'time': '2018-01-01T00:00:00+00:00/2020-12-31T23:59:59+00:00', 'limit': 1, 'zoom_level': 14}, 'snap-polarimetric:1': {'bbox': [13.371037, 52.512799, 13.382624, 52.518747], 'mask': None, 'contains': None, 'intersects': None, 'clip_to_aoi': True, 'tcorrection': True, 'linear_to_db': True, 'polarisations': ['VV'], 'speckle_filter': True, 'calibration_band': ['sigma']}}. 2020-05-26 14:21:46,310 - up42.workflow - INFO - Created and running new job: 2e0e9cf0-8d80-439a-bc50-179543641ea9. 2020-05-26 14:21:46,734 - up42.job - INFO - Tracking job status continuously, reporting every 30 seconds... 2020-05-26 14:22:21,006 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:23:06,480 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:23:40,185 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:24:13,848 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:24:47,455 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:25:21,147 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:25:54,825 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:26:28,527 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:27:02,484 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:27:36,284 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:28:09,935 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:28:42,827 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:29:15,409 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:29:48,015 - up42.job - INFO - Job is RUNNING! - 2e0e9cf0-8d80-439a-bc50-179543641ea9 2020-05-26 14:30:20,694 - up42.job - INFO - Job finished successfully! - 2e0e9cf0-8d80-439a-bc50-179543641ea9","title":"Run the job"},{"location":"examples/radar_processing_1/#visualize-the-results","text":"In [12]: # Download results: job . download_results () # Visualize downloaded results job . plot_results ()","title":"Visualize the results"},{"location":"examples/radar_processing_1/#next-processing-steps","text":"The output of the workflow is a GeoTIFF file which can be processed by different algorithms. It is for example possible to apply raster tiling and then do some machine learning based analysis at the end.","title":"Next processing steps"},{"location":"reference/catalog/","text":"Catalog class \u00b6 The Catalog class enables access to the UP42 catalog search. You can search for satellite image scenes (for different sensors and criteria like cloud cover), plot the scene coverage and download and plot the scene quicklooks. \u00b6 construct_parameters ( geometry , start_date = '2020-01-01' , end_date = '2020-01-30' , sensors = [ 'pleiades' , 'spot' , 'sentinel1' , 'sentinel2' , 'sentinel3' , 'sentinel5p' ], limit = 10 , max_cloudcover = 100 , sortby = 'acquisitionDate' , ascending = True ) staticmethod \u00b6 Follows STAC principles and property names. Parameters: Name Type Description Default geometry Union[Dict, geojson.feature.Feature, geojson.feature.FeatureCollection, List, geopandas.geodataframe.GeoDataFrame, shapely.geometry.point.Point, shapely.geometry.polygon.Polygon] The search geometry, one of Dict, Feature, FeatureCollection, List, GeoDataFrame, Point, Polygon. required start_date str Query period starting day, format \"2020-01-01\". '2020-01-01' end_date str Query period ending day, format \"2020-01-01\". '2020-01-30' sensors List[str] The satellite sensors to search for, one or multiple of [\"pleiades\", \"spot\", \"sentinel1\", \"sentinel2\", \"sentinel3\", \"sentinel5p\"] ['pleiades', 'spot', 'sentinel1', 'sentinel2', 'sentinel3', 'sentinel5p'] limit int The maximum number of search results to return (1-max.500). 10 max_cloudcover float Maximum cloudcover % - e.g. 100 will return all scenes, 8.4 will return all scenes with 8.4 or less cloudcover. Ignored for sensors that have no cloudcover (e.g. sentinel1). 100 sortby str The property to sort by, \"cloudCoverage\", \"acquisitionDate\", \"acquisitionIdentifier\", \"incidenceAngle\", \"snowCover\". 'acquisitionDate' ascending bool Ascending sort order by default, descending if False. True Returns: Type Description Dict The constructed parameters dictionary. Source code in up42/catalog.py @staticmethod def construct_parameters ( geometry : Union [ Dict , Feature , FeatureCollection , List , GeoDataFrame , Point , Polygon , ], start_date : str = \"2020-01-01\" , end_date : str = \"2020-01-30\" , sensors : List [ str ] = [ \"pleiades\" , \"spot\" , \"sentinel1\" , \"sentinel2\" , \"sentinel3\" , \"sentinel5p\" , ], limit : int = 10 , max_cloudcover : float = 100 , sortby : str = \"acquisitionDate\" , ascending : bool = True , ) -> Dict : \"\"\" Follows STAC principles and property names. Args: geometry: The search geometry, one of Dict, Feature, FeatureCollection, List, GeoDataFrame, Point, Polygon. start_date: Query period starting day, format \"2020-01-01\". end_date: Query period ending day, format \"2020-01-01\". sensors: The satellite sensors to search for, one or multiple of [\"pleiades\", \"spot\", \"sentinel1\", \"sentinel2\", \"sentinel3\", \"sentinel5p\"] limit: The maximum number of search results to return (1-max.500). max_cloudcover: Maximum cloudcover % - e.g. 100 will return all scenes, 8.4 will return all scenes with 8.4 or less cloudcover. Ignored for sensors that have no cloudcover (e.g. sentinel1). sortby: The property to sort by, \"cloudCoverage\", \"acquisitionDate\", \"acquisitionIdentifier\", \"incidenceAngle\", \"snowCover\". ascending: Ascending sort order by default, descending if False. Returns: The constructed parameters dictionary. \"\"\" datetime = f \" { start_date } T00:00:00Z/ { end_date } T23:59:59Z\" block_filters : List [ str ] = [] for sensor in sensors : if sensor not in list ( supported_sensors . keys ()): raise ValueError ( f \"Currently only these sensors are supported: \" f \" { list ( supported_sensors . keys ()) } \" ) block_filters . extend ( supported_sensors [ sensor ][ \"blocks\" ]) aoi_fc = any_vector_to_fc ( vector = geometry , ) aoi_geometry = fc_to_query_geometry ( fc = aoi_fc , geometry_operation = \"intersects\" , squash_multiple_features = \"union\" , ) sort_order = \"asc\" if ascending else \"desc\" query_filters = { \"dataBlock\" : { \"in\" : block_filters }} if sensors != [ \"sentinel1\" ]: query_filters [ \"cloudCoverage\" ] = { \"lte\" : max_cloudcover } # type: ignore search_parameters = { \"datetime\" : datetime , \"intersects\" : aoi_geometry , \"limit\" : limit , \"query\" : query_filters , \"sortby\" : [{ \"field\" : f \"properties. { sortby } \" , \"direction\" : sort_order }], } return search_parameters download_quicklooks ( self , image_ids , sensor , output_directory = None ) \u00b6 Gets the quicklooks of scenes from a single sensor. After download, can be plotted via catalog.plot_quicklooks(). Parameters: Name Type Description Default image_ids List[str] List of provider image_ids e.g. [\"6dffb8be-c2ab-46e3-9c1c-6958a54e4527\"]. Access the search results id column via list(search_results.id) . required sensor str The satellite sensor of the image_ids, one of \"pleiades\", \"spot\", \"sentinel1\", \"sentinel2\", \"sentinel3\", \"sentinel5p\". required output_directory Union[str, pathlib.Path] The file output directory, defaults to the current working directory. None Returns: Type Description List[str] List of quicklook image output file paths. Source code in up42/catalog.py def download_quicklooks ( self , image_ids : List [ str ], sensor : str , output_directory : Union [ str , Path ] = None , ) -> List [ str ]: \"\"\" Gets the quicklooks of scenes from a single sensor. After download, can be plotted via catalog.plot_quicklooks(). Args: image_ids: List of provider image_ids e.g. [\"6dffb8be-c2ab-46e3-9c1c-6958a54e4527\"]. Access the search results id column via `list(search_results.id)`. sensor: The satellite sensor of the image_ids, one of \"pleiades\", \"spot\", \"sentinel1\", \"sentinel2\", \"sentinel3\", \"sentinel5p\". output_directory: The file output directory, defaults to the current working directory. Returns: List of quicklook image output file paths. \"\"\" if sensor not in list ( supported_sensors . keys ()): raise ValueError ( f \"Currently only these sensors are supported: \" f \" { list ( supported_sensors . keys ()) } \" ) provider = supported_sensors [ sensor ][ \"provider\" ] logger . info ( f \"Getting quicklooks from provider { provider } for image_ids: \" f \" { image_ids } \" ) if output_directory is None : output_directory = Path . cwd () / f \"project_ { self . auth . project_id } /catalog\" else : output_directory = Path ( output_directory ) output_directory . mkdir ( parents = True , exist_ok = True ) logger . info ( f \"Download directory: { str ( output_directory ) } \" ) if isinstance ( image_ids , str ): image_ids = [ image_ids ] out_paths : List [ str ] = [] for image_id in tqdm ( image_ids ): try : url = f \" { self . auth . _endpoint () } /catalog/ { provider } /image/ { image_id } /quicklook\" response = self . auth . _request ( request_type = \"GET\" , url = url , return_text = False ) out_path = output_directory / f \"quicklook_ { image_id } .jpg\" out_paths . append ( str ( out_path )) with open ( out_path , \"wb\" ) as dst : for chunk in response : dst . write ( chunk ) except ValueError : logger . warning ( f \"Image with id { image_id } does not have quicklook available. Skipping ...\" ) self . quicklooks = out_paths # pylint: disable=attribute-defined-outside-init return out_paths search ( self , search_parameters , as_dataframe = True ) \u00b6 Searches the catalog for the the search parameters and returns the metadata of the matching scenes. Parameters: Name Type Description Default search_parameters Dict The catalog search parameters, see example. required as_dataframe bool return type, GeoDataFrame if True (default), FeatureCollection if False. True Returns: Type Description Union[geopandas.geodataframe.GeoDataFrame, Dict] The search results as a GeoDataFrame, optionally as json dict. Examples: search_parameters = { \"datetime\" : \"2019-01-01T00:00:00Z/2019-01-15T23:59:59Z\" , \"intersects\" : { \"type\" : \"Polygon\" , \"coordinates\" : [[[ 13.32113746 , 52.73971768 ],[ 13.15981158 , 52.2092959 ], [ 13.62204483 , 52.15632025 ],[ 13.78859517 , 52.68655119 ],[ 13.32113746 , 52.73971768 ]]]}, \"limit\" : 10 , \"sortby\" : [{ \"field\" : \"properties.acquisitionDate\" , \"direction\" : \"asc\" }] } Source code in up42/catalog.py def search ( self , search_parameters : Dict , as_dataframe : bool = True ) -> Union [ GeoDataFrame , Dict ]: \"\"\" Searches the catalog for the the search parameters and returns the metadata of the matching scenes. Args: search_parameters: The catalog search parameters, see example. as_dataframe: return type, GeoDataFrame if True (default), FeatureCollection if False. Returns: The search results as a GeoDataFrame, optionally as json dict. Example: ```python search_parameters={ \"datetime\": \"2019-01-01T00:00:00Z/2019-01-15T23:59:59Z\", \"intersects\": { \"type\": \"Polygon\", \"coordinates\": [[[13.32113746,52.73971768],[13.15981158,52.2092959], [13.62204483,52.15632025],[13.78859517,52.68655119],[13.32113746, 52.73971768]]]}, \"limit\": 10, \"sortby\": [{\"field\" : \"properties.acquisitionDate\", \"direction\" : \"asc\"}] } ``` \"\"\" logger . info ( f \"Searching catalog with search_parameters: { search_parameters } \" ) url = f \" { self . auth . _endpoint () } /catalog/stac/search\" response_json = self . auth . _request ( \"POST\" , url , search_parameters ) logger . info ( f \" { len ( response_json [ 'features' ]) } results returned.\" ) dst_crs = \"EPSG:4326\" df = GeoDataFrame . from_features ( response_json , crs = dst_crs ) if df . empty : if as_dataframe : return df else : return df . __geo_interface__ # Filter to actual geometries intersecting the aoi (Sobloo search uses a rectangular # bounds geometry, can contain scenes that touch the aoi bbox, but not the aoi. # So number returned images not consistent with set limit. # TODO: Resolve on backend geometry = search_parameters [ \"intersects\" ] poly = shape ( geometry ) df = df [ df . intersects ( poly )] df = df . reset_index ( drop = True ) # Make scene_id more easily accessible def _get_scene_id ( row ): if row [ \"providerName\" ] == \"oneatlas\" : row [ \"scene_id\" ] = row [ \"providerProperties\" ][ \"parentIdentifier\" ] elif row [ \"providerName\" ] in [ \"sobloo-radar\" , \"sobloo-image\" ]: row [ \"scene_id\" ] = row [ \"providerProperties\" ][ \"identification\" ][ \"externalId\" ] return row # Search result dataframe can contain scenes of multiple sensors, need to apply row by row. df = df . apply ( _get_scene_id , axis = 1 ) df . crs = dst_crs # apply resets the crs if as_dataframe : return df else : return df . __geo_interface__","title":"Catalog"},{"location":"reference/catalog/#catalog-class","text":"The Catalog class enables access to the UP42 catalog search. You can search for satellite image scenes (for different sensors and criteria like cloud cover), plot the scene coverage and download and plot the scene quicklooks.","title":"Catalog class"},{"location":"reference/catalog/#up42.catalog.Catalog","text":"","title":"up42.catalog.Catalog"},{"location":"reference/catalog/#up42.catalog.Catalog.construct_parameters","text":"Follows STAC principles and property names. Parameters: Name Type Description Default geometry Union[Dict, geojson.feature.Feature, geojson.feature.FeatureCollection, List, geopandas.geodataframe.GeoDataFrame, shapely.geometry.point.Point, shapely.geometry.polygon.Polygon] The search geometry, one of Dict, Feature, FeatureCollection, List, GeoDataFrame, Point, Polygon. required start_date str Query period starting day, format \"2020-01-01\". '2020-01-01' end_date str Query period ending day, format \"2020-01-01\". '2020-01-30' sensors List[str] The satellite sensors to search for, one or multiple of [\"pleiades\", \"spot\", \"sentinel1\", \"sentinel2\", \"sentinel3\", \"sentinel5p\"] ['pleiades', 'spot', 'sentinel1', 'sentinel2', 'sentinel3', 'sentinel5p'] limit int The maximum number of search results to return (1-max.500). 10 max_cloudcover float Maximum cloudcover % - e.g. 100 will return all scenes, 8.4 will return all scenes with 8.4 or less cloudcover. Ignored for sensors that have no cloudcover (e.g. sentinel1). 100 sortby str The property to sort by, \"cloudCoverage\", \"acquisitionDate\", \"acquisitionIdentifier\", \"incidenceAngle\", \"snowCover\". 'acquisitionDate' ascending bool Ascending sort order by default, descending if False. True Returns: Type Description Dict The constructed parameters dictionary. Source code in up42/catalog.py @staticmethod def construct_parameters ( geometry : Union [ Dict , Feature , FeatureCollection , List , GeoDataFrame , Point , Polygon , ], start_date : str = \"2020-01-01\" , end_date : str = \"2020-01-30\" , sensors : List [ str ] = [ \"pleiades\" , \"spot\" , \"sentinel1\" , \"sentinel2\" , \"sentinel3\" , \"sentinel5p\" , ], limit : int = 10 , max_cloudcover : float = 100 , sortby : str = \"acquisitionDate\" , ascending : bool = True , ) -> Dict : \"\"\" Follows STAC principles and property names. Args: geometry: The search geometry, one of Dict, Feature, FeatureCollection, List, GeoDataFrame, Point, Polygon. start_date: Query period starting day, format \"2020-01-01\". end_date: Query period ending day, format \"2020-01-01\". sensors: The satellite sensors to search for, one or multiple of [\"pleiades\", \"spot\", \"sentinel1\", \"sentinel2\", \"sentinel3\", \"sentinel5p\"] limit: The maximum number of search results to return (1-max.500). max_cloudcover: Maximum cloudcover % - e.g. 100 will return all scenes, 8.4 will return all scenes with 8.4 or less cloudcover. Ignored for sensors that have no cloudcover (e.g. sentinel1). sortby: The property to sort by, \"cloudCoverage\", \"acquisitionDate\", \"acquisitionIdentifier\", \"incidenceAngle\", \"snowCover\". ascending: Ascending sort order by default, descending if False. Returns: The constructed parameters dictionary. \"\"\" datetime = f \" { start_date } T00:00:00Z/ { end_date } T23:59:59Z\" block_filters : List [ str ] = [] for sensor in sensors : if sensor not in list ( supported_sensors . keys ()): raise ValueError ( f \"Currently only these sensors are supported: \" f \" { list ( supported_sensors . keys ()) } \" ) block_filters . extend ( supported_sensors [ sensor ][ \"blocks\" ]) aoi_fc = any_vector_to_fc ( vector = geometry , ) aoi_geometry = fc_to_query_geometry ( fc = aoi_fc , geometry_operation = \"intersects\" , squash_multiple_features = \"union\" , ) sort_order = \"asc\" if ascending else \"desc\" query_filters = { \"dataBlock\" : { \"in\" : block_filters }} if sensors != [ \"sentinel1\" ]: query_filters [ \"cloudCoverage\" ] = { \"lte\" : max_cloudcover } # type: ignore search_parameters = { \"datetime\" : datetime , \"intersects\" : aoi_geometry , \"limit\" : limit , \"query\" : query_filters , \"sortby\" : [{ \"field\" : f \"properties. { sortby } \" , \"direction\" : sort_order }], } return search_parameters","title":"construct_parameters()"},{"location":"reference/catalog/#up42.catalog.Catalog.download_quicklooks","text":"Gets the quicklooks of scenes from a single sensor. After download, can be plotted via catalog.plot_quicklooks(). Parameters: Name Type Description Default image_ids List[str] List of provider image_ids e.g. [\"6dffb8be-c2ab-46e3-9c1c-6958a54e4527\"]. Access the search results id column via list(search_results.id) . required sensor str The satellite sensor of the image_ids, one of \"pleiades\", \"spot\", \"sentinel1\", \"sentinel2\", \"sentinel3\", \"sentinel5p\". required output_directory Union[str, pathlib.Path] The file output directory, defaults to the current working directory. None Returns: Type Description List[str] List of quicklook image output file paths. Source code in up42/catalog.py def download_quicklooks ( self , image_ids : List [ str ], sensor : str , output_directory : Union [ str , Path ] = None , ) -> List [ str ]: \"\"\" Gets the quicklooks of scenes from a single sensor. After download, can be plotted via catalog.plot_quicklooks(). Args: image_ids: List of provider image_ids e.g. [\"6dffb8be-c2ab-46e3-9c1c-6958a54e4527\"]. Access the search results id column via `list(search_results.id)`. sensor: The satellite sensor of the image_ids, one of \"pleiades\", \"spot\", \"sentinel1\", \"sentinel2\", \"sentinel3\", \"sentinel5p\". output_directory: The file output directory, defaults to the current working directory. Returns: List of quicklook image output file paths. \"\"\" if sensor not in list ( supported_sensors . keys ()): raise ValueError ( f \"Currently only these sensors are supported: \" f \" { list ( supported_sensors . keys ()) } \" ) provider = supported_sensors [ sensor ][ \"provider\" ] logger . info ( f \"Getting quicklooks from provider { provider } for image_ids: \" f \" { image_ids } \" ) if output_directory is None : output_directory = Path . cwd () / f \"project_ { self . auth . project_id } /catalog\" else : output_directory = Path ( output_directory ) output_directory . mkdir ( parents = True , exist_ok = True ) logger . info ( f \"Download directory: { str ( output_directory ) } \" ) if isinstance ( image_ids , str ): image_ids = [ image_ids ] out_paths : List [ str ] = [] for image_id in tqdm ( image_ids ): try : url = f \" { self . auth . _endpoint () } /catalog/ { provider } /image/ { image_id } /quicklook\" response = self . auth . _request ( request_type = \"GET\" , url = url , return_text = False ) out_path = output_directory / f \"quicklook_ { image_id } .jpg\" out_paths . append ( str ( out_path )) with open ( out_path , \"wb\" ) as dst : for chunk in response : dst . write ( chunk ) except ValueError : logger . warning ( f \"Image with id { image_id } does not have quicklook available. Skipping ...\" ) self . quicklooks = out_paths # pylint: disable=attribute-defined-outside-init return out_paths","title":"download_quicklooks()"},{"location":"reference/catalog/#up42.catalog.Catalog.search","text":"Searches the catalog for the the search parameters and returns the metadata of the matching scenes. Parameters: Name Type Description Default search_parameters Dict The catalog search parameters, see example. required as_dataframe bool return type, GeoDataFrame if True (default), FeatureCollection if False. True Returns: Type Description Union[geopandas.geodataframe.GeoDataFrame, Dict] The search results as a GeoDataFrame, optionally as json dict. Examples: search_parameters = { \"datetime\" : \"2019-01-01T00:00:00Z/2019-01-15T23:59:59Z\" , \"intersects\" : { \"type\" : \"Polygon\" , \"coordinates\" : [[[ 13.32113746 , 52.73971768 ],[ 13.15981158 , 52.2092959 ], [ 13.62204483 , 52.15632025 ],[ 13.78859517 , 52.68655119 ],[ 13.32113746 , 52.73971768 ]]]}, \"limit\" : 10 , \"sortby\" : [{ \"field\" : \"properties.acquisitionDate\" , \"direction\" : \"asc\" }] } Source code in up42/catalog.py def search ( self , search_parameters : Dict , as_dataframe : bool = True ) -> Union [ GeoDataFrame , Dict ]: \"\"\" Searches the catalog for the the search parameters and returns the metadata of the matching scenes. Args: search_parameters: The catalog search parameters, see example. as_dataframe: return type, GeoDataFrame if True (default), FeatureCollection if False. Returns: The search results as a GeoDataFrame, optionally as json dict. Example: ```python search_parameters={ \"datetime\": \"2019-01-01T00:00:00Z/2019-01-15T23:59:59Z\", \"intersects\": { \"type\": \"Polygon\", \"coordinates\": [[[13.32113746,52.73971768],[13.15981158,52.2092959], [13.62204483,52.15632025],[13.78859517,52.68655119],[13.32113746, 52.73971768]]]}, \"limit\": 10, \"sortby\": [{\"field\" : \"properties.acquisitionDate\", \"direction\" : \"asc\"}] } ``` \"\"\" logger . info ( f \"Searching catalog with search_parameters: { search_parameters } \" ) url = f \" { self . auth . _endpoint () } /catalog/stac/search\" response_json = self . auth . _request ( \"POST\" , url , search_parameters ) logger . info ( f \" { len ( response_json [ 'features' ]) } results returned.\" ) dst_crs = \"EPSG:4326\" df = GeoDataFrame . from_features ( response_json , crs = dst_crs ) if df . empty : if as_dataframe : return df else : return df . __geo_interface__ # Filter to actual geometries intersecting the aoi (Sobloo search uses a rectangular # bounds geometry, can contain scenes that touch the aoi bbox, but not the aoi. # So number returned images not consistent with set limit. # TODO: Resolve on backend geometry = search_parameters [ \"intersects\" ] poly = shape ( geometry ) df = df [ df . intersects ( poly )] df = df . reset_index ( drop = True ) # Make scene_id more easily accessible def _get_scene_id ( row ): if row [ \"providerName\" ] == \"oneatlas\" : row [ \"scene_id\" ] = row [ \"providerProperties\" ][ \"parentIdentifier\" ] elif row [ \"providerName\" ] in [ \"sobloo-radar\" , \"sobloo-image\" ]: row [ \"scene_id\" ] = row [ \"providerProperties\" ][ \"identification\" ][ \"externalId\" ] return row # Search result dataframe can contain scenes of multiple sensors, need to apply row by row. df = df . apply ( _get_scene_id , axis = 1 ) df . crs = dst_crs # apply resets the crs if as_dataframe : return df else : return df . __geo_interface__","title":"search()"},{"location":"reference/cli/","text":"Command Line Interface (CLI) \u00b6 The CLI tool allows you to use the UP42 functionality from the command line. It is installed automatically with and based on the Python SDK. up42 \u00b6 Usage: up42 [OPTIONS] COMMAND [ARGS]... Options: -pid, --project-id TEXT Your project ID, get it in the Project settings in the console. -pkey, --project-api-key TEXT Your project API KEY, get in the Project settings in the console. -cfg, --config-file PATH File path to the config.json with {project_id: '...', project_api_key: '...'} --env TEXT auth \u00b6 Check authentication. Usage: up42 auth [OPTIONS] catalog \u00b6 UP42 catalog search. You can search for satellite image scenes for different sensors and criteria like cloud cover. Usage: up42 catalog [OPTIONS] COMMAND [ARGS]... construct-parameters \u00b6 Follows STAC principles and property names to create a filter for catalog search. Usage: up42 catalog construct-parameters [OPTIONS] GEOM_FILE Options: --start-date [%Y-%m-%d] Query period starting day, format '2020-01-01'. --end-date [%Y-%m-%d] Query period ending day, format '2020-01-01'. --sensors [pleiades|spot|sentinel1|sentinel2|sentinel3|sentinel5p] Imagery sensors to search for. --max-cloud-cover INTEGER RANGE Maximum cloudcover percentage. 100 will return all scenes,8.4 will return all scenes with 8.4 or less cloudcover. --limit INTEGER The maximum number of search results. search \u00b6 Searches the catalog for the search parameters and returns the metadata of the matching scenes. Generate search parameters with 'up42 catalog construct-parameters'. Usage: up42 catalog search [OPTIONS] SEARCH_PARAMETERS_JSON config \u00b6 Create a config file. Usage: up42 config [OPTIONS] Options: --env TEXT get-block-details \u00b6 Get details of block by block name. Usage: up42 get-block-details [OPTIONS] Options: -n, --block-name TEXT Block name to get details. [required] get-blocks \u00b6 Get public blocks information. Usage: up42 get-blocks [OPTIONS] Options: -t, --block-type [data|processing] Filter by block type. --basic / --full Show basic or full block information. job \u00b6 Get job status, results and more. Usage: up42 job [OPTIONS] COMMAND [ARGS]... Options: -jid, --job-id TEXT Your job ID, get it by creating a job or running 'up42 project workflow get-jobs' [required] cancel-job \u00b6 Cancel a job that is running. Usage: up42 job cancel-job [OPTIONS] download-quicklooks \u00b6 Download a job's quicklooks. Usage: up42 job download-quicklooks [OPTIONS] OUTPUT_DIRECTORY download-results \u00b6 Download and unpack the job results. Usage: up42 job download-results [OPTIONS] OUTPUT_DIRECTORY get-info \u00b6 Get information about the job. Usage: up42 job get-info [OPTIONS] get-jobtasks \u00b6 Get the individual items of the job. Usage: up42 job get-jobtasks [OPTIONS] get-jobtasks-results-json \u00b6 Convenience function to get the resulting data.json of all job tasks. Usage: up42 job get-jobtasks-results-json [OPTIONS] get-logs \u00b6 Convenience function to print or return the logs of all job tasks. Usage: up42 job get-logs [OPTIONS] get-results-json \u00b6 Get the job results data.json. Usage: up42 job get-results-json [OPTIONS] get-status \u00b6 Get the job status. Usage: up42 job get-status [OPTIONS] track-status \u00b6 Track the job status with regular time intervals. Usage: up42 job track-status [OPTIONS] Options: -i, --interval INTEGER RANGE Interval between getting job status in seconds. project \u00b6 Create and get workflows, manage project settings and more. Usage: up42 project [OPTIONS] COMMAND [ARGS]... create-workflow \u00b6 Create a workflow. Usage: up42 project create-workflow [OPTIONS] NAME get-project-settings \u00b6 Get the project settings. Usage: up42 project get-project-settings [OPTIONS] get-workflows \u00b6 Get the project workflows. Usage: up42 project get-workflows [OPTIONS] update-project-settings \u00b6 Update project settings. Usage: up42 project update-project-settings [OPTIONS] Options: --max-aoi-size INTEGER RANGE The maximum area of interest geometry size, from 1-1000 sqkm, default 10 sqkm. --max-concurrent-jobs INTEGER RANGE The maximum number of concurrent jobs, from 1-10, default 1. --number-of-images INTEGER RANGE The maximum number of images returned with each job, from 1-20, default 10. workflow-from-name \u00b6 Use a workflow from name. Usage: up42 project workflow-from-name [OPTIONS] Options: -n, --workflow-name TEXT Workflow name to use. [required] validate-manifest \u00b6 Validate a block manifest. Usage: up42 validate-manifest [OPTIONS] MANIFEST_JSON workflow \u00b6 Add workflow tasks, run a job and more. Usage: up42 workflow [OPTIONS] COMMAND [ARGS]... Options: -wid, --workflow-id TEXT Your workflow ID, get it by creating a workflow or running 'up42 project get-workflows' [required] add-workflow-tasks \u00b6 Adds or overwrites workflow tasks. - Name is arbitrary but best use the block name. Always use :1 to be able to identify the order when two times the same workflow task is used. - API by itself validates if the underlying block for the selected block-id is available. Usage: up42 workflow add-workflow-tasks [OPTIONS] INPUT_TASKS_JSON delete \u00b6 Delete the workflow. Usage: up42 workflow delete [OPTIONS] get-compatible-blocks \u00b6 Get all compatible blocks for the current workflow. Usage: up42 workflow get-compatible-blocks [OPTIONS] get-info \u00b6 Get information about the workflow. Usage: up42 workflow get-info [OPTIONS] get-jobs \u00b6 Get the jobs ran with this workflow. Usage: up42 workflow get-jobs [OPTIONS] get-parameters-info \u00b6 Get info about the parameters of each task in the workflow to make it easy to construct the desired parameters. Usage: up42 workflow get-parameters-info [OPTIONS] get-workflow-tasks \u00b6 Get the workflow tasks list (DAG). Usage: up42 workflow get-workflow-tasks [OPTIONS] Options: --basic / --full Show basic or full task information. run-job \u00b6 Creates and runs a new job. Usage: up42 workflow run-job [OPTIONS] INPUT_PARAMETERS_JSON Options: --track Track status of job in shell. test-job \u00b6 Create a run a new test job (Test Query). With this test query you will not be charged with any data or processing credits, but have a preview of the job result. Usage: up42 workflow test-job [OPTIONS] INPUT_PARAMETERS_JSON Options: --track Track status of job in shell. update-name \u00b6 Update the workflow name. Usage: up42 workflow update-name [OPTIONS] Options: -n, --workflow-name TEXT New name for the workflow. [required] --description TEXT An optional description for the workflow.","title":"CLI"},{"location":"reference/cli/#command-line-interface-cli","text":"The CLI tool allows you to use the UP42 functionality from the command line. It is installed automatically with and based on the Python SDK.","title":"Command Line Interface (CLI)"},{"location":"reference/cli/#up42","text":"Usage: up42 [OPTIONS] COMMAND [ARGS]... Options: -pid, --project-id TEXT Your project ID, get it in the Project settings in the console. -pkey, --project-api-key TEXT Your project API KEY, get in the Project settings in the console. -cfg, --config-file PATH File path to the config.json with {project_id: '...', project_api_key: '...'} --env TEXT","title":"up42"},{"location":"reference/cli/#auth","text":"Check authentication. Usage: up42 auth [OPTIONS]","title":"auth"},{"location":"reference/cli/#catalog","text":"UP42 catalog search. You can search for satellite image scenes for different sensors and criteria like cloud cover. Usage: up42 catalog [OPTIONS] COMMAND [ARGS]...","title":"catalog"},{"location":"reference/cli/#construct-parameters","text":"Follows STAC principles and property names to create a filter for catalog search. Usage: up42 catalog construct-parameters [OPTIONS] GEOM_FILE Options: --start-date [%Y-%m-%d] Query period starting day, format '2020-01-01'. --end-date [%Y-%m-%d] Query period ending day, format '2020-01-01'. --sensors [pleiades|spot|sentinel1|sentinel2|sentinel3|sentinel5p] Imagery sensors to search for. --max-cloud-cover INTEGER RANGE Maximum cloudcover percentage. 100 will return all scenes,8.4 will return all scenes with 8.4 or less cloudcover. --limit INTEGER The maximum number of search results.","title":"construct-parameters"},{"location":"reference/cli/#search","text":"Searches the catalog for the search parameters and returns the metadata of the matching scenes. Generate search parameters with 'up42 catalog construct-parameters'. Usage: up42 catalog search [OPTIONS] SEARCH_PARAMETERS_JSON","title":"search"},{"location":"reference/cli/#config","text":"Create a config file. Usage: up42 config [OPTIONS] Options: --env TEXT","title":"config"},{"location":"reference/cli/#get-block-details","text":"Get details of block by block name. Usage: up42 get-block-details [OPTIONS] Options: -n, --block-name TEXT Block name to get details. [required]","title":"get-block-details"},{"location":"reference/cli/#get-blocks","text":"Get public blocks information. Usage: up42 get-blocks [OPTIONS] Options: -t, --block-type [data|processing] Filter by block type. --basic / --full Show basic or full block information.","title":"get-blocks"},{"location":"reference/cli/#job","text":"Get job status, results and more. Usage: up42 job [OPTIONS] COMMAND [ARGS]... Options: -jid, --job-id TEXT Your job ID, get it by creating a job or running 'up42 project workflow get-jobs' [required]","title":"job"},{"location":"reference/cli/#cancel-job","text":"Cancel a job that is running. Usage: up42 job cancel-job [OPTIONS]","title":"cancel-job"},{"location":"reference/cli/#download-quicklooks","text":"Download a job's quicklooks. Usage: up42 job download-quicklooks [OPTIONS] OUTPUT_DIRECTORY","title":"download-quicklooks"},{"location":"reference/cli/#download-results","text":"Download and unpack the job results. Usage: up42 job download-results [OPTIONS] OUTPUT_DIRECTORY","title":"download-results"},{"location":"reference/cli/#get-info","text":"Get information about the job. Usage: up42 job get-info [OPTIONS]","title":"get-info"},{"location":"reference/cli/#get-jobtasks","text":"Get the individual items of the job. Usage: up42 job get-jobtasks [OPTIONS]","title":"get-jobtasks"},{"location":"reference/cli/#get-jobtasks-results-json","text":"Convenience function to get the resulting data.json of all job tasks. Usage: up42 job get-jobtasks-results-json [OPTIONS]","title":"get-jobtasks-results-json"},{"location":"reference/cli/#get-logs","text":"Convenience function to print or return the logs of all job tasks. Usage: up42 job get-logs [OPTIONS]","title":"get-logs"},{"location":"reference/cli/#get-results-json","text":"Get the job results data.json. Usage: up42 job get-results-json [OPTIONS]","title":"get-results-json"},{"location":"reference/cli/#get-status","text":"Get the job status. Usage: up42 job get-status [OPTIONS]","title":"get-status"},{"location":"reference/cli/#track-status","text":"Track the job status with regular time intervals. Usage: up42 job track-status [OPTIONS] Options: -i, --interval INTEGER RANGE Interval between getting job status in seconds.","title":"track-status"},{"location":"reference/cli/#project","text":"Create and get workflows, manage project settings and more. Usage: up42 project [OPTIONS] COMMAND [ARGS]...","title":"project"},{"location":"reference/cli/#create-workflow","text":"Create a workflow. Usage: up42 project create-workflow [OPTIONS] NAME","title":"create-workflow"},{"location":"reference/cli/#get-project-settings","text":"Get the project settings. Usage: up42 project get-project-settings [OPTIONS]","title":"get-project-settings"},{"location":"reference/cli/#get-workflows","text":"Get the project workflows. Usage: up42 project get-workflows [OPTIONS]","title":"get-workflows"},{"location":"reference/cli/#update-project-settings","text":"Update project settings. Usage: up42 project update-project-settings [OPTIONS] Options: --max-aoi-size INTEGER RANGE The maximum area of interest geometry size, from 1-1000 sqkm, default 10 sqkm. --max-concurrent-jobs INTEGER RANGE The maximum number of concurrent jobs, from 1-10, default 1. --number-of-images INTEGER RANGE The maximum number of images returned with each job, from 1-20, default 10.","title":"update-project-settings"},{"location":"reference/cli/#workflow-from-name","text":"Use a workflow from name. Usage: up42 project workflow-from-name [OPTIONS] Options: -n, --workflow-name TEXT Workflow name to use. [required]","title":"workflow-from-name"},{"location":"reference/cli/#validate-manifest","text":"Validate a block manifest. Usage: up42 validate-manifest [OPTIONS] MANIFEST_JSON","title":"validate-manifest"},{"location":"reference/cli/#workflow","text":"Add workflow tasks, run a job and more. Usage: up42 workflow [OPTIONS] COMMAND [ARGS]... Options: -wid, --workflow-id TEXT Your workflow ID, get it by creating a workflow or running 'up42 project get-workflows' [required]","title":"workflow"},{"location":"reference/cli/#add-workflow-tasks","text":"Adds or overwrites workflow tasks. - Name is arbitrary but best use the block name. Always use :1 to be able to identify the order when two times the same workflow task is used. - API by itself validates if the underlying block for the selected block-id is available. Usage: up42 workflow add-workflow-tasks [OPTIONS] INPUT_TASKS_JSON","title":"add-workflow-tasks"},{"location":"reference/cli/#delete","text":"Delete the workflow. Usage: up42 workflow delete [OPTIONS]","title":"delete"},{"location":"reference/cli/#get-compatible-blocks","text":"Get all compatible blocks for the current workflow. Usage: up42 workflow get-compatible-blocks [OPTIONS]","title":"get-compatible-blocks"},{"location":"reference/cli/#get-info_1","text":"Get information about the workflow. Usage: up42 workflow get-info [OPTIONS]","title":"get-info"},{"location":"reference/cli/#get-jobs","text":"Get the jobs ran with this workflow. Usage: up42 workflow get-jobs [OPTIONS]","title":"get-jobs"},{"location":"reference/cli/#get-parameters-info","text":"Get info about the parameters of each task in the workflow to make it easy to construct the desired parameters. Usage: up42 workflow get-parameters-info [OPTIONS]","title":"get-parameters-info"},{"location":"reference/cli/#get-workflow-tasks","text":"Get the workflow tasks list (DAG). Usage: up42 workflow get-workflow-tasks [OPTIONS] Options: --basic / --full Show basic or full task information.","title":"get-workflow-tasks"},{"location":"reference/cli/#run-job","text":"Creates and runs a new job. Usage: up42 workflow run-job [OPTIONS] INPUT_PARAMETERS_JSON Options: --track Track status of job in shell.","title":"run-job"},{"location":"reference/cli/#test-job","text":"Create a run a new test job (Test Query). With this test query you will not be charged with any data or processing credits, but have a preview of the job result. Usage: up42 workflow test-job [OPTIONS] INPUT_PARAMETERS_JSON Options: --track Track status of job in shell.","title":"test-job"},{"location":"reference/cli/#update-name","text":"Update the workflow name. Usage: up42 workflow update-name [OPTIONS] Options: -n, --workflow-name TEXT New name for the workflow. [required] --description TEXT An optional description for the workflow.","title":"update-name"},{"location":"reference/job/","text":"Job class \u00b6 The Job class provides access to the results, parameters and tasks of UP42 Jobs (Workflows that have been run as Jobs). \u00b6 is_succeeded property readonly \u00b6 Gets True if the job succeeded, False otherwise cancel_job ( self ) \u00b6 Cancels a pending or running job. Source code in up42/job.py def cancel_job ( self ) -> None : \"\"\"Cancels a pending or running job.\"\"\" url = f \" { self . auth . _endpoint () } /jobs/ { self . job_id } /cancel/\" self . auth . _request ( request_type = \"POST\" , url = url ) logger . info ( f \"Job canceled: { self . job_id } \" ) download_quicklooks ( self , output_directory = None ) \u00b6 Conveniance function that downloads the quicklooks of the data (dirst) jobtask. After download, can be plotted via job.plot_quicklooks(). Source code in up42/job.py def download_quicklooks ( self , output_directory : Union [ str , Path , None ] = None ) -> List [ str ]: \"\"\" Conveniance function that downloads the quicklooks of the data (dirst) jobtask. After download, can be plotted via job.plot_quicklooks(). \"\"\" # Currently only the first/data task produces quicklooks. logger . setLevel ( logging . CRITICAL ) data_task = self . get_jobtasks ()[ 0 ] logger . setLevel ( logging . INFO ) out_paths : List [ str ] = data_task . download_quicklooks ( # type: ignore output_directory = output_directory ) # type: ignore self . quicklooks = out_paths # pylint: disable=attribute-defined-outside-init return out_paths download_results ( self , output_directory = None , unpacking = True ) \u00b6 Downloads the job results. Unpacking the final file will happen as default. Parameters: Name Type Description Default output_directory Optional[Union[str, pathlib.Path]] The file output directory, defaults to the current working directory. None unpacking bool By default the final result which is in TAR archive format will be unpacked. True Returns: Type Description List[str] List of the downloaded results' filepaths. Source code in up42/job.py def download_results ( self , output_directory : Union [ str , Path , None ] = None , unpacking : bool = True ) -> List [ str ]: \"\"\" Downloads the job results. Unpacking the final file will happen as default. Args: output_directory: The file output directory, defaults to the current working directory. unpacking: By default the final result which is in TAR archive format will be unpacked. Returns: List of the downloaded results' filepaths. \"\"\" logger . info ( f \"Downloading results of job { self . job_id } \" ) if output_directory is None : output_directory = ( Path . cwd () / f \"project_ { self . auth . project_id } /job_ { self . job_id } \" ) else : output_directory = Path ( output_directory ) output_directory . mkdir ( parents = True , exist_ok = True ) logger . info ( f \"Download directory: { str ( output_directory ) } \" ) download_url = self . _get_download_url () if unpacking : out_filepaths = download_results_from_gcs ( download_url = download_url , output_directory = output_directory , ) else : out_filepaths = download_results_from_gcs_without_unpacking ( download_url = download_url , output_directory = output_directory , ) self . results = out_filepaths return out_filepaths get_jobtasks ( self , return_json = False ) \u00b6 Get the individual items of the job as JobTask objects or json. Parameters: Name Type Description Default return_json bool If True returns the json information of the job tasks. False Returns: Type Description Union[List[JobTask], List[Dict]] The job task objects in a list. Source code in up42/job.py def get_jobtasks ( self , return_json : bool = False ) -> Union [ List [ \"JobTask\" ], List [ Dict ]]: \"\"\" Get the individual items of the job as JobTask objects or json. Args: return_json: If True returns the json information of the job tasks. Returns: The job task objects in a list. \"\"\" url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /jobs/ { self . job_id } \" f \"/tasks/\" ) logger . info ( f \"Getting job tasks: { self . job_id } \" ) response_json = self . auth . _request ( request_type = \"GET\" , url = url ) jobtasks_json : List [ Dict ] = response_json [ \"data\" ] jobtasks = [ JobTask ( auth = self . auth , project_id = self . project_id , job_id = self . job_id , jobtask_id = task [ \"id\" ], ) for task in jobtasks_json ] if return_json : return jobtasks_json else : return jobtasks get_jobtasks_results_json ( self ) \u00b6 Convenience function to get the resulting data.json of all job tasks in a dictionary of strings. Returns: Type Description Dict The data.json of alle single job tasks. Source code in up42/job.py def get_jobtasks_results_json ( self ) -> Dict : \"\"\" Convenience function to get the resulting data.json of all job tasks in a dictionary of strings. Returns: The data.json of alle single job tasks. \"\"\" jobtasks : List [ Dict ] = self . get_jobtasks ( return_json = True ) # type: ignore jobtasks_ids = [ task [ \"id\" ] for task in jobtasks ] jobtasks_results_json = {} for jobtask_id in jobtasks_ids : url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /jobs/ { self . job_id } \" f \"/tasks/ { jobtask_id } /outputs/data-json\" ) response_json = self . auth . _request ( request_type = \"GET\" , url = url ) jobtasks_results_json [ jobtask_id ] = response_json return jobtasks_results_json get_logs ( self , as_print = True , as_return = False ) \u00b6 Convenience function to print or return the logs of all job tasks. Parameters: Name Type Description Default as_print bool Prints the logs, no return. True as_return bool Also returns the log strings. False Returns: Type Description Optional[Dict] The log strings (only if as_return was selected). Source code in up42/job.py def get_logs ( self , as_print : bool = True , as_return : bool = False ) -> Optional [ Dict ]: \"\"\" Convenience function to print or return the logs of all job tasks. Args: as_print: Prints the logs, no return. as_return: Also returns the log strings. Returns: The log strings (only if as_return was selected). \"\"\" job_logs = {} jobtasks : List [ Dict ] = self . get_jobtasks ( return_json = True ) # type: ignore jobtasks_ids = [ task [ \"id\" ] for task in jobtasks ] logger . info ( f \"Getting logs for { len ( jobtasks_ids ) } job tasks: { jobtasks_ids } \" ) if as_print : print ( f \"Printing logs of { len ( jobtasks_ids ) } JobTasks in Job with job_id \" f \" { self . job_id } : \\n \" ) for idx , jobtask_id in enumerate ( jobtasks_ids ): url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /jobs/\" f \" { self . job_id } /tasks/ { jobtask_id } /logs\" ) response_json = self . auth . _request ( request_type = \"GET\" , url = url ) job_logs [ jobtask_id ] = response_json if as_print : print ( \"----------------------------------------------------------\" ) print ( f \"JobTask { idx + 1 } with jobtask_id { jobtask_id } : \\n \" ) print ( response_json ) if as_return : return job_logs else : return None get_results_json ( self , as_dataframe = False ) \u00b6 Gets the Job results data.json. Parameters: Name Type Description Default as_dataframe bool Return type, Default Feature Collection. GeoDataFrame if True. False Returns: Type Description Union[Dict, geopandas.geodataframe.GeoDataFrame] The job data.json json. Source code in up42/job.py def get_results_json ( self , as_dataframe : bool = False ) -> Union [ Dict , GeoDataFrame ]: \"\"\" Gets the Job results data.json. Args: as_dataframe: Return type, Default Feature Collection. GeoDataFrame if True. Returns: The job data.json json. \"\"\" url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /jobs/ { self . job_id } \" f \"/outputs/data-json/\" ) response_json = self . auth . _request ( request_type = \"GET\" , url = url ) logger . info ( f \"Retrieved { len ( response_json [ 'features' ]) } features.\" ) if as_dataframe : # UP42 results are always in EPSG 4326 df = GeoDataFrame . from_features ( response_json , crs = 4326 ) return df else : return response_json get_status ( self ) \u00b6 Gets the job status. Returns: Type Description str The job status, one of \"SUCCEEDED\", \"NOT STARTED\", \"PENDING\", \"RUNNING\", \"CANCELLED\", \"CANCELLING\", \"FAILED\", \"ERROR\" Source code in up42/job.py def get_status ( self ) -> str : \"\"\" Gets the job status. Returns: The job status, one of \"SUCCEEDED\", \"NOT STARTED\", \"PENDING\", \"RUNNING\", \"CANCELLED\", \"CANCELLING\", \"FAILED\", \"ERROR\" \"\"\" info = self . _get_info () status = info [ \"status\" ] logger . info ( f \"Job is { status } \" ) return status map_results ( self , show_images = True , name_column = 'uid' , save_html = None ) \u00b6 Displays data.json, and if available, one or multiple results geotiffs. Parameters: Name Type Description Default show_images bool Shows images if True (default), only features if False. True name_column str Name of the feature property that provides the Feature/Layer name. 'uid' save_html The path for saving folium map as html file. With default None, no file is saved. None Source code in up42/job.py def map_results ( self , show_images : bool = True , name_column : str = \"uid\" , save_html = None ) -> folium . Map : \"\"\" Displays data.json, and if available, one or multiple results geotiffs. Args: show_images: Shows images if True (default), only features if False. name_column: Name of the feature property that provides the Feature/Layer name. save_html: The path for saving folium map as html file. With default None, no file is saved. \"\"\" if self . results is None : raise ValueError ( \"You first need to download the results via job.download_results()!\" ) # Add features to map. # Some blocks store vector results in an additional geojson file. json_fp = [ fp for fp in self . results if fp . endswith ( \".geojson\" )] if json_fp : json_fp = json_fp [ 0 ] else : json_fp = [ fp for fp in self . results if fp . endswith ( \".json\" )][ 0 ] df : GeoDataFrame = gpd . read_file ( json_fp ) plot_file_format = [ \".tif\" ] # Add image to map. m = _map_images ( plot_file_format = plot_file_format , result_df = df , filepaths = self . results , aoi = None , show_images = show_images , show_features = True , name_column = name_column , save_html = save_html , ) return m track_status ( self , report_time = 30 ) \u00b6 Continuously gets the job status until job has finished or failed. Internally checks every five seconds for the status, prints the log every time interval given in report_time argument. Parameters: Name Type Description Default report_time int The intervall (in seconds) when to query the job status. 30 Source code in up42/job.py def track_status ( self , report_time : int = 30 ) -> str : \"\"\" Continuously gets the job status until job has finished or failed. Internally checks every five seconds for the status, prints the log every time interval given in report_time argument. Args: report_time: The intervall (in seconds) when to query the job status. \"\"\" logger . info ( f \"Tracking job status continuously, reporting every { report_time } seconds...\" , ) status = \"NOT STARTED\" time_asleep = 0 while status != \"SUCCEEDED\" : logger . setLevel ( logging . CRITICAL ) status = self . get_status () logger . setLevel ( logging . INFO ) # TODO: Add statuses as constants (maybe objects?) if status in [ \"NOT STARTED\" , \"PENDING\" , \"RUNNING\" ]: if time_asleep != 0 and time_asleep % report_time == 0 : logger . info ( f \"Job is { status } ! - { self . job_id } \" ) elif status in [ \"FAILED\" , \"ERROR\" ]: logger . info ( f \"Job is { status } ! - { self . job_id } - Printing logs ...\" ) self . get_logs ( as_print = True ) raise ValueError ( \"Job has failed! See the above log.\" ) elif status in [ \"CANCELLED\" , \"CANCELLING\" ]: logger . info ( f \"Job is { status } ! - { self . job_id } \" ) raise ValueError ( \"Job has been cancelled!\" ) elif status == \"SUCCEEDED\" : logger . info ( f \"Job finished successfully! - { self . job_id } \" ) sleep ( 5 ) time_asleep += 5 return status upload_results_to_bucket ( self , gs_client , bucket , folder , extension = '.tgz' , version = 'v0' ) \u00b6 Uploads the results of a job directly to a custom google cloud storage bucket. Source code in up42/job.py def upload_results_to_bucket ( self , gs_client , bucket , folder , extension : str = \".tgz\" , version : str = \"v0\" ) -> None : \"\"\" Uploads the results of a job directly to a custom google cloud storage bucket. \"\"\" download_url = self . _get_download_url () r = requests . get ( download_url ) if self . order_ids is not None : blob = bucket . blob ( str ( Path ( version ) / Path ( folder ) / Path ( self . order_ids [ 0 ] + extension )) ) logger . info ( f \"Upload job { self . job_id } results with order_ids to \" f \" { blob . name } ...\" ) else : blob = bucket . blob ( str ( Path ( version ) / Path ( folder ) / Path ( self . job_id + extension )) ) logger . info ( f \"Upload job { self . job_id } results to { blob . name } ...\" ) blob . upload_from_string ( data = r . content , content_type = \"application/octet-stream\" , client = gs_client , ) logger . info ( \"Uploaded!\" )","title":"Job"},{"location":"reference/job/#job-class","text":"The Job class provides access to the results, parameters and tasks of UP42 Jobs (Workflows that have been run as Jobs).","title":"Job class"},{"location":"reference/job/#up42.job.Job","text":"","title":"up42.job.Job"},{"location":"reference/job/#up42.job.Job.is_succeeded","text":"Gets True if the job succeeded, False otherwise","title":"is_succeeded"},{"location":"reference/job/#up42.job.Job.cancel_job","text":"Cancels a pending or running job. Source code in up42/job.py def cancel_job ( self ) -> None : \"\"\"Cancels a pending or running job.\"\"\" url = f \" { self . auth . _endpoint () } /jobs/ { self . job_id } /cancel/\" self . auth . _request ( request_type = \"POST\" , url = url ) logger . info ( f \"Job canceled: { self . job_id } \" )","title":"cancel_job()"},{"location":"reference/job/#up42.job.Job.download_quicklooks","text":"Conveniance function that downloads the quicklooks of the data (dirst) jobtask. After download, can be plotted via job.plot_quicklooks(). Source code in up42/job.py def download_quicklooks ( self , output_directory : Union [ str , Path , None ] = None ) -> List [ str ]: \"\"\" Conveniance function that downloads the quicklooks of the data (dirst) jobtask. After download, can be plotted via job.plot_quicklooks(). \"\"\" # Currently only the first/data task produces quicklooks. logger . setLevel ( logging . CRITICAL ) data_task = self . get_jobtasks ()[ 0 ] logger . setLevel ( logging . INFO ) out_paths : List [ str ] = data_task . download_quicklooks ( # type: ignore output_directory = output_directory ) # type: ignore self . quicklooks = out_paths # pylint: disable=attribute-defined-outside-init return out_paths","title":"download_quicklooks()"},{"location":"reference/job/#up42.job.Job.download_results","text":"Downloads the job results. Unpacking the final file will happen as default. Parameters: Name Type Description Default output_directory Optional[Union[str, pathlib.Path]] The file output directory, defaults to the current working directory. None unpacking bool By default the final result which is in TAR archive format will be unpacked. True Returns: Type Description List[str] List of the downloaded results' filepaths. Source code in up42/job.py def download_results ( self , output_directory : Union [ str , Path , None ] = None , unpacking : bool = True ) -> List [ str ]: \"\"\" Downloads the job results. Unpacking the final file will happen as default. Args: output_directory: The file output directory, defaults to the current working directory. unpacking: By default the final result which is in TAR archive format will be unpacked. Returns: List of the downloaded results' filepaths. \"\"\" logger . info ( f \"Downloading results of job { self . job_id } \" ) if output_directory is None : output_directory = ( Path . cwd () / f \"project_ { self . auth . project_id } /job_ { self . job_id } \" ) else : output_directory = Path ( output_directory ) output_directory . mkdir ( parents = True , exist_ok = True ) logger . info ( f \"Download directory: { str ( output_directory ) } \" ) download_url = self . _get_download_url () if unpacking : out_filepaths = download_results_from_gcs ( download_url = download_url , output_directory = output_directory , ) else : out_filepaths = download_results_from_gcs_without_unpacking ( download_url = download_url , output_directory = output_directory , ) self . results = out_filepaths return out_filepaths","title":"download_results()"},{"location":"reference/job/#up42.job.Job.get_jobtasks","text":"Get the individual items of the job as JobTask objects or json. Parameters: Name Type Description Default return_json bool If True returns the json information of the job tasks. False Returns: Type Description Union[List[JobTask], List[Dict]] The job task objects in a list. Source code in up42/job.py def get_jobtasks ( self , return_json : bool = False ) -> Union [ List [ \"JobTask\" ], List [ Dict ]]: \"\"\" Get the individual items of the job as JobTask objects or json. Args: return_json: If True returns the json information of the job tasks. Returns: The job task objects in a list. \"\"\" url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /jobs/ { self . job_id } \" f \"/tasks/\" ) logger . info ( f \"Getting job tasks: { self . job_id } \" ) response_json = self . auth . _request ( request_type = \"GET\" , url = url ) jobtasks_json : List [ Dict ] = response_json [ \"data\" ] jobtasks = [ JobTask ( auth = self . auth , project_id = self . project_id , job_id = self . job_id , jobtask_id = task [ \"id\" ], ) for task in jobtasks_json ] if return_json : return jobtasks_json else : return jobtasks","title":"get_jobtasks()"},{"location":"reference/job/#up42.job.Job.get_jobtasks_results_json","text":"Convenience function to get the resulting data.json of all job tasks in a dictionary of strings. Returns: Type Description Dict The data.json of alle single job tasks. Source code in up42/job.py def get_jobtasks_results_json ( self ) -> Dict : \"\"\" Convenience function to get the resulting data.json of all job tasks in a dictionary of strings. Returns: The data.json of alle single job tasks. \"\"\" jobtasks : List [ Dict ] = self . get_jobtasks ( return_json = True ) # type: ignore jobtasks_ids = [ task [ \"id\" ] for task in jobtasks ] jobtasks_results_json = {} for jobtask_id in jobtasks_ids : url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /jobs/ { self . job_id } \" f \"/tasks/ { jobtask_id } /outputs/data-json\" ) response_json = self . auth . _request ( request_type = \"GET\" , url = url ) jobtasks_results_json [ jobtask_id ] = response_json return jobtasks_results_json","title":"get_jobtasks_results_json()"},{"location":"reference/job/#up42.job.Job.get_logs","text":"Convenience function to print or return the logs of all job tasks. Parameters: Name Type Description Default as_print bool Prints the logs, no return. True as_return bool Also returns the log strings. False Returns: Type Description Optional[Dict] The log strings (only if as_return was selected). Source code in up42/job.py def get_logs ( self , as_print : bool = True , as_return : bool = False ) -> Optional [ Dict ]: \"\"\" Convenience function to print or return the logs of all job tasks. Args: as_print: Prints the logs, no return. as_return: Also returns the log strings. Returns: The log strings (only if as_return was selected). \"\"\" job_logs = {} jobtasks : List [ Dict ] = self . get_jobtasks ( return_json = True ) # type: ignore jobtasks_ids = [ task [ \"id\" ] for task in jobtasks ] logger . info ( f \"Getting logs for { len ( jobtasks_ids ) } job tasks: { jobtasks_ids } \" ) if as_print : print ( f \"Printing logs of { len ( jobtasks_ids ) } JobTasks in Job with job_id \" f \" { self . job_id } : \\n \" ) for idx , jobtask_id in enumerate ( jobtasks_ids ): url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /jobs/\" f \" { self . job_id } /tasks/ { jobtask_id } /logs\" ) response_json = self . auth . _request ( request_type = \"GET\" , url = url ) job_logs [ jobtask_id ] = response_json if as_print : print ( \"----------------------------------------------------------\" ) print ( f \"JobTask { idx + 1 } with jobtask_id { jobtask_id } : \\n \" ) print ( response_json ) if as_return : return job_logs else : return None","title":"get_logs()"},{"location":"reference/job/#up42.job.Job.get_results_json","text":"Gets the Job results data.json. Parameters: Name Type Description Default as_dataframe bool Return type, Default Feature Collection. GeoDataFrame if True. False Returns: Type Description Union[Dict, geopandas.geodataframe.GeoDataFrame] The job data.json json. Source code in up42/job.py def get_results_json ( self , as_dataframe : bool = False ) -> Union [ Dict , GeoDataFrame ]: \"\"\" Gets the Job results data.json. Args: as_dataframe: Return type, Default Feature Collection. GeoDataFrame if True. Returns: The job data.json json. \"\"\" url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /jobs/ { self . job_id } \" f \"/outputs/data-json/\" ) response_json = self . auth . _request ( request_type = \"GET\" , url = url ) logger . info ( f \"Retrieved { len ( response_json [ 'features' ]) } features.\" ) if as_dataframe : # UP42 results are always in EPSG 4326 df = GeoDataFrame . from_features ( response_json , crs = 4326 ) return df else : return response_json","title":"get_results_json()"},{"location":"reference/job/#up42.job.Job.get_status","text":"Gets the job status. Returns: Type Description str The job status, one of \"SUCCEEDED\", \"NOT STARTED\", \"PENDING\", \"RUNNING\", \"CANCELLED\", \"CANCELLING\", \"FAILED\", \"ERROR\" Source code in up42/job.py def get_status ( self ) -> str : \"\"\" Gets the job status. Returns: The job status, one of \"SUCCEEDED\", \"NOT STARTED\", \"PENDING\", \"RUNNING\", \"CANCELLED\", \"CANCELLING\", \"FAILED\", \"ERROR\" \"\"\" info = self . _get_info () status = info [ \"status\" ] logger . info ( f \"Job is { status } \" ) return status","title":"get_status()"},{"location":"reference/job/#up42.job.Job.map_results","text":"Displays data.json, and if available, one or multiple results geotiffs. Parameters: Name Type Description Default show_images bool Shows images if True (default), only features if False. True name_column str Name of the feature property that provides the Feature/Layer name. 'uid' save_html The path for saving folium map as html file. With default None, no file is saved. None Source code in up42/job.py def map_results ( self , show_images : bool = True , name_column : str = \"uid\" , save_html = None ) -> folium . Map : \"\"\" Displays data.json, and if available, one or multiple results geotiffs. Args: show_images: Shows images if True (default), only features if False. name_column: Name of the feature property that provides the Feature/Layer name. save_html: The path for saving folium map as html file. With default None, no file is saved. \"\"\" if self . results is None : raise ValueError ( \"You first need to download the results via job.download_results()!\" ) # Add features to map. # Some blocks store vector results in an additional geojson file. json_fp = [ fp for fp in self . results if fp . endswith ( \".geojson\" )] if json_fp : json_fp = json_fp [ 0 ] else : json_fp = [ fp for fp in self . results if fp . endswith ( \".json\" )][ 0 ] df : GeoDataFrame = gpd . read_file ( json_fp ) plot_file_format = [ \".tif\" ] # Add image to map. m = _map_images ( plot_file_format = plot_file_format , result_df = df , filepaths = self . results , aoi = None , show_images = show_images , show_features = True , name_column = name_column , save_html = save_html , ) return m","title":"map_results()"},{"location":"reference/job/#up42.job.Job.track_status","text":"Continuously gets the job status until job has finished or failed. Internally checks every five seconds for the status, prints the log every time interval given in report_time argument. Parameters: Name Type Description Default report_time int The intervall (in seconds) when to query the job status. 30 Source code in up42/job.py def track_status ( self , report_time : int = 30 ) -> str : \"\"\" Continuously gets the job status until job has finished or failed. Internally checks every five seconds for the status, prints the log every time interval given in report_time argument. Args: report_time: The intervall (in seconds) when to query the job status. \"\"\" logger . info ( f \"Tracking job status continuously, reporting every { report_time } seconds...\" , ) status = \"NOT STARTED\" time_asleep = 0 while status != \"SUCCEEDED\" : logger . setLevel ( logging . CRITICAL ) status = self . get_status () logger . setLevel ( logging . INFO ) # TODO: Add statuses as constants (maybe objects?) if status in [ \"NOT STARTED\" , \"PENDING\" , \"RUNNING\" ]: if time_asleep != 0 and time_asleep % report_time == 0 : logger . info ( f \"Job is { status } ! - { self . job_id } \" ) elif status in [ \"FAILED\" , \"ERROR\" ]: logger . info ( f \"Job is { status } ! - { self . job_id } - Printing logs ...\" ) self . get_logs ( as_print = True ) raise ValueError ( \"Job has failed! See the above log.\" ) elif status in [ \"CANCELLED\" , \"CANCELLING\" ]: logger . info ( f \"Job is { status } ! - { self . job_id } \" ) raise ValueError ( \"Job has been cancelled!\" ) elif status == \"SUCCEEDED\" : logger . info ( f \"Job finished successfully! - { self . job_id } \" ) sleep ( 5 ) time_asleep += 5 return status","title":"track_status()"},{"location":"reference/job/#up42.job.Job.upload_results_to_bucket","text":"Uploads the results of a job directly to a custom google cloud storage bucket. Source code in up42/job.py def upload_results_to_bucket ( self , gs_client , bucket , folder , extension : str = \".tgz\" , version : str = \"v0\" ) -> None : \"\"\" Uploads the results of a job directly to a custom google cloud storage bucket. \"\"\" download_url = self . _get_download_url () r = requests . get ( download_url ) if self . order_ids is not None : blob = bucket . blob ( str ( Path ( version ) / Path ( folder ) / Path ( self . order_ids [ 0 ] + extension )) ) logger . info ( f \"Upload job { self . job_id } results with order_ids to \" f \" { blob . name } ...\" ) else : blob = bucket . blob ( str ( Path ( version ) / Path ( folder ) / Path ( self . job_id + extension )) ) logger . info ( f \"Upload job { self . job_id } results to { blob . name } ...\" ) blob . upload_from_string ( data = r . content , content_type = \"application/octet-stream\" , client = gs_client , ) logger . info ( \"Uploaded!\" )","title":"upload_results_to_bucket()"},{"location":"reference/jobcollection/","text":"JobCollection class \u00b6 The JobCollection class provides facilities for downloading and merging multiple jobs results. \u00b6 apply ( self , worker , only_succeeded = True , ** kwargs ) \u00b6 Helper function to apply worker on all jobs in the collection. worker needs to accept Job as first argument. For example, a lambda function that returns the job info: self . apply ( lambda job : job . _get_info ()) Parameters: Name Type Description Default worker Callable A function to apply on all jobs in the collection. required only_succeeded bool Only apply to succeeded jobs (default is True ). True kwargs additional keyword arguments to pass to worker . {} Returns: Type Description Dict[str, Any] Dictionary where the key is the job id and the value the return of worker . Source code in up42/jobcollection.py def apply ( self , worker : Callable , only_succeeded : bool = True , ** kwargs ) -> Dict [ str , Any ]: \"\"\" Helper function to apply `worker` on all jobs in the collection. `worker` needs to accept `Job` as first argument. For example, a lambda function that returns the job info: ```python self.apply(lambda job: job._get_info()) ``` Args: worker: A function to apply on all jobs in the collection. only_succeeded: Only apply to succeeded jobs (default is `True`). kwargs: additional keyword arguments to pass to `worker`. Returns: Dictionary where the key is the job id and the value the return of `worker`. \"\"\" if not self . jobs : raise ValueError ( \"This is an empty JobCollection. Cannot apply over an empty job list.\" ) out_dict = {} for job in self . jobs : if only_succeeded : if job . is_succeeded : out_dict [ job . job_id ] = worker ( job , ** kwargs ) else : out_dict [ job . job_id ] = worker ( job , ** kwargs ) if not out_dict : raise ValueError ( \"All jobs have failed! Cannot apply over an empty succeeded job list.\" ) return out_dict download_results ( self , output_directory = None , merge = True , unpacking = True ) \u00b6 Downloads the job results. The final results are individually downloaded and by default a merged data.json is generated with all the results in a single feature collection. Unpacking the final will happen as default. Parameters: Name Type Description Default output_directory Optional[Union[str, pathlib.Path]] The file output directory, defaults to the current working directory. None merge bool Wether to generate a merged data.json with all results. True unpacking bool By default the final result which is in TAR archive format will be unpacked. True Returns: Type Description Dict[str, List[str]] Dict of the job_ids and jobs' downloaded results filepaths. In addition, an additional key merged_result is added with the path to the merged data.json. Source code in up42/jobcollection.py def download_results ( self , output_directory : Union [ str , Path , None ] = None , merge : bool = True , unpacking : bool = True , ) -> Dict [ str , List [ str ]]: \"\"\" Downloads the job results. The final results are individually downloaded and by default a merged data.json is generated with all the results in a single feature collection. Unpacking the final will happen as default. Args: output_directory: The file output directory, defaults to the current working directory. merge: Wether to generate a merged data.json with all results. unpacking: By default the final result which is in TAR archive format will be unpacked. Returns: Dict of the job_ids and jobs' downloaded results filepaths. In addition, an additional key merged_result is added with the path to the merged data.json. \"\"\" if output_directory is None : output_directory = Path . cwd () / f \"project_ { self . auth . project_id } \" else : output_directory = Path ( output_directory ) def download_results_worker ( job , output_directory , unpacking ): out_dir = output_directory / f \"job_ { job . job_id } \" out_filepaths_job = job . download_results ( output_directory = out_dir , unpacking = unpacking ) return out_filepaths_job out_filepaths = self . apply ( download_results_worker , output_directory = output_directory , unpacking = unpacking , ) if merge : merged_data_json = output_directory / \"data.json\" with open ( merged_data_json , \"w\" ) as dst : out_features = [] for job_id in out_filepaths : all_files = out_filepaths [ job_id ] data_json = [ d for d in all_files if Path ( d ) . name == \"data.json\" ][ 0 ] with open ( data_json ) as src : data_json_fc = geojson . load ( src ) for feat in data_json_fc . features : feat . properties [ \"job_id\" ] = job_id try : feat . properties [ \"up42.data_path\" ] = f \"job_ { job_id } / { feat . properties [ 'up42.data_path' ] } \" except KeyError : logger . warning ( \"data.json does not contain up42.data_path, skipping...\" ) out_features . append ( feat ) geojson . dump ( FeatureCollection ( out_features ), dst ) out_filepaths [ \"merged_result\" ] = [ str ( merged_data_json )] self . results = out_filepaths return out_filepaths get_jobs_info ( self ) \u00b6 Gets the jobs information. Returns: Type Description Dict[str, Dict] A dictionary with key being the job_id and value the job information. Source code in up42/jobcollection.py def get_jobs_info ( self ) -> Dict [ str , Dict ]: \"\"\" Gets the jobs information. Returns: A dictionary with key being the job_id and value the job information. \"\"\" return self . apply ( lambda job : job . _get_info (), only_succeeded = False ) get_jobs_status ( self ) \u00b6 Gets the jobs status. Returns: Type Description Dict[str, str] A dictionary with key being the job_id and value the job status. Source code in up42/jobcollection.py def get_jobs_status ( self ) -> Dict [ str , str ]: \"\"\" Gets the jobs status. Returns: A dictionary with key being the job_id and value the job status. \"\"\" return self . apply ( lambda job : job . get_status (), only_succeeded = False )","title":"JobCollection"},{"location":"reference/jobcollection/#jobcollection-class","text":"The JobCollection class provides facilities for downloading and merging multiple jobs results.","title":"JobCollection class"},{"location":"reference/jobcollection/#up42.jobcollection.JobCollection","text":"","title":"up42.jobcollection.JobCollection"},{"location":"reference/jobcollection/#up42.jobcollection.JobCollection.apply","text":"Helper function to apply worker on all jobs in the collection. worker needs to accept Job as first argument. For example, a lambda function that returns the job info: self . apply ( lambda job : job . _get_info ()) Parameters: Name Type Description Default worker Callable A function to apply on all jobs in the collection. required only_succeeded bool Only apply to succeeded jobs (default is True ). True kwargs additional keyword arguments to pass to worker . {} Returns: Type Description Dict[str, Any] Dictionary where the key is the job id and the value the return of worker . Source code in up42/jobcollection.py def apply ( self , worker : Callable , only_succeeded : bool = True , ** kwargs ) -> Dict [ str , Any ]: \"\"\" Helper function to apply `worker` on all jobs in the collection. `worker` needs to accept `Job` as first argument. For example, a lambda function that returns the job info: ```python self.apply(lambda job: job._get_info()) ``` Args: worker: A function to apply on all jobs in the collection. only_succeeded: Only apply to succeeded jobs (default is `True`). kwargs: additional keyword arguments to pass to `worker`. Returns: Dictionary where the key is the job id and the value the return of `worker`. \"\"\" if not self . jobs : raise ValueError ( \"This is an empty JobCollection. Cannot apply over an empty job list.\" ) out_dict = {} for job in self . jobs : if only_succeeded : if job . is_succeeded : out_dict [ job . job_id ] = worker ( job , ** kwargs ) else : out_dict [ job . job_id ] = worker ( job , ** kwargs ) if not out_dict : raise ValueError ( \"All jobs have failed! Cannot apply over an empty succeeded job list.\" ) return out_dict","title":"apply()"},{"location":"reference/jobcollection/#up42.jobcollection.JobCollection.download_results","text":"Downloads the job results. The final results are individually downloaded and by default a merged data.json is generated with all the results in a single feature collection. Unpacking the final will happen as default. Parameters: Name Type Description Default output_directory Optional[Union[str, pathlib.Path]] The file output directory, defaults to the current working directory. None merge bool Wether to generate a merged data.json with all results. True unpacking bool By default the final result which is in TAR archive format will be unpacked. True Returns: Type Description Dict[str, List[str]] Dict of the job_ids and jobs' downloaded results filepaths. In addition, an additional key merged_result is added with the path to the merged data.json. Source code in up42/jobcollection.py def download_results ( self , output_directory : Union [ str , Path , None ] = None , merge : bool = True , unpacking : bool = True , ) -> Dict [ str , List [ str ]]: \"\"\" Downloads the job results. The final results are individually downloaded and by default a merged data.json is generated with all the results in a single feature collection. Unpacking the final will happen as default. Args: output_directory: The file output directory, defaults to the current working directory. merge: Wether to generate a merged data.json with all results. unpacking: By default the final result which is in TAR archive format will be unpacked. Returns: Dict of the job_ids and jobs' downloaded results filepaths. In addition, an additional key merged_result is added with the path to the merged data.json. \"\"\" if output_directory is None : output_directory = Path . cwd () / f \"project_ { self . auth . project_id } \" else : output_directory = Path ( output_directory ) def download_results_worker ( job , output_directory , unpacking ): out_dir = output_directory / f \"job_ { job . job_id } \" out_filepaths_job = job . download_results ( output_directory = out_dir , unpacking = unpacking ) return out_filepaths_job out_filepaths = self . apply ( download_results_worker , output_directory = output_directory , unpacking = unpacking , ) if merge : merged_data_json = output_directory / \"data.json\" with open ( merged_data_json , \"w\" ) as dst : out_features = [] for job_id in out_filepaths : all_files = out_filepaths [ job_id ] data_json = [ d for d in all_files if Path ( d ) . name == \"data.json\" ][ 0 ] with open ( data_json ) as src : data_json_fc = geojson . load ( src ) for feat in data_json_fc . features : feat . properties [ \"job_id\" ] = job_id try : feat . properties [ \"up42.data_path\" ] = f \"job_ { job_id } / { feat . properties [ 'up42.data_path' ] } \" except KeyError : logger . warning ( \"data.json does not contain up42.data_path, skipping...\" ) out_features . append ( feat ) geojson . dump ( FeatureCollection ( out_features ), dst ) out_filepaths [ \"merged_result\" ] = [ str ( merged_data_json )] self . results = out_filepaths return out_filepaths","title":"download_results()"},{"location":"reference/jobcollection/#up42.jobcollection.JobCollection.get_jobs_info","text":"Gets the jobs information. Returns: Type Description Dict[str, Dict] A dictionary with key being the job_id and value the job information. Source code in up42/jobcollection.py def get_jobs_info ( self ) -> Dict [ str , Dict ]: \"\"\" Gets the jobs information. Returns: A dictionary with key being the job_id and value the job information. \"\"\" return self . apply ( lambda job : job . _get_info (), only_succeeded = False )","title":"get_jobs_info()"},{"location":"reference/jobcollection/#up42.jobcollection.JobCollection.get_jobs_status","text":"Gets the jobs status. Returns: Type Description Dict[str, str] A dictionary with key being the job_id and value the job status. Source code in up42/jobcollection.py def get_jobs_status ( self ) -> Dict [ str , str ]: \"\"\" Gets the jobs status. Returns: A dictionary with key being the job_id and value the job status. \"\"\" return self . apply ( lambda job : job . get_status (), only_succeeded = False )","title":"get_jobs_status()"},{"location":"reference/jobtask/","text":"JobTask class \u00b6 The JobTask class provides access to the results and parameters of single Tasks of UP42 Jobs (each Job contains one or multiple Jobtasks, one for each block in the workflow). \u00b6 download_quicklooks ( self , output_directory = None ) \u00b6 Downloads quicklooks of the job task to disk. After download, can be plotted via jobtask.plot_quicklooks(). Parameters: Name Type Description Default output_directory Optional[Union[str, pathlib.Path]] The file output directory, defaults to the current working directory. None Returns: Type Description List[str] The quicklooks filepaths. Source code in up42/jobtask.py def download_quicklooks ( self , output_directory : Union [ str , Path , None ] = None , ) -> List [ str ]: \"\"\" Downloads quicklooks of the job task to disk. After download, can be plotted via jobtask.plot_quicklooks(). Args: output_directory: The file output directory, defaults to the current working directory. Returns: The quicklooks filepaths. \"\"\" if output_directory is None : # On purpose downloading the quicklooks to the jobs folder and not the # jobtasks folder,since only relevant for data block task. And clearer # for job.download_quicklooks. output_directory = ( Path . cwd () / f \"project_ { self . auth . project_id } \" / f \"job_ { self . job_id } \" ) else : output_directory = Path ( output_directory ) output_directory . mkdir ( parents = True , exist_ok = True ) logger . info ( f \"Download directory: { str ( output_directory ) } \" ) url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /jobs/ { self . job_id } \" f \"/tasks/ { self . jobtask_id } /outputs/quicklooks/\" ) response_json = self . auth . _request ( request_type = \"GET\" , url = url ) quicklooks_ids = response_json [ \"data\" ] out_paths : List [ str ] = [] for ql_id in tqdm ( quicklooks_ids ): out_path = output_directory / f \"quicklook_ { ql_id } \" # No suffix required. out_paths . append ( str ( out_path )) url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /jobs/ { self . job_id } \" f \"/tasks/ { self . jobtask_id } /outputs/quicklooks/ { ql_id } \" ) response = self . auth . _request ( request_type = \"GET\" , url = url , return_text = False ) with open ( out_path , \"wb\" ) as dst : for chunk in response : dst . write ( chunk ) self . quicklooks = out_paths # pylint: disable=attribute-defined-outside-init return out_paths download_results ( self , output_directory = None ) \u00b6 Downloads and unpacks the jobtask results. Default download to Desktop. Parameters: Name Type Description Default output_directory Optional[Union[str, pathlib.Path]] The file output directory, defaults to the current working directory. None Returns: Type Description List[str] List of the downloaded results' filepaths. Source code in up42/jobtask.py def download_results ( self , output_directory : Union [ str , Path , None ] = None ) -> List [ str ]: \"\"\" Downloads and unpacks the jobtask results. Default download to Desktop. Args: output_directory: The file output directory, defaults to the current working directory. Returns: List of the downloaded results' filepaths. \"\"\" logger . info ( f \"Downloading results of jobtask { self . jobtask_id } \" ) if output_directory is None : output_directory = ( Path . cwd () / f \"project_ { self . auth . project_id } /job_ { self . job_id } /jobtask_ { self . jobtask_id } \" ) else : output_directory = Path ( output_directory ) output_directory . mkdir ( parents = True , exist_ok = True ) logger . info ( f \"Download directory: { str ( output_directory ) } \" ) download_url = self . _get_download_url () out_filepaths = download_results_from_gcs ( download_url = download_url , output_directory = output_directory , ) self . results = out_filepaths return out_filepaths get_results_json ( self , as_dataframe = False ) \u00b6 Gets the Jobtask results data.json. Parameters: Name Type Description Default as_dataframe bool \"fc\" for FeatureCollection dict, \"df\" for GeoDataFrame. False Returns: Type Description Union[Dict, geopandas.geodataframe.GeoDataFrame] Json of the results, alternatively geodataframe. Source code in up42/jobtask.py def get_results_json ( self , as_dataframe : bool = False ) -> Union [ Dict , GeoDataFrame ]: \"\"\" Gets the Jobtask results data.json. Args: as_dataframe: \"fc\" for FeatureCollection dict, \"df\" for GeoDataFrame. Returns: Json of the results, alternatively geodataframe. \"\"\" url = ( f \" { self . auth . _endpoint () } /projects/ { self . auth . project_id } /jobs/ { self . job_id } \" f \"/tasks/ { self . jobtask_id } /outputs/data-json/\" ) response_json = self . auth . _request ( request_type = \"GET\" , url = url ) logger . info ( f \"Retrieved { len ( response_json [ 'features' ]) } features.\" ) if as_dataframe : # UP42 results are always in EPSG 4326 df = GeoDataFrame . from_features ( response_json , crs = 4326 ) return df else : return response_json","title":"JobTask"},{"location":"reference/jobtask/#jobtask-class","text":"The JobTask class provides access to the results and parameters of single Tasks of UP42 Jobs (each Job contains one or multiple Jobtasks, one for each block in the workflow).","title":"JobTask class"},{"location":"reference/jobtask/#up42.jobtask.JobTask","text":"","title":"up42.jobtask.JobTask"},{"location":"reference/jobtask/#up42.jobtask.JobTask.download_quicklooks","text":"Downloads quicklooks of the job task to disk. After download, can be plotted via jobtask.plot_quicklooks(). Parameters: Name Type Description Default output_directory Optional[Union[str, pathlib.Path]] The file output directory, defaults to the current working directory. None Returns: Type Description List[str] The quicklooks filepaths. Source code in up42/jobtask.py def download_quicklooks ( self , output_directory : Union [ str , Path , None ] = None , ) -> List [ str ]: \"\"\" Downloads quicklooks of the job task to disk. After download, can be plotted via jobtask.plot_quicklooks(). Args: output_directory: The file output directory, defaults to the current working directory. Returns: The quicklooks filepaths. \"\"\" if output_directory is None : # On purpose downloading the quicklooks to the jobs folder and not the # jobtasks folder,since only relevant for data block task. And clearer # for job.download_quicklooks. output_directory = ( Path . cwd () / f \"project_ { self . auth . project_id } \" / f \"job_ { self . job_id } \" ) else : output_directory = Path ( output_directory ) output_directory . mkdir ( parents = True , exist_ok = True ) logger . info ( f \"Download directory: { str ( output_directory ) } \" ) url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /jobs/ { self . job_id } \" f \"/tasks/ { self . jobtask_id } /outputs/quicklooks/\" ) response_json = self . auth . _request ( request_type = \"GET\" , url = url ) quicklooks_ids = response_json [ \"data\" ] out_paths : List [ str ] = [] for ql_id in tqdm ( quicklooks_ids ): out_path = output_directory / f \"quicklook_ { ql_id } \" # No suffix required. out_paths . append ( str ( out_path )) url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /jobs/ { self . job_id } \" f \"/tasks/ { self . jobtask_id } /outputs/quicklooks/ { ql_id } \" ) response = self . auth . _request ( request_type = \"GET\" , url = url , return_text = False ) with open ( out_path , \"wb\" ) as dst : for chunk in response : dst . write ( chunk ) self . quicklooks = out_paths # pylint: disable=attribute-defined-outside-init return out_paths","title":"download_quicklooks()"},{"location":"reference/jobtask/#up42.jobtask.JobTask.download_results","text":"Downloads and unpacks the jobtask results. Default download to Desktop. Parameters: Name Type Description Default output_directory Optional[Union[str, pathlib.Path]] The file output directory, defaults to the current working directory. None Returns: Type Description List[str] List of the downloaded results' filepaths. Source code in up42/jobtask.py def download_results ( self , output_directory : Union [ str , Path , None ] = None ) -> List [ str ]: \"\"\" Downloads and unpacks the jobtask results. Default download to Desktop. Args: output_directory: The file output directory, defaults to the current working directory. Returns: List of the downloaded results' filepaths. \"\"\" logger . info ( f \"Downloading results of jobtask { self . jobtask_id } \" ) if output_directory is None : output_directory = ( Path . cwd () / f \"project_ { self . auth . project_id } /job_ { self . job_id } /jobtask_ { self . jobtask_id } \" ) else : output_directory = Path ( output_directory ) output_directory . mkdir ( parents = True , exist_ok = True ) logger . info ( f \"Download directory: { str ( output_directory ) } \" ) download_url = self . _get_download_url () out_filepaths = download_results_from_gcs ( download_url = download_url , output_directory = output_directory , ) self . results = out_filepaths return out_filepaths","title":"download_results()"},{"location":"reference/jobtask/#up42.jobtask.JobTask.get_results_json","text":"Gets the Jobtask results data.json. Parameters: Name Type Description Default as_dataframe bool \"fc\" for FeatureCollection dict, \"df\" for GeoDataFrame. False Returns: Type Description Union[Dict, geopandas.geodataframe.GeoDataFrame] Json of the results, alternatively geodataframe. Source code in up42/jobtask.py def get_results_json ( self , as_dataframe : bool = False ) -> Union [ Dict , GeoDataFrame ]: \"\"\" Gets the Jobtask results data.json. Args: as_dataframe: \"fc\" for FeatureCollection dict, \"df\" for GeoDataFrame. Returns: Json of the results, alternatively geodataframe. \"\"\" url = ( f \" { self . auth . _endpoint () } /projects/ { self . auth . project_id } /jobs/ { self . job_id } \" f \"/tasks/ { self . jobtask_id } /outputs/data-json/\" ) response_json = self . auth . _request ( request_type = \"GET\" , url = url ) logger . info ( f \"Retrieved { len ( response_json [ 'features' ]) } features.\" ) if as_dataframe : # UP42 results are always in EPSG 4326 df = GeoDataFrame . from_features ( response_json , crs = 4326 ) return df else : return response_json","title":"get_results_json()"},{"location":"reference/project/","text":"Project class \u00b6 The Project class can query all available workflows and spawn new workflows within an UP42 project. Also handles project user settings. \u00b6 max_concurrent_jobs: int property readonly \u00b6 Gets the maximum number of concurrent jobs allowed by the project settings. create_workflow ( self , name , description = '' , use_existing = False ) \u00b6 Creates a new workflow and returns a workflow object. Parameters: Name Type Description Default name str Name of the new workflow. required description str Description of the new workflow. '' use_existing bool If True, instead of creating a new workflow, uses the most recent workflow with the same name & description. False Returns: Type Description Workflow The workflow object. Source code in up42/project.py def create_workflow ( self , name : str , description : str = \"\" , use_existing : bool = False ) -> \"Workflow\" : \"\"\" Creates a new workflow and returns a workflow object. Args: name: Name of the new workflow. description: Description of the new workflow. use_existing: If True, instead of creating a new workflow, uses the most recent workflow with the same name & description. Returns: The workflow object. \"\"\" if use_existing : logger . info ( \"Getting existing workflows in project ...\" ) logging . getLogger ( \"up42.workflow\" ) . setLevel ( logging . CRITICAL ) existing_workflows = self . get_workflows () logging . getLogger ( \"up42.workflow\" ) . setLevel ( logging . INFO ) matching_workflows = [ workflow for workflow in existing_workflows if workflow . info [ \"name\" ] == name and workflow . info [ \"description\" ] == description ] if matching_workflows : existing_workflow = matching_workflows [ 0 ] logger . info ( f \"Using existing workflow: { name } - { existing_workflow . workflow_id } \" ) return existing_workflow url = f \" { self . auth . _endpoint () } /projects/ { self . project_id } /workflows/\" payload = { \"name\" : name , \"description\" : description } response_json = self . auth . _request ( request_type = \"POST\" , url = url , data = payload ) workflow_id = response_json [ \"data\" ][ \"id\" ] logger . info ( f \"Created new workflow: { workflow_id } \" ) workflow = Workflow ( self . auth , project_id = self . project_id , workflow_id = workflow_id ) return workflow get_jobs ( self , return_json = False ) \u00b6 Get all jobs in the project as a JobCollection or json. Use Workflow().get_job() to get a JobCollection with jobs associated with a specific workflow. Parameters: Name Type Description Default return_json bool If true, returns the job info jsons instead of JobCollection. False Returns: Type Description Union[up42.jobcollection.JobCollection, Dict] All job objects in a JobCollection, or alternatively the jobs info as json. Source code in up42/project.py def get_jobs ( self , return_json : bool = False ) -> Union [ JobCollection , Dict ]: \"\"\" Get all jobs in the project as a JobCollection or json. Use Workflow().get_job() to get a JobCollection with jobs associated with a specific workflow. Args: return_json: If true, returns the job info jsons instead of JobCollection. Returns: All job objects in a JobCollection, or alternatively the jobs info as json. \"\"\" url = f \" { self . auth . _endpoint () } /projects/ { self . project_id } /jobs\" response_json = self . auth . _request ( request_type = \"GET\" , url = url ) jobs_json = response_json [ \"data\" ] logger . info ( f \"Got { len ( jobs_json ) } jobs in project { self . project_id } .\" ) if return_json : return jobs_json else : jobs = [ Job ( self . auth , job_id = job [ \"id\" ], project_id = self . project_id ) for job in tqdm ( jobs_json ) ] jobcollection = JobCollection ( auth = self . auth , project_id = self . project_id , jobs = jobs ) return jobcollection get_project_settings ( self ) \u00b6 Gets the project settings. Returns: Type Description List[Dict[str, str]] The project settings. Source code in up42/project.py def get_project_settings ( self ) -> List [ Dict [ str , str ]]: \"\"\" Gets the project settings. Returns: The project settings. \"\"\" url = f \" { self . auth . _endpoint () } /projects/ { self . project_id } /settings\" response_json = self . auth . _request ( request_type = \"GET\" , url = url ) project_settings = response_json [ \"data\" ] return project_settings get_workflows ( self , return_json = False ) \u00b6 Gets all workflows in a project as workflow objects or json. Parameters: Name Type Description Default return_json bool True returns Workflow Objects. False Returns: Type Description Union[List[Workflow], Dict] Workflow objects in the project or alternatively json info of the workflows. Source code in up42/project.py def get_workflows ( self , return_json : bool = False ) -> Union [ List [ \"Workflow\" ], Dict ]: \"\"\" Gets all workflows in a project as workflow objects or json. Args: return_json: True returns Workflow Objects. Returns: Workflow objects in the project or alternatively json info of the workflows. \"\"\" url = f \" { self . auth . _endpoint () } /projects/ { self . project_id } /workflows\" response_json = self . auth . _request ( request_type = \"GET\" , url = url ) workflows_json = response_json [ \"data\" ] logger . info ( f \"Got { len ( workflows_json ) } workflows for project { self . project_id } .\" ) if return_json : return workflows_json else : workflows = [ Workflow ( self . auth , project_id = self . project_id , workflow_id = work [ \"id\" ]) for work in tqdm ( workflows_json ) ] return workflows update_project_settings ( self , max_aoi_size = None , max_concurrent_jobs = None , number_of_images = None ) \u00b6 Updates a project's settings. Parameters: Name Type Description Default max_aoi_size int The maximum area of interest geometry size, from 1-1000 sqkm, default 10 sqkm. None max_concurrent_jobs int The maximum number of concurrent jobs, from 1-10, default 1. None number_of_images The maximum number of images returned with each job, from 1-20, default 10. None Source code in up42/project.py def update_project_settings ( self , max_aoi_size : int = None , max_concurrent_jobs : int = None , number_of_images = None , ) -> None : \"\"\" Updates a project's settings. Args: max_aoi_size: The maximum area of interest geometry size, from 1-1000 sqkm, default 10 sqkm. max_concurrent_jobs: The maximum number of concurrent jobs, from 1-10, default 1. number_of_images: The maximum number of images returned with each job, from 1-20, default 10. \"\"\" url = f \" { self . auth . _endpoint () } /projects/ { self . project_id } /settings\" payload = [ { \"name\" : \"JOB_QUERY_MAX_AOI_SIZE\" , \"value\" : f \" { 100 if max_aoi_size is None else max_aoi_size } \" , }, { \"name\" : \"MAX_CONCURRENT_JOBS\" , \"value\" : f \" { 10 if max_concurrent_jobs is None else max_concurrent_jobs } \" , }, { \"name\" : \"JOB_QUERY_LIMIT_PARAMETER_MAX_VALUE\" , \"value\" : f \" { 10 if number_of_images is None else number_of_images } \" , }, ] self . auth . _request ( request_type = \"PUT\" , url = url , data = payload ) logger . info ( f \"Updated project settings: { payload } \" )","title":"Project"},{"location":"reference/project/#project-class","text":"The Project class can query all available workflows and spawn new workflows within an UP42 project. Also handles project user settings.","title":"Project class"},{"location":"reference/project/#up42.project.Project","text":"","title":"up42.project.Project"},{"location":"reference/project/#up42.project.Project.max_concurrent_jobs","text":"Gets the maximum number of concurrent jobs allowed by the project settings.","title":"max_concurrent_jobs"},{"location":"reference/project/#up42.project.Project.create_workflow","text":"Creates a new workflow and returns a workflow object. Parameters: Name Type Description Default name str Name of the new workflow. required description str Description of the new workflow. '' use_existing bool If True, instead of creating a new workflow, uses the most recent workflow with the same name & description. False Returns: Type Description Workflow The workflow object. Source code in up42/project.py def create_workflow ( self , name : str , description : str = \"\" , use_existing : bool = False ) -> \"Workflow\" : \"\"\" Creates a new workflow and returns a workflow object. Args: name: Name of the new workflow. description: Description of the new workflow. use_existing: If True, instead of creating a new workflow, uses the most recent workflow with the same name & description. Returns: The workflow object. \"\"\" if use_existing : logger . info ( \"Getting existing workflows in project ...\" ) logging . getLogger ( \"up42.workflow\" ) . setLevel ( logging . CRITICAL ) existing_workflows = self . get_workflows () logging . getLogger ( \"up42.workflow\" ) . setLevel ( logging . INFO ) matching_workflows = [ workflow for workflow in existing_workflows if workflow . info [ \"name\" ] == name and workflow . info [ \"description\" ] == description ] if matching_workflows : existing_workflow = matching_workflows [ 0 ] logger . info ( f \"Using existing workflow: { name } - { existing_workflow . workflow_id } \" ) return existing_workflow url = f \" { self . auth . _endpoint () } /projects/ { self . project_id } /workflows/\" payload = { \"name\" : name , \"description\" : description } response_json = self . auth . _request ( request_type = \"POST\" , url = url , data = payload ) workflow_id = response_json [ \"data\" ][ \"id\" ] logger . info ( f \"Created new workflow: { workflow_id } \" ) workflow = Workflow ( self . auth , project_id = self . project_id , workflow_id = workflow_id ) return workflow","title":"create_workflow()"},{"location":"reference/project/#up42.project.Project.get_jobs","text":"Get all jobs in the project as a JobCollection or json. Use Workflow().get_job() to get a JobCollection with jobs associated with a specific workflow. Parameters: Name Type Description Default return_json bool If true, returns the job info jsons instead of JobCollection. False Returns: Type Description Union[up42.jobcollection.JobCollection, Dict] All job objects in a JobCollection, or alternatively the jobs info as json. Source code in up42/project.py def get_jobs ( self , return_json : bool = False ) -> Union [ JobCollection , Dict ]: \"\"\" Get all jobs in the project as a JobCollection or json. Use Workflow().get_job() to get a JobCollection with jobs associated with a specific workflow. Args: return_json: If true, returns the job info jsons instead of JobCollection. Returns: All job objects in a JobCollection, or alternatively the jobs info as json. \"\"\" url = f \" { self . auth . _endpoint () } /projects/ { self . project_id } /jobs\" response_json = self . auth . _request ( request_type = \"GET\" , url = url ) jobs_json = response_json [ \"data\" ] logger . info ( f \"Got { len ( jobs_json ) } jobs in project { self . project_id } .\" ) if return_json : return jobs_json else : jobs = [ Job ( self . auth , job_id = job [ \"id\" ], project_id = self . project_id ) for job in tqdm ( jobs_json ) ] jobcollection = JobCollection ( auth = self . auth , project_id = self . project_id , jobs = jobs ) return jobcollection","title":"get_jobs()"},{"location":"reference/project/#up42.project.Project.get_project_settings","text":"Gets the project settings. Returns: Type Description List[Dict[str, str]] The project settings. Source code in up42/project.py def get_project_settings ( self ) -> List [ Dict [ str , str ]]: \"\"\" Gets the project settings. Returns: The project settings. \"\"\" url = f \" { self . auth . _endpoint () } /projects/ { self . project_id } /settings\" response_json = self . auth . _request ( request_type = \"GET\" , url = url ) project_settings = response_json [ \"data\" ] return project_settings","title":"get_project_settings()"},{"location":"reference/project/#up42.project.Project.get_workflows","text":"Gets all workflows in a project as workflow objects or json. Parameters: Name Type Description Default return_json bool True returns Workflow Objects. False Returns: Type Description Union[List[Workflow], Dict] Workflow objects in the project or alternatively json info of the workflows. Source code in up42/project.py def get_workflows ( self , return_json : bool = False ) -> Union [ List [ \"Workflow\" ], Dict ]: \"\"\" Gets all workflows in a project as workflow objects or json. Args: return_json: True returns Workflow Objects. Returns: Workflow objects in the project or alternatively json info of the workflows. \"\"\" url = f \" { self . auth . _endpoint () } /projects/ { self . project_id } /workflows\" response_json = self . auth . _request ( request_type = \"GET\" , url = url ) workflows_json = response_json [ \"data\" ] logger . info ( f \"Got { len ( workflows_json ) } workflows for project { self . project_id } .\" ) if return_json : return workflows_json else : workflows = [ Workflow ( self . auth , project_id = self . project_id , workflow_id = work [ \"id\" ]) for work in tqdm ( workflows_json ) ] return workflows","title":"get_workflows()"},{"location":"reference/project/#up42.project.Project.update_project_settings","text":"Updates a project's settings. Parameters: Name Type Description Default max_aoi_size int The maximum area of interest geometry size, from 1-1000 sqkm, default 10 sqkm. None max_concurrent_jobs int The maximum number of concurrent jobs, from 1-10, default 1. None number_of_images The maximum number of images returned with each job, from 1-20, default 10. None Source code in up42/project.py def update_project_settings ( self , max_aoi_size : int = None , max_concurrent_jobs : int = None , number_of_images = None , ) -> None : \"\"\" Updates a project's settings. Args: max_aoi_size: The maximum area of interest geometry size, from 1-1000 sqkm, default 10 sqkm. max_concurrent_jobs: The maximum number of concurrent jobs, from 1-10, default 1. number_of_images: The maximum number of images returned with each job, from 1-20, default 10. \"\"\" url = f \" { self . auth . _endpoint () } /projects/ { self . project_id } /settings\" payload = [ { \"name\" : \"JOB_QUERY_MAX_AOI_SIZE\" , \"value\" : f \" { 100 if max_aoi_size is None else max_aoi_size } \" , }, { \"name\" : \"MAX_CONCURRENT_JOBS\" , \"value\" : f \" { 10 if max_concurrent_jobs is None else max_concurrent_jobs } \" , }, { \"name\" : \"JOB_QUERY_LIMIT_PARAMETER_MAX_VALUE\" , \"value\" : f \" { 10 if number_of_images is None else number_of_images } \" , }, ] self . auth . _request ( request_type = \"PUT\" , url = url , data = payload ) logger . info ( f \"Updated project settings: { payload } \" )","title":"update_project_settings()"},{"location":"reference/tools/","text":"Tools class \u00b6 The tools class contains functionality that is not bound to a specific UP42 object, e.g. for aoi handling etc., UP42 block information, validatin a block manifest etc. They can be accessed from every object and also from the imported up42 package directly. \u00b6 draw_aoi ( self ) \u00b6 Displays an interactive map to draw an aoi by hand, returns the folium object if not run in a Jupyter notebook. Export the drawn aoi via the export button, then read the geometries via read_aoi_file(). Source code in up42/tools.py def draw_aoi ( self ): \"\"\" Displays an interactive map to draw an aoi by hand, returns the folium object if not run in a Jupyter notebook. Export the drawn aoi via the export button, then read the geometries via read_aoi_file(). \"\"\" m = folium_base_map ( layer_control = True ) DrawFoliumOverride ( export = True , filename = \"aoi.geojson\" , position = \"topleft\" , draw_options = { \"rectangle\" : { \"repeatMode\" : False , \"showArea\" : True }, \"polygon\" : { \"showArea\" : True , \"allowIntersection\" : False }, \"polyline\" : False , \"circle\" : False , \"marker\" : False , \"circlemarker\" : False , }, edit_options = { \"polygon\" : { \"allowIntersection\" : False }}, ) . add_to ( m ) try : assert get_ipython () is not None display ( m ) except ( AssertionError , NameError ): logger . info ( \"Returning folium map object. To display it directly run in a \" \"Jupyter notebook!\" ) return m get_block_details ( self , block_id , as_dataframe = False ) \u00b6 Gets the detailed information about a specific public block from the server, includes all manifest.json and marketplace.json contents. Parameters: Name Type Description Default block_id str The block id. required as_dataframe Returns a dataframe instead of json (default). False Returns: Type Description Dict A dict of the block details metadata for the specific block. Source code in up42/tools.py def get_block_details ( self , block_id : str , as_dataframe = False ) -> Dict : \"\"\" Gets the detailed information about a specific public block from the server, includes all manifest.json and marketplace.json contents. Args: block_id: The block id. as_dataframe: Returns a dataframe instead of json (default). Returns: A dict of the block details metadata for the specific block. \"\"\" if not hasattr ( self , \"auth\" ): raise Exception ( \"Requires authentication with UP42, use up42.authenticate()!\" ) url = f \" { self . auth . _endpoint () } /blocks/ { block_id } \" # public blocks response_json = self . auth . _request ( request_type = \"GET\" , url = url ) details_json = response_json [ \"data\" ] if as_dataframe : return pd . DataFrame . from_dict ( details_json , orient = \"index\" ) . transpose () else : return details_json get_blocks ( self , block_type = None , basic = True , as_dataframe = False ) \u00b6 Gets a list of all public blocks on the marketplace. Parameters: Name Type Description Default block_type Optionally filters to \"data\" or \"processing\" blocks, default None. None basic bool Optionally returns simple version {block_id : block_name} True as_dataframe Returns a dataframe instead of json (default). False Returns: Type Description Union[List[Dict], Dict] A list of the public blocks and their metadata. Optional a simpler version dict. Source code in up42/tools.py def get_blocks ( self , block_type = None , basic : bool = True , as_dataframe = False , ) -> Union [ List [ Dict ], Dict ]: \"\"\" Gets a list of all public blocks on the marketplace. Args: block_type: Optionally filters to \"data\" or \"processing\" blocks, default None. basic: Optionally returns simple version {block_id : block_name} as_dataframe: Returns a dataframe instead of json (default). Returns: A list of the public blocks and their metadata. Optional a simpler version dict. \"\"\" try : block_type = block_type . lower () except AttributeError : pass if not hasattr ( self , \"auth\" ): raise Exception ( \"Requires authentication with UP42, use up42.authenticate()!\" ) url = f \" { self . auth . _endpoint () } /blocks\" response_json = self . auth . _request ( request_type = \"GET\" , url = url ) public_blocks_json = response_json [ \"data\" ] if block_type == \"data\" : logger . info ( \"Getting only data blocks.\" ) blocks_json = [ block for block in public_blocks_json if block [ \"type\" ] == \"DATA\" ] elif block_type == \"processing\" : logger . info ( \"Getting only processing blocks.\" ) blocks_json = [ block for block in public_blocks_json if block [ \"type\" ] == \"PROCESSING\" ] else : blocks_json = public_blocks_json if basic : logger . info ( \"Getting blocks name and id, use basic=False for all block details.\" ) blocks_basic = { block [ \"name\" ]: block [ \"id\" ] for block in blocks_json } if as_dataframe : return pd . DataFrame . from_dict ( blocks_basic , orient = \"index\" ) else : return blocks_basic else : if as_dataframe : return pd . DataFrame ( blocks_json ) else : return blocks_json get_example_aoi ( self , location = 'Berlin' , as_dataframe = False ) \u00b6 Gets predefined, small, rectangular example aoi for the selected location. Parameters: Name Type Description Default location str Location, one of Berlin, Washington. 'Berlin' as_dataframe bool Returns a dataframe instead of dict FeatureColletions (default). False Returns: Type Description Union[dict, geopandas.geodataframe.GeoDataFrame] Feature collection json with the selected aoi. Source code in up42/tools.py def get_example_aoi ( self , location : str = \"Berlin\" , as_dataframe : bool = False ) -> Union [ dict , GeoDataFrame ]: \"\"\" Gets predefined, small, rectangular example aoi for the selected location. Args: location: Location, one of Berlin, Washington. as_dataframe: Returns a dataframe instead of dict FeatureColletions (default). Returns: Feature collection json with the selected aoi. \"\"\" logger . info ( f \"Getting small example aoi in location ' { location } '.\" ) if location == \"Berlin\" : example_aoi = self . read_vector_file ( f \" { str ( Path ( __file__ ) . resolve () . parent ) } /data/aoi_berlin.geojson\" ) elif location == \"Washington\" : example_aoi = self . read_vector_file ( f \" { str ( Path ( __file__ ) . resolve () . parent ) } /data/aoi_washington.geojson\" ) else : raise ValueError ( \"Please select one of 'Berlin' or 'Washington' as the location!\" ) if as_dataframe : df = GeoDataFrame . from_features ( example_aoi , crs = 4326 ) return df else : return example_aoi map_quicklooks ( self , scenes , aoi = None , filepaths = None , name_column = 'id' , save_html = None ) \u00b6 Plots the downloaded quicklooks (filepaths saved to self.quicklooks of the respective object, e.g. job, catalog). Parameters: Name Type Description Default scenes GeoDataFrame GeoDataFrame of scenes, results of catalog.search() required aoi GeoDataFrame GeoDataFrame of aoi. None filepaths List Paths to images to plot. Optional, by default picks up the last downloaded results. None name_column str Name of the feature property that provides the Feature/Layer name. 'id' save_html Path The path for saving folium map as html file. With default None, no file is saved. None Source code in up42/tools.py def map_quicklooks ( self , scenes : GeoDataFrame , aoi : GeoDataFrame = None , filepaths : List = None , name_column : str = \"id\" , save_html : Path = None , ) -> folium . Map : \"\"\" Plots the downloaded quicklooks (filepaths saved to self.quicklooks of the respective object, e.g. job, catalog). Args: scenes: GeoDataFrame of scenes, results of catalog.search() aoi: GeoDataFrame of aoi. filepaths: Paths to images to plot. Optional, by default picks up the last downloaded results. name_column: Name of the feature property that provides the Feature/Layer name. save_html: The path for saving folium map as html file. With default None, no file is saved. \"\"\" if filepaths is None : if self . quicklooks is None : raise ValueError ( \"You first need to download the quicklooks!\" ) filepaths = self . quicklooks plot_file_format = [ \".jpg\" , \".jpeg\" , \".png\" ] warnings . filterwarnings ( \"ignore\" , category = rasterio . errors . NotGeoreferencedWarning ) m = _map_images ( plot_file_format = plot_file_format , result_df = scenes , filepaths = filepaths , aoi = aoi , name_column = name_column , save_html = save_html , ) return m plot_coverage ( scenes , aoi = None , legend_column = 'scene_id' , figsize = ( 12 , 16 )) staticmethod \u00b6 Plots a coverage map of a dataframe with geometries e.g. the results of catalog.search()) Parameters: Name Type Description Default scenes GeoDataFrame GeoDataFrame of scenes, results of catalog.search() required aoi GeoDataFrame GeoDataFrame of aoi. None legend_column str Dataframe column set to legend, default is \"scene_id\". Legend entries are sorted and this determines plotting order. 'scene_id' figsize Matplotlib figure size. (12, 16) Source code in up42/tools.py @staticmethod def plot_coverage ( scenes : GeoDataFrame , aoi : GeoDataFrame = None , legend_column : str = \"scene_id\" , figsize = ( 12 , 16 ), ) -> None : \"\"\" Plots a coverage map of a dataframe with geometries e.g. the results of catalog.search()) Args: scenes: GeoDataFrame of scenes, results of catalog.search() aoi: GeoDataFrame of aoi. legend_column: Dataframe column set to legend, default is \"scene_id\". Legend entries are sorted and this determines plotting order. figsize: Matplotlib figure size. \"\"\" if legend_column not in scenes . columns : legend_column = None # type: ignore logger . info ( \"Given legend_column name not in scene dataframe, \" \"plotting without legend.\" ) ax = scenes . plot ( legend_column , categorical = True , figsize = figsize , cmap = \"Set3\" , legend = True , alpha = 0.7 , legend_kwds = dict ( loc = \"upper left\" , bbox_to_anchor = ( 1 , 1 )), ) if aoi is not None : aoi . plot ( color = \"r\" , ax = ax , fc = \"None\" , edgecolor = \"r\" , lw = 1 ) ax . set_axis_off () plt . show () plot_quicklooks ( self , figsize = ( 8 , 8 ), filepaths = None , titles = None ) \u00b6 Plots the downloaded quicklooks (filepaths saved to self.quicklooks of the respective object, e.g. job, catalog). Parameters: Name Type Description Default figsize Tuple[int, int] matplotlib figure size. (8, 8) filepaths List Paths to images to plot. Optional, by default picks up the last downloaded results. None titles List[str] List of titles for the subplots, optional. None Source code in up42/tools.py def plot_quicklooks ( self , figsize : Tuple [ int , int ] = ( 8 , 8 ), filepaths : List = None , titles : List [ str ] = None , ) -> None : \"\"\" Plots the downloaded quicklooks (filepaths saved to self.quicklooks of the respective object, e.g. job, catalog). Args: figsize: matplotlib figure size. filepaths: Paths to images to plot. Optional, by default picks up the last downloaded results. titles: List of titles for the subplots, optional. \"\"\" if filepaths is None : if self . quicklooks is None : raise ValueError ( \"You first need to download the quicklooks!\" ) filepaths = self . quicklooks plot_file_format = [ \".jpg\" , \".jpeg\" , \".png\" ] warnings . filterwarnings ( \"ignore\" , category = rasterio . errors . NotGeoreferencedWarning ) _plot_images ( plot_file_format = plot_file_format , figsize = figsize , filepaths = filepaths , titles = titles , ) plot_results ( self , figsize = ( 14 , 8 ), filepaths = None , titles = None ) \u00b6 Plots the downloaded results data. Parameters: Name Type Description Default figsize Tuple[int, int] matplotlib figure size. (14, 8) filepaths List[Union[str, pathlib.Path]] Paths to images to plot. Optional, by default picks up the last downloaded results. None titles List[str] Optional list of titles for the subplots. None Source code in up42/tools.py def plot_results ( self , figsize : Tuple [ int , int ] = ( 14 , 8 ), filepaths : List [ Union [ str , Path ]] = None , titles : List [ str ] = None , ) -> None : \"\"\" Plots the downloaded results data. Args: figsize: matplotlib figure size. filepaths: Paths to images to plot. Optional, by default picks up the last downloaded results. titles: Optional list of titles for the subplots. \"\"\" if filepaths is None : if self . results is None : raise ValueError ( \"You first need to download the results!\" ) filepaths = self . results # Unpack results path dict in case of jobcollection. if isinstance ( filepaths , dict ): filepaths = [ item for sublist in list ( filepaths . values ()) for item in sublist # type: ignore ] plot_file_format = [ \".tif\" ] # TODO: Add other fileformats. _plot_images ( plot_file_format = plot_file_format , figsize = figsize , filepaths = filepaths , titles = titles , ) read_vector_file ( self , filename = 'aoi.geojson' , as_dataframe = False ) \u00b6 Reads vector files (geojson, shapefile, kml, wkt) to a feature collection, for use as the aoi geometry in the workflow input parameters (see get_input_parameters). Example aoi fiels are provided, e.g. example/data/aoi_Berlin.geojson Parameters: Name Type Description Default filename str File path of the vector file. 'aoi.geojson' as_dataframe bool Return type, default FeatureCollection, GeoDataFrame if True. False Returns: Type Description Union[Dict, geopandas.geodataframe.GeoDataFrame] Feature Collection Source code in up42/tools.py def read_vector_file ( self , filename : str = \"aoi.geojson\" , as_dataframe : bool = False ) -> Union [ Dict , GeoDataFrame ]: \"\"\" Reads vector files (geojson, shapefile, kml, wkt) to a feature collection, for use as the aoi geometry in the workflow input parameters (see get_input_parameters). Example aoi fiels are provided, e.g. example/data/aoi_Berlin.geojson Args: filename: File path of the vector file. as_dataframe: Return type, default FeatureCollection, GeoDataFrame if True. Returns: Feature Collection \"\"\" suffix = Path ( filename ) . suffix if suffix == \".kml\" : gpd . io . file . fiona . drvsupport . supported_drivers [ \"KML\" ] = \"rw\" df = gpd . read_file ( filename , driver = \"KML\" ) elif suffix == \".wkt\" : with open ( filename ) as wkt_file : wkt = wkt_file . read () df = pd . DataFrame ({ \"geometry\" : [ wkt ]}) df [ \"geometry\" ] = df [ \"geometry\" ] . apply ( shapely . wkt . loads ) df = GeoDataFrame ( df , geometry = \"geometry\" , crs = 4326 ) else : df = gpd . read_file ( filename ) if df . crs . to_string () != \"EPSG:4326\" : df = df . to_crs ( epsg = 4326 ) # TODO: Explode multipolygons (if neccessary as union in aoi anyway most often). # TODO: Have both bboxes for each feature and overall? if as_dataframe : return df else : return df . __geo_interface__ validate_manifest ( self , path_or_json ) \u00b6 Validates the block manifest, input either manifest json string or filepath. Parameters: Name Type Description Default path_or_json Union[str, pathlib.Path, Dict] The input manifest, either filepath or json string, see example. required Returns: Type Description Dict A dictionary with the validation results and potential validation errors. Examples: { \"_up42_specification_version\" : 2 , \"name\" : \"sharpening\" , \"type\" : \"processing\" , \"tags\" : [ \"imagery\" , \"processing\" ], \"display_name\" : \"Sharpening Filter\" , \"description\" : \"This block enhances the sharpness of a raster image by applying an unsharp mask filter algorithm.\" , \"parameters\" : { \"strength\" : { \"type\" : \"string\" , \"default\" : \"medium\" } }, \"machine\" : { \"type\" : \"large\" }, \"input_capabilities\" : { \"raster\" : { \"up42_standard\" : { \"format\" : \"GTiff\" } } }, \"output_capabilities\" : { \"raster\" : { \"up42_standard\" : { \"format\" : \"GTiff\" , \"bands\" : \">\" , \"sensor\" : \">\" , \"resolution\" : \">\" , \"dtype\" : \">\" , \"processing_level\" : \">\" } } } } Source code in up42/tools.py def validate_manifest ( self , path_or_json : Union [ str , Path , Dict ]) -> Dict : \"\"\" Validates the block manifest, input either manifest json string or filepath. Args: path_or_json: The input manifest, either filepath or json string, see example. Returns: A dictionary with the validation results and potential validation errors. Example: ```json { \"_up42_specification_version\": 2, \"name\": \"sharpening\", \"type\": \"processing\", \"tags\": [ \"imagery\", \"processing\" ], \"display_name\": \"Sharpening Filter\", \"description\": \"This block enhances the sharpness of a raster image by applying an unsharp mask filter algorithm.\", \"parameters\": { \"strength\": {\"type\": \"string\", \"default\": \"medium\"} }, \"machine\": { \"type\": \"large\" }, \"input_capabilities\": { \"raster\": { \"up42_standard\": { \"format\": \"GTiff\" } } }, \"output_capabilities\": { \"raster\": { \"up42_standard\": { \"format\": \"GTiff\", \"bands\": \">\", \"sensor\": \">\", \"resolution\": \">\", \"dtype\": \">\", \"processing_level\": \">\" } } } } ``` \"\"\" if isinstance ( path_or_json , ( str , Path )): with open ( path_or_json ) as src : manifest_json = json . load ( src ) else : manifest_json = path_or_json if not hasattr ( self , \"auth\" ): raise Exception ( \"Requires authentication with UP42, use up42.authenticate()!\" ) url = f \" { self . auth . _endpoint () } /validate-schema/block\" response_json = self . auth . _request ( request_type = \"POST\" , url = url , data = manifest_json ) logger . info ( \"The manifest is valid.\" ) return response_json [ \"data\" ]","title":"Tools"},{"location":"reference/tools/#tools-class","text":"The tools class contains functionality that is not bound to a specific UP42 object, e.g. for aoi handling etc., UP42 block information, validatin a block manifest etc. They can be accessed from every object and also from the imported up42 package directly.","title":"Tools class"},{"location":"reference/tools/#up42.tools.Tools","text":"","title":"up42.tools.Tools"},{"location":"reference/tools/#up42.tools.Tools.draw_aoi","text":"Displays an interactive map to draw an aoi by hand, returns the folium object if not run in a Jupyter notebook. Export the drawn aoi via the export button, then read the geometries via read_aoi_file(). Source code in up42/tools.py def draw_aoi ( self ): \"\"\" Displays an interactive map to draw an aoi by hand, returns the folium object if not run in a Jupyter notebook. Export the drawn aoi via the export button, then read the geometries via read_aoi_file(). \"\"\" m = folium_base_map ( layer_control = True ) DrawFoliumOverride ( export = True , filename = \"aoi.geojson\" , position = \"topleft\" , draw_options = { \"rectangle\" : { \"repeatMode\" : False , \"showArea\" : True }, \"polygon\" : { \"showArea\" : True , \"allowIntersection\" : False }, \"polyline\" : False , \"circle\" : False , \"marker\" : False , \"circlemarker\" : False , }, edit_options = { \"polygon\" : { \"allowIntersection\" : False }}, ) . add_to ( m ) try : assert get_ipython () is not None display ( m ) except ( AssertionError , NameError ): logger . info ( \"Returning folium map object. To display it directly run in a \" \"Jupyter notebook!\" ) return m","title":"draw_aoi()"},{"location":"reference/tools/#up42.tools.Tools.get_block_details","text":"Gets the detailed information about a specific public block from the server, includes all manifest.json and marketplace.json contents. Parameters: Name Type Description Default block_id str The block id. required as_dataframe Returns a dataframe instead of json (default). False Returns: Type Description Dict A dict of the block details metadata for the specific block. Source code in up42/tools.py def get_block_details ( self , block_id : str , as_dataframe = False ) -> Dict : \"\"\" Gets the detailed information about a specific public block from the server, includes all manifest.json and marketplace.json contents. Args: block_id: The block id. as_dataframe: Returns a dataframe instead of json (default). Returns: A dict of the block details metadata for the specific block. \"\"\" if not hasattr ( self , \"auth\" ): raise Exception ( \"Requires authentication with UP42, use up42.authenticate()!\" ) url = f \" { self . auth . _endpoint () } /blocks/ { block_id } \" # public blocks response_json = self . auth . _request ( request_type = \"GET\" , url = url ) details_json = response_json [ \"data\" ] if as_dataframe : return pd . DataFrame . from_dict ( details_json , orient = \"index\" ) . transpose () else : return details_json","title":"get_block_details()"},{"location":"reference/tools/#up42.tools.Tools.get_blocks","text":"Gets a list of all public blocks on the marketplace. Parameters: Name Type Description Default block_type Optionally filters to \"data\" or \"processing\" blocks, default None. None basic bool Optionally returns simple version {block_id : block_name} True as_dataframe Returns a dataframe instead of json (default). False Returns: Type Description Union[List[Dict], Dict] A list of the public blocks and their metadata. Optional a simpler version dict. Source code in up42/tools.py def get_blocks ( self , block_type = None , basic : bool = True , as_dataframe = False , ) -> Union [ List [ Dict ], Dict ]: \"\"\" Gets a list of all public blocks on the marketplace. Args: block_type: Optionally filters to \"data\" or \"processing\" blocks, default None. basic: Optionally returns simple version {block_id : block_name} as_dataframe: Returns a dataframe instead of json (default). Returns: A list of the public blocks and their metadata. Optional a simpler version dict. \"\"\" try : block_type = block_type . lower () except AttributeError : pass if not hasattr ( self , \"auth\" ): raise Exception ( \"Requires authentication with UP42, use up42.authenticate()!\" ) url = f \" { self . auth . _endpoint () } /blocks\" response_json = self . auth . _request ( request_type = \"GET\" , url = url ) public_blocks_json = response_json [ \"data\" ] if block_type == \"data\" : logger . info ( \"Getting only data blocks.\" ) blocks_json = [ block for block in public_blocks_json if block [ \"type\" ] == \"DATA\" ] elif block_type == \"processing\" : logger . info ( \"Getting only processing blocks.\" ) blocks_json = [ block for block in public_blocks_json if block [ \"type\" ] == \"PROCESSING\" ] else : blocks_json = public_blocks_json if basic : logger . info ( \"Getting blocks name and id, use basic=False for all block details.\" ) blocks_basic = { block [ \"name\" ]: block [ \"id\" ] for block in blocks_json } if as_dataframe : return pd . DataFrame . from_dict ( blocks_basic , orient = \"index\" ) else : return blocks_basic else : if as_dataframe : return pd . DataFrame ( blocks_json ) else : return blocks_json","title":"get_blocks()"},{"location":"reference/tools/#up42.tools.Tools.get_example_aoi","text":"Gets predefined, small, rectangular example aoi for the selected location. Parameters: Name Type Description Default location str Location, one of Berlin, Washington. 'Berlin' as_dataframe bool Returns a dataframe instead of dict FeatureColletions (default). False Returns: Type Description Union[dict, geopandas.geodataframe.GeoDataFrame] Feature collection json with the selected aoi. Source code in up42/tools.py def get_example_aoi ( self , location : str = \"Berlin\" , as_dataframe : bool = False ) -> Union [ dict , GeoDataFrame ]: \"\"\" Gets predefined, small, rectangular example aoi for the selected location. Args: location: Location, one of Berlin, Washington. as_dataframe: Returns a dataframe instead of dict FeatureColletions (default). Returns: Feature collection json with the selected aoi. \"\"\" logger . info ( f \"Getting small example aoi in location ' { location } '.\" ) if location == \"Berlin\" : example_aoi = self . read_vector_file ( f \" { str ( Path ( __file__ ) . resolve () . parent ) } /data/aoi_berlin.geojson\" ) elif location == \"Washington\" : example_aoi = self . read_vector_file ( f \" { str ( Path ( __file__ ) . resolve () . parent ) } /data/aoi_washington.geojson\" ) else : raise ValueError ( \"Please select one of 'Berlin' or 'Washington' as the location!\" ) if as_dataframe : df = GeoDataFrame . from_features ( example_aoi , crs = 4326 ) return df else : return example_aoi","title":"get_example_aoi()"},{"location":"reference/tools/#up42.tools.Tools.map_quicklooks","text":"Plots the downloaded quicklooks (filepaths saved to self.quicklooks of the respective object, e.g. job, catalog). Parameters: Name Type Description Default scenes GeoDataFrame GeoDataFrame of scenes, results of catalog.search() required aoi GeoDataFrame GeoDataFrame of aoi. None filepaths List Paths to images to plot. Optional, by default picks up the last downloaded results. None name_column str Name of the feature property that provides the Feature/Layer name. 'id' save_html Path The path for saving folium map as html file. With default None, no file is saved. None Source code in up42/tools.py def map_quicklooks ( self , scenes : GeoDataFrame , aoi : GeoDataFrame = None , filepaths : List = None , name_column : str = \"id\" , save_html : Path = None , ) -> folium . Map : \"\"\" Plots the downloaded quicklooks (filepaths saved to self.quicklooks of the respective object, e.g. job, catalog). Args: scenes: GeoDataFrame of scenes, results of catalog.search() aoi: GeoDataFrame of aoi. filepaths: Paths to images to plot. Optional, by default picks up the last downloaded results. name_column: Name of the feature property that provides the Feature/Layer name. save_html: The path for saving folium map as html file. With default None, no file is saved. \"\"\" if filepaths is None : if self . quicklooks is None : raise ValueError ( \"You first need to download the quicklooks!\" ) filepaths = self . quicklooks plot_file_format = [ \".jpg\" , \".jpeg\" , \".png\" ] warnings . filterwarnings ( \"ignore\" , category = rasterio . errors . NotGeoreferencedWarning ) m = _map_images ( plot_file_format = plot_file_format , result_df = scenes , filepaths = filepaths , aoi = aoi , name_column = name_column , save_html = save_html , ) return m","title":"map_quicklooks()"},{"location":"reference/tools/#up42.tools.Tools.plot_coverage","text":"Plots a coverage map of a dataframe with geometries e.g. the results of catalog.search()) Parameters: Name Type Description Default scenes GeoDataFrame GeoDataFrame of scenes, results of catalog.search() required aoi GeoDataFrame GeoDataFrame of aoi. None legend_column str Dataframe column set to legend, default is \"scene_id\". Legend entries are sorted and this determines plotting order. 'scene_id' figsize Matplotlib figure size. (12, 16) Source code in up42/tools.py @staticmethod def plot_coverage ( scenes : GeoDataFrame , aoi : GeoDataFrame = None , legend_column : str = \"scene_id\" , figsize = ( 12 , 16 ), ) -> None : \"\"\" Plots a coverage map of a dataframe with geometries e.g. the results of catalog.search()) Args: scenes: GeoDataFrame of scenes, results of catalog.search() aoi: GeoDataFrame of aoi. legend_column: Dataframe column set to legend, default is \"scene_id\". Legend entries are sorted and this determines plotting order. figsize: Matplotlib figure size. \"\"\" if legend_column not in scenes . columns : legend_column = None # type: ignore logger . info ( \"Given legend_column name not in scene dataframe, \" \"plotting without legend.\" ) ax = scenes . plot ( legend_column , categorical = True , figsize = figsize , cmap = \"Set3\" , legend = True , alpha = 0.7 , legend_kwds = dict ( loc = \"upper left\" , bbox_to_anchor = ( 1 , 1 )), ) if aoi is not None : aoi . plot ( color = \"r\" , ax = ax , fc = \"None\" , edgecolor = \"r\" , lw = 1 ) ax . set_axis_off () plt . show ()","title":"plot_coverage()"},{"location":"reference/tools/#up42.tools.Tools.plot_quicklooks","text":"Plots the downloaded quicklooks (filepaths saved to self.quicklooks of the respective object, e.g. job, catalog). Parameters: Name Type Description Default figsize Tuple[int, int] matplotlib figure size. (8, 8) filepaths List Paths to images to plot. Optional, by default picks up the last downloaded results. None titles List[str] List of titles for the subplots, optional. None Source code in up42/tools.py def plot_quicklooks ( self , figsize : Tuple [ int , int ] = ( 8 , 8 ), filepaths : List = None , titles : List [ str ] = None , ) -> None : \"\"\" Plots the downloaded quicklooks (filepaths saved to self.quicklooks of the respective object, e.g. job, catalog). Args: figsize: matplotlib figure size. filepaths: Paths to images to plot. Optional, by default picks up the last downloaded results. titles: List of titles for the subplots, optional. \"\"\" if filepaths is None : if self . quicklooks is None : raise ValueError ( \"You first need to download the quicklooks!\" ) filepaths = self . quicklooks plot_file_format = [ \".jpg\" , \".jpeg\" , \".png\" ] warnings . filterwarnings ( \"ignore\" , category = rasterio . errors . NotGeoreferencedWarning ) _plot_images ( plot_file_format = plot_file_format , figsize = figsize , filepaths = filepaths , titles = titles , )","title":"plot_quicklooks()"},{"location":"reference/tools/#up42.tools.Tools.plot_results","text":"Plots the downloaded results data. Parameters: Name Type Description Default figsize Tuple[int, int] matplotlib figure size. (14, 8) filepaths List[Union[str, pathlib.Path]] Paths to images to plot. Optional, by default picks up the last downloaded results. None titles List[str] Optional list of titles for the subplots. None Source code in up42/tools.py def plot_results ( self , figsize : Tuple [ int , int ] = ( 14 , 8 ), filepaths : List [ Union [ str , Path ]] = None , titles : List [ str ] = None , ) -> None : \"\"\" Plots the downloaded results data. Args: figsize: matplotlib figure size. filepaths: Paths to images to plot. Optional, by default picks up the last downloaded results. titles: Optional list of titles for the subplots. \"\"\" if filepaths is None : if self . results is None : raise ValueError ( \"You first need to download the results!\" ) filepaths = self . results # Unpack results path dict in case of jobcollection. if isinstance ( filepaths , dict ): filepaths = [ item for sublist in list ( filepaths . values ()) for item in sublist # type: ignore ] plot_file_format = [ \".tif\" ] # TODO: Add other fileformats. _plot_images ( plot_file_format = plot_file_format , figsize = figsize , filepaths = filepaths , titles = titles , )","title":"plot_results()"},{"location":"reference/tools/#up42.tools.Tools.read_vector_file","text":"Reads vector files (geojson, shapefile, kml, wkt) to a feature collection, for use as the aoi geometry in the workflow input parameters (see get_input_parameters). Example aoi fiels are provided, e.g. example/data/aoi_Berlin.geojson Parameters: Name Type Description Default filename str File path of the vector file. 'aoi.geojson' as_dataframe bool Return type, default FeatureCollection, GeoDataFrame if True. False Returns: Type Description Union[Dict, geopandas.geodataframe.GeoDataFrame] Feature Collection Source code in up42/tools.py def read_vector_file ( self , filename : str = \"aoi.geojson\" , as_dataframe : bool = False ) -> Union [ Dict , GeoDataFrame ]: \"\"\" Reads vector files (geojson, shapefile, kml, wkt) to a feature collection, for use as the aoi geometry in the workflow input parameters (see get_input_parameters). Example aoi fiels are provided, e.g. example/data/aoi_Berlin.geojson Args: filename: File path of the vector file. as_dataframe: Return type, default FeatureCollection, GeoDataFrame if True. Returns: Feature Collection \"\"\" suffix = Path ( filename ) . suffix if suffix == \".kml\" : gpd . io . file . fiona . drvsupport . supported_drivers [ \"KML\" ] = \"rw\" df = gpd . read_file ( filename , driver = \"KML\" ) elif suffix == \".wkt\" : with open ( filename ) as wkt_file : wkt = wkt_file . read () df = pd . DataFrame ({ \"geometry\" : [ wkt ]}) df [ \"geometry\" ] = df [ \"geometry\" ] . apply ( shapely . wkt . loads ) df = GeoDataFrame ( df , geometry = \"geometry\" , crs = 4326 ) else : df = gpd . read_file ( filename ) if df . crs . to_string () != \"EPSG:4326\" : df = df . to_crs ( epsg = 4326 ) # TODO: Explode multipolygons (if neccessary as union in aoi anyway most often). # TODO: Have both bboxes for each feature and overall? if as_dataframe : return df else : return df . __geo_interface__","title":"read_vector_file()"},{"location":"reference/tools/#up42.tools.Tools.validate_manifest","text":"Validates the block manifest, input either manifest json string or filepath. Parameters: Name Type Description Default path_or_json Union[str, pathlib.Path, Dict] The input manifest, either filepath or json string, see example. required Returns: Type Description Dict A dictionary with the validation results and potential validation errors. Examples: { \"_up42_specification_version\" : 2 , \"name\" : \"sharpening\" , \"type\" : \"processing\" , \"tags\" : [ \"imagery\" , \"processing\" ], \"display_name\" : \"Sharpening Filter\" , \"description\" : \"This block enhances the sharpness of a raster image by applying an unsharp mask filter algorithm.\" , \"parameters\" : { \"strength\" : { \"type\" : \"string\" , \"default\" : \"medium\" } }, \"machine\" : { \"type\" : \"large\" }, \"input_capabilities\" : { \"raster\" : { \"up42_standard\" : { \"format\" : \"GTiff\" } } }, \"output_capabilities\" : { \"raster\" : { \"up42_standard\" : { \"format\" : \"GTiff\" , \"bands\" : \">\" , \"sensor\" : \">\" , \"resolution\" : \">\" , \"dtype\" : \">\" , \"processing_level\" : \">\" } } } } Source code in up42/tools.py def validate_manifest ( self , path_or_json : Union [ str , Path , Dict ]) -> Dict : \"\"\" Validates the block manifest, input either manifest json string or filepath. Args: path_or_json: The input manifest, either filepath or json string, see example. Returns: A dictionary with the validation results and potential validation errors. Example: ```json { \"_up42_specification_version\": 2, \"name\": \"sharpening\", \"type\": \"processing\", \"tags\": [ \"imagery\", \"processing\" ], \"display_name\": \"Sharpening Filter\", \"description\": \"This block enhances the sharpness of a raster image by applying an unsharp mask filter algorithm.\", \"parameters\": { \"strength\": {\"type\": \"string\", \"default\": \"medium\"} }, \"machine\": { \"type\": \"large\" }, \"input_capabilities\": { \"raster\": { \"up42_standard\": { \"format\": \"GTiff\" } } }, \"output_capabilities\": { \"raster\": { \"up42_standard\": { \"format\": \"GTiff\", \"bands\": \">\", \"sensor\": \">\", \"resolution\": \">\", \"dtype\": \">\", \"processing_level\": \">\" } } } } ``` \"\"\" if isinstance ( path_or_json , ( str , Path )): with open ( path_or_json ) as src : manifest_json = json . load ( src ) else : manifest_json = path_or_json if not hasattr ( self , \"auth\" ): raise Exception ( \"Requires authentication with UP42, use up42.authenticate()!\" ) url = f \" { self . auth . _endpoint () } /validate-schema/block\" response_json = self . auth . _request ( request_type = \"POST\" , url = url , data = manifest_json ) logger . info ( \"The manifest is valid.\" ) return response_json [ \"data\" ]","title":"validate_manifest()"},{"location":"reference/workflow/","text":"Workflow class \u00b6 The Workflow class can query all available and spawn new jobs for an UP42 Workflow and helps to find and set the the workflow tasks, parameters and aoi. \u00b6 max_concurrent_jobs: int property readonly \u00b6 Gets the maximum number of concurrent jobs allowed by the project settings. add_workflow_tasks ( self , input_tasks ) \u00b6 Adds or overwrites workflow tasks in a workflow on UP42. Parameters: Name Type Description Default input_tasks Union[List[str], List[Dict]] The input tasks, specifying the blocks. Can be a list of the block ids, block names or block display names (The name shown on the marketplace . required Info Using block ids specifies a specific version of the block that will be added to the workflow. With block names or block display names, the most recent version of a block will always be added. Examples: input_tasks_simple = [ 'a2daaab4-196d-4226-a018-a810444dcad1' , '4ed70368-d4e1-4462-bef6-14e768049471' ] input_tasks = [ \"sobloo-s2-l1c-aoiclipped\" , \"tiling\" ] input_tasks = [ \"Sentinel-2 L1C MSI AOI clipped\" , \"Raster Tiling\" ] Source code in up42/workflow.py def add_workflow_tasks ( self , input_tasks : Union [ List [ str ], List [ Dict ]]) -> None : \"\"\" Adds or overwrites workflow tasks in a workflow on UP42. Args: input_tasks: The input tasks, specifying the blocks. Can be a list of the block ids, block names or block display names (The name shown on the [marketplace](https://marketplace.up42.com). !!! Info Using block ids specifies a specific version of the block that will be added to the workflow. With block names or block display names, the most recent version of a block will always be added. Example: ```python input_tasks_simple = ['a2daaab4-196d-4226-a018-a810444dcad1', '4ed70368-d4e1-4462-bef6-14e768049471'] ``` ```python input_tasks = [\"sobloo-s2-l1c-aoiclipped\", \"tiling\"] ``` ```python input_tasks = [\"Sentinel-2 L1C MSI AOI clipped\", \"Raster Tiling\"] ``` \"\"\" # Relevant when non-linear workflows are introduced: # Optional: # The input_tasks can also be provided as the full, detailed workflow task # definition (dict of block id, block name and parent block name). Always use :1 # to be able to identify the order when two times the same workflow task is used. # The name is arbitrary, but best use the block name. # # Example: # ```python # input_tasks_full = [{'name': 'sobloo-s2-l1c-aoiclipped:1', # 'parentName': None, # 'blockId': 'a2daaab4-196d-4226-a018-a810444dcad1'}, # {'name': 'sharpening:1', # 'parentName': 'sobloo-s2-l1c-aoiclipped', # 'blockId': '4ed70368-d4e1-4462-bef6-14e768049471'}] # Construct proper task definition from simplified input. if isinstance ( input_tasks [ 0 ], str ) and not isinstance ( input_tasks [ 0 ], dict ): input_tasks = self . _construct_full_workflow_tasks_dict ( input_tasks ) url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /workflows/\" f \" { self . workflow_id } /tasks/\" ) self . auth . _request ( request_type = \"POST\" , url = url , data = input_tasks ) logger . info ( f \"Added tasks to workflow: { input_tasks } \" ) construct_parameters ( self , geometry = None , geometry_operation = None , handle_multiple_features = 'union' , start_date = None , end_date = None , limit = None , scene_ids = None , order_ids = None ) \u00b6 Constructs workflow input parameters with a specified aoi, the default input parameters, and optionally limit and order-ids. Further parameter editing needs to be done manually via dict.update({key:value}). Parameters: Name Type Description Default geometry Union[Dict, geojson.feature.Feature, geojson.feature.FeatureCollection, geojson.geometry.Polygon, List, geopandas.geodataframe.GeoDataFrame, shapely.geometry.polygon.Polygon, shapely.geometry.point.Point] One of Dict, FeatureCollection, Feature, List, GeoDataFrame, shapely.geometry.Polygon, shapely.geometry.Point. All assume EPSG 4326. None geometry_operation str Desired operation, One of \"bbox\", \"intersects\", \"contains\". None limit int Maximum number of expected results. None start_date str Query period starting day, format \"2020-01-01\". None end_date str Query period ending day, format \"2020-01-01\". None scene_ids List List of scene_ids, if given ignores all other parameters except geometry. None order_ids List[str] Optional, can be used to incorporate existing bought imagery on UP42 into new workflows. None Returns: Type Description Dict Dictionary of constructed input parameters. Source code in up42/workflow.py def construct_parameters ( self , geometry : Union [ Dict , Feature , FeatureCollection , geojson_Polygon , List , GeoDataFrame , Polygon , Point , ] = None , geometry_operation : str = None , handle_multiple_features : str = \"union\" , start_date : str = None , end_date : str = None , limit : int = None , scene_ids : List = None , order_ids : List [ str ] = None , ) -> Dict : \"\"\" Constructs workflow input parameters with a specified aoi, the default input parameters, and optionally limit and order-ids. Further parameter editing needs to be done manually via dict.update({key:value}). Args: geometry: One of Dict, FeatureCollection, Feature, List, GeoDataFrame, shapely.geometry.Polygon, shapely.geometry.Point. All assume EPSG 4326. geometry_operation: Desired operation, One of \"bbox\", \"intersects\", \"contains\". limit: Maximum number of expected results. start_date: Query period starting day, format \"2020-01-01\". end_date: Query period ending day, format \"2020-01-01\". scene_ids: List of scene_ids, if given ignores all other parameters except geometry. order_ids: Optional, can be used to incorporate existing bought imagery on UP42 into new workflows. Returns: Dictionary of constructed input parameters. \"\"\" input_parameters = self . _get_default_parameters () data_block_name = list ( input_parameters . keys ())[ 0 ] if order_ids is not None : # Needs to be handled in this function(not run_job) as it is only # relevant for the data block. input_parameters [ data_block_name ] = { \"order_ids\" : order_ids } else : if limit is not None : input_parameters [ data_block_name ][ \"limit\" ] = limit if scene_ids is not None : if not isinstance ( scene_ids , list ): scene_ids = [ scene_ids ] input_parameters [ data_block_name ][ \"ids\" ] = scene_ids input_parameters [ data_block_name ][ \"limit\" ] = len ( scene_ids ) input_parameters [ data_block_name ] . pop ( \"time\" ) elif start_date is not None and end_date is not None : time = f \" { start_date } T00:00:00Z/ { end_date } T23:59:59Z\" input_parameters [ data_block_name ][ \"time\" ] = time if geometry is not None : aoi_fc = any_vector_to_fc ( vector = geometry , ) aoi_feature = fc_to_query_geometry ( fc = aoi_fc , geometry_operation = geometry_operation , # type: ignore squash_multiple_features = handle_multiple_features , ) input_parameters [ data_block_name ][ geometry_operation ] = aoi_feature return input_parameters construct_parameters_parallel ( self , geometries = None , interval_dates = None , scene_ids = None , limit_per_job = 1 , geometry_operation = 'intersects' ) \u00b6 Maps a list of geometries and a list of time series into a list of input parameters of a workflow. If you pass 2 geometries and 1 time interval this will result in 2 x 1 input parameters. Parameters: Name Type Description Default geometries List[Union[Dict, geojson.feature.Feature, geojson.geometry.Polygon, shapely.geometry.polygon.Polygon, shapely.geometry.point.Point]] List of unit geometries to map with times. None interval_dates List[Tuple[str, str]] List of tuples of start and end dates, i.e. (\"2014-01-01\",\"2015-01-01\") . None scene_ids List List of scene ids. Will be mapped 1:1 to each job. All other arguments are ignored except geometries if passed. None limit_per_job int Limit passed to be passed to each individual job parameter. 1 geometry_operation str Geometry operation to be passed to each job parameter. 'intersects' Returns: Type Description List[dict] List of dictionary of constructed input parameters. Source code in up42/workflow.py def construct_parameters_parallel ( self , geometries : List [ Union [ Dict , Feature , geojson_Polygon , Polygon , Point , ] ] = None , interval_dates : List [ Tuple [ str , str ]] = None , scene_ids : List = None , limit_per_job : int = 1 , geometry_operation : str = \"intersects\" , ) -> List [ dict ]: \"\"\" Maps a list of geometries and a list of time series into a list of input parameters of a workflow. If you pass 2 geometries and 1 time interval this will result in 2 x 1 input parameters. Args: geometries: List of unit geometries to map with times. interval_dates: List of tuples of start and end dates, i.e. `(\"2014-01-01\",\"2015-01-01\")`. scene_ids: List of scene ids. Will be mapped 1:1 to each job. All other arguments are ignored except geometries if passed. limit_per_job: Limit passed to be passed to each individual job parameter. geometry_operation: Geometry operation to be passed to each job parameter. Returns: List of dictionary of constructed input parameters. \"\"\" # TODO: Rename arguments result_params = [] # scene_ids mapped to geometries if scene_ids is not None and geometries is not None : for geo in geometries : for scene_id in scene_ids : params = self . construct_parameters ( geometry = geo , scene_ids = [ scene_id ], geometry_operation = geometry_operation , ) result_params . append ( params ) # interval_dates mapped to geometries elif interval_dates is not None and geometries is not None : for geo in geometries : for start_date , end_date in interval_dates : params = self . construct_parameters ( geometry = geo , geometry_operation = geometry_operation , start_date = start_date , end_date = end_date , limit = limit_per_job , ) result_params . append ( params ) # only scene_ids elif scene_ids is not None : for scene_id in scene_ids : result_params . append ( self . construct_parameters ( geometry = None , scene_ids = [ scene_id ], ) ) else : raise ValueError ( \"Please provides geometries and scene_ids, geometries\" \"and time_interval or scene_ids.\" ) return result_params delete ( self ) \u00b6 Deletes the workflow and sets the Python object to None. Source code in up42/workflow.py def delete ( self ) -> None : \"\"\" Deletes the workflow and sets the Python object to None. \"\"\" url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /workflows/\" f \" { self . workflow_id } \" ) self . auth . _request ( request_type = \"DELETE\" , url = url , return_text = False ) logger . info ( f \"Successfully deleted workflow: { self . workflow_id } \" ) del self get_compatible_blocks ( self ) \u00b6 Gets all compatible blocks for the current workflow. If the workflow is empty it will provide all data blocks, if the workflow already has workflow tasks, it will provide the compatible blocks for the last workflow task in the workflow. Currently no data blocks can be attached to other data blocks. Source code in up42/workflow.py def get_compatible_blocks ( self ) -> Dict : \"\"\" Gets all compatible blocks for the current workflow. If the workflow is empty it will provide all data blocks, if the workflow already has workflow tasks, it will provide the compatible blocks for the last workflow task in the workflow. Currently no data blocks can be attached to other data blocks. \"\"\" last_task = list ( self . get_workflow_tasks ( basic = True ) . keys ())[ - 1 ] # type: ignore url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /workflows/ { self . workflow_id } /\" f \"compatible-blocks?parentTaskName= { last_task } \" ) response_json = self . auth . _request ( request_type = \"GET\" , url = url ) compatible_blocks = response_json [ \"data\" ][ \"blocks\" ] compatible_blocks = { block [ \"name\" ]: block [ \"blockId\" ] for block in compatible_blocks } return compatible_blocks get_jobs ( self , return_json = False ) \u00b6 Get all jobs associated with the workflow as a JobCollection or json. Parameters: Name Type Description Default return_json bool If true, returns the job info jsons instead of a JobCollection. False Returns: Type Description Union[up42.jobcollection.JobCollection, List[Dict]] A JobCollection, or alternatively the jobs info as json. Source code in up42/workflow.py def get_jobs ( self , return_json : bool = False ) -> Union [ JobCollection , List [ Dict ]]: \"\"\" Get all jobs associated with the workflow as a JobCollection or json. Args: return_json: If true, returns the job info jsons instead of a JobCollection. Returns: A JobCollection, or alternatively the jobs info as json. \"\"\" url = f \" { self . auth . _endpoint () } /projects/ { self . project_id } /jobs\" response_json = self . auth . _request ( request_type = \"GET\" , url = url ) jobs_json = response_json [ \"data\" ] jobs_workflow_json = [ j for j in jobs_json if j [ \"workflowId\" ] == self . workflow_id ] logger . info ( f \"Got { len ( jobs_workflow_json ) } jobs for workflow \" f \" { self . workflow_id } in project { self . project_id } .\" ) if return_json : return jobs_workflow_json else : jobs = [ Job ( self . auth , job_id = job [ \"id\" ], project_id = self . project_id ) for job in tqdm ( jobs_workflow_json ) ] jobcollection = JobCollection ( auth = self . auth , project_id = self . project_id , jobs = jobs ) return jobcollection get_parameters_info ( self ) \u00b6 Gets infos about the workflow parameters of each block in the current workflow to make it easy to construct the desired parameters. Returns: Type Description Dict Workflow parameters info json. Source code in up42/workflow.py def get_parameters_info ( self ) -> Dict : \"\"\" Gets infos about the workflow parameters of each block in the current workflow to make it easy to construct the desired parameters. Returns: Workflow parameters info json. \"\"\" workflow_parameters_info = {} workflow_tasks = self . get_workflow_tasks () for task in workflow_tasks : task_name = task [ \"name\" ] task_default_parameters = task [ \"block\" ][ \"parameters\" ] workflow_parameters_info [ task_name ] = task_default_parameters return workflow_parameters_info get_workflow_tasks ( self , basic = False ) \u00b6 Get the workflow-tasks of the workflow (Blocks in a workflow are called workflow_tasks) Parameters: Name Type Description Default basic bool If selected returns a simplified task-name : task-id` version. False Returns: Type Description Union[List, Dict] The workflow task info. Source code in up42/workflow.py def get_workflow_tasks ( self , basic : bool = False ) -> Union [ List , Dict ]: \"\"\" Get the workflow-tasks of the workflow (Blocks in a workflow are called workflow_tasks) Args: basic: If selected returns a simplified task-name : task-id` version. Returns: The workflow task info. \"\"\" url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /workflows/\" f \" { self . workflow_id } /tasks\" ) response_json = self . auth . _request ( request_type = \"GET\" , url = url ) tasks = response_json [ \"data\" ] logger . info ( f \"Got { len ( tasks ) } tasks/blocks in workflow { self . workflow_id } .\" ) if basic : return { task [ \"name\" ]: task [ \"id\" ] for task in tasks } else : return tasks run_job ( self , input_parameters = None , track_status = False , name = None ) \u00b6 Creates and runs a new job. Parameters: Name Type Description Default input_parameters Union[Dict, str, pathlib.Path] Either json string of workflow parameters or filepath to json. None track_status bool Automatically attaches workflow.track_status which queries the job status every 30 seconds. False name str The job name. Optional, by default the workflow name is assigned. None Returns: Type Description Job The spawned job object. Source code in up42/workflow.py def run_job ( self , input_parameters : Union [ Dict , str , Path ] = None , track_status : bool = False , name : str = None , ) -> \"Job\" : \"\"\" Creates and runs a new job. Args: input_parameters: Either json string of workflow parameters or filepath to json. track_status: Automatically attaches workflow.track_status which queries the job status every 30 seconds. name: The job name. Optional, by default the workflow name is assigned. Returns: The spawned job object. \"\"\" return self . _helper_run_job ( input_parameters = input_parameters , track_status = track_status , name = name ) run_jobs_parallel ( self , input_parameters_list = None , name = None , max_concurrent_jobs = 10 ) \u00b6 Create and run jobs in parallel. Parameters: Name Type Description Default input_parameters_list List[Dict] List of dictionary of input parameters None name str The job name. Optional, by default the workflow name is assigned. None max_concurrent_jobs int The maximum number of jobs to run in parallel. This is defined in the project settings. 10 Returns: Type Description JobCollection The spawned JobCollection object. Exceptions: Type Description ValueError When max_concurrent_jobs is greater than max_concurrent_jobs set in project settings. Source code in up42/workflow.py def run_jobs_parallel ( self , input_parameters_list : List [ Dict ] = None , name : str = None , max_concurrent_jobs : int = 10 , ) -> \"JobCollection\" : \"\"\" Create and run jobs in parallel. Args: input_parameters_list: List of dictionary of input parameters name: The job name. Optional, by default the workflow name is assigned. max_concurrent_jobs: The maximum number of jobs to run in parallel. This is defined in the project settings. Returns: The spawned JobCollection object. Raises: ValueError: When max_concurrent_jobs is greater than max_concurrent_jobs set in project settings. \"\"\" jobcollection = self . _helper_run_parallel_jobs ( input_parameters_list = input_parameters_list , max_concurrent_jobs = max_concurrent_jobs , name = name , ) return jobcollection test_job ( self , input_parameters = None , track_status = False , name = None ) \u00b6 Create a run a new test job (Test Query). With this test query you will not be charged with any data or processing credits, but have a preview of the job result. Parameters: Name Type Description Default input_parameters Union[Dict, str, pathlib.Path] Either json string of workflow parameters or filepath to json. None track_status bool Automatically attaches workflow.track_status which queries the job status every 30 seconds. False name str The job name. Optional, by default the workflow name is assigned. None Returns: Type Description Job The spawned test job object. Source code in up42/workflow.py def test_job ( self , input_parameters : Union [ Dict , str , Path ] = None , track_status : bool = False , name : str = None , ) -> \"Job\" : \"\"\" Create a run a new test job (Test Query). With this test query you will not be charged with any data or processing credits, but have a preview of the job result. Args: input_parameters: Either json string of workflow parameters or filepath to json. track_status: Automatically attaches workflow.track_status which queries the job status every 30 seconds. name: The job name. Optional, by default the workflow name is assigned. Returns: The spawned test job object. \"\"\" return self . _helper_run_job ( input_parameters = input_parameters , test_job = True , track_status = track_status , name = name , ) test_jobs_parallel ( self , input_parameters_list = None , name = None , max_concurrent_jobs = 10 ) \u00b6 Create and run test jobs (Test Query) in parallel. With this test query you will not be charged with any data or processing credits, but have a preview of the job result. Parameters: Name Type Description Default input_parameters_list List[Dict] List of dictionary of input parameters None name str The job name. Optional, by default the workflow name is assigned. None max_concurrent_jobs int The maximum number of jobs to run in parallel. This is defined in the project settings. 10 Returns: Type Description JobCollection The spawned test JobCollection object. Exceptions: Type Description ValueError When max_concurrent_jobs is greater than max_concurrent_jobs set in project settings. Source code in up42/workflow.py def test_jobs_parallel ( self , input_parameters_list : List [ Dict ] = None , name : str = None , max_concurrent_jobs : int = 10 , ) -> \"JobCollection\" : \"\"\" Create and run test jobs (Test Query) in parallel. With this test query you will not be charged with any data or processing credits, but have a preview of the job result. Args: input_parameters_list: List of dictionary of input parameters name: The job name. Optional, by default the workflow name is assigned. max_concurrent_jobs: The maximum number of jobs to run in parallel. This is defined in the project settings. Returns: The spawned test JobCollection object. Raises: ValueError: When max_concurrent_jobs is greater than max_concurrent_jobs set in project settings. \"\"\" return self . _helper_run_parallel_jobs ( input_parameters_list = input_parameters_list , max_concurrent_jobs = max_concurrent_jobs , test_job = True , name = name , ) update_name ( self , name = None , description = None ) \u00b6 Updates the workflow name and description. Parameters: Name Type Description Default name str New name of the workflow. None description str New description of the workflow. None Source code in up42/workflow.py def update_name ( self , name : str = None , description : str = None ) -> None : \"\"\" Updates the workflow name and description. Args: name: New name of the workflow. description: New description of the workflow. \"\"\" properties_to_update = { \"name\" : name , \"description\" : description } url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /workflows/\" f \" { self . workflow_id } \" ) self . auth . _request ( request_type = \"PUT\" , url = url , data = properties_to_update ) logger . info ( f \"Updated workflow name: { properties_to_update } \" )","title":"Workflow"},{"location":"reference/workflow/#workflow-class","text":"The Workflow class can query all available and spawn new jobs for an UP42 Workflow and helps to find and set the the workflow tasks, parameters and aoi.","title":"Workflow class"},{"location":"reference/workflow/#up42.workflow.Workflow","text":"","title":"up42.workflow.Workflow"},{"location":"reference/workflow/#up42.workflow.Workflow.max_concurrent_jobs","text":"Gets the maximum number of concurrent jobs allowed by the project settings.","title":"max_concurrent_jobs"},{"location":"reference/workflow/#up42.workflow.Workflow.add_workflow_tasks","text":"Adds or overwrites workflow tasks in a workflow on UP42. Parameters: Name Type Description Default input_tasks Union[List[str], List[Dict]] The input tasks, specifying the blocks. Can be a list of the block ids, block names or block display names (The name shown on the marketplace . required Info Using block ids specifies a specific version of the block that will be added to the workflow. With block names or block display names, the most recent version of a block will always be added. Examples: input_tasks_simple = [ 'a2daaab4-196d-4226-a018-a810444dcad1' , '4ed70368-d4e1-4462-bef6-14e768049471' ] input_tasks = [ \"sobloo-s2-l1c-aoiclipped\" , \"tiling\" ] input_tasks = [ \"Sentinel-2 L1C MSI AOI clipped\" , \"Raster Tiling\" ] Source code in up42/workflow.py def add_workflow_tasks ( self , input_tasks : Union [ List [ str ], List [ Dict ]]) -> None : \"\"\" Adds or overwrites workflow tasks in a workflow on UP42. Args: input_tasks: The input tasks, specifying the blocks. Can be a list of the block ids, block names or block display names (The name shown on the [marketplace](https://marketplace.up42.com). !!! Info Using block ids specifies a specific version of the block that will be added to the workflow. With block names or block display names, the most recent version of a block will always be added. Example: ```python input_tasks_simple = ['a2daaab4-196d-4226-a018-a810444dcad1', '4ed70368-d4e1-4462-bef6-14e768049471'] ``` ```python input_tasks = [\"sobloo-s2-l1c-aoiclipped\", \"tiling\"] ``` ```python input_tasks = [\"Sentinel-2 L1C MSI AOI clipped\", \"Raster Tiling\"] ``` \"\"\" # Relevant when non-linear workflows are introduced: # Optional: # The input_tasks can also be provided as the full, detailed workflow task # definition (dict of block id, block name and parent block name). Always use :1 # to be able to identify the order when two times the same workflow task is used. # The name is arbitrary, but best use the block name. # # Example: # ```python # input_tasks_full = [{'name': 'sobloo-s2-l1c-aoiclipped:1', # 'parentName': None, # 'blockId': 'a2daaab4-196d-4226-a018-a810444dcad1'}, # {'name': 'sharpening:1', # 'parentName': 'sobloo-s2-l1c-aoiclipped', # 'blockId': '4ed70368-d4e1-4462-bef6-14e768049471'}] # Construct proper task definition from simplified input. if isinstance ( input_tasks [ 0 ], str ) and not isinstance ( input_tasks [ 0 ], dict ): input_tasks = self . _construct_full_workflow_tasks_dict ( input_tasks ) url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /workflows/\" f \" { self . workflow_id } /tasks/\" ) self . auth . _request ( request_type = \"POST\" , url = url , data = input_tasks ) logger . info ( f \"Added tasks to workflow: { input_tasks } \" )","title":"add_workflow_tasks()"},{"location":"reference/workflow/#up42.workflow.Workflow.construct_parameters","text":"Constructs workflow input parameters with a specified aoi, the default input parameters, and optionally limit and order-ids. Further parameter editing needs to be done manually via dict.update({key:value}). Parameters: Name Type Description Default geometry Union[Dict, geojson.feature.Feature, geojson.feature.FeatureCollection, geojson.geometry.Polygon, List, geopandas.geodataframe.GeoDataFrame, shapely.geometry.polygon.Polygon, shapely.geometry.point.Point] One of Dict, FeatureCollection, Feature, List, GeoDataFrame, shapely.geometry.Polygon, shapely.geometry.Point. All assume EPSG 4326. None geometry_operation str Desired operation, One of \"bbox\", \"intersects\", \"contains\". None limit int Maximum number of expected results. None start_date str Query period starting day, format \"2020-01-01\". None end_date str Query period ending day, format \"2020-01-01\". None scene_ids List List of scene_ids, if given ignores all other parameters except geometry. None order_ids List[str] Optional, can be used to incorporate existing bought imagery on UP42 into new workflows. None Returns: Type Description Dict Dictionary of constructed input parameters. Source code in up42/workflow.py def construct_parameters ( self , geometry : Union [ Dict , Feature , FeatureCollection , geojson_Polygon , List , GeoDataFrame , Polygon , Point , ] = None , geometry_operation : str = None , handle_multiple_features : str = \"union\" , start_date : str = None , end_date : str = None , limit : int = None , scene_ids : List = None , order_ids : List [ str ] = None , ) -> Dict : \"\"\" Constructs workflow input parameters with a specified aoi, the default input parameters, and optionally limit and order-ids. Further parameter editing needs to be done manually via dict.update({key:value}). Args: geometry: One of Dict, FeatureCollection, Feature, List, GeoDataFrame, shapely.geometry.Polygon, shapely.geometry.Point. All assume EPSG 4326. geometry_operation: Desired operation, One of \"bbox\", \"intersects\", \"contains\". limit: Maximum number of expected results. start_date: Query period starting day, format \"2020-01-01\". end_date: Query period ending day, format \"2020-01-01\". scene_ids: List of scene_ids, if given ignores all other parameters except geometry. order_ids: Optional, can be used to incorporate existing bought imagery on UP42 into new workflows. Returns: Dictionary of constructed input parameters. \"\"\" input_parameters = self . _get_default_parameters () data_block_name = list ( input_parameters . keys ())[ 0 ] if order_ids is not None : # Needs to be handled in this function(not run_job) as it is only # relevant for the data block. input_parameters [ data_block_name ] = { \"order_ids\" : order_ids } else : if limit is not None : input_parameters [ data_block_name ][ \"limit\" ] = limit if scene_ids is not None : if not isinstance ( scene_ids , list ): scene_ids = [ scene_ids ] input_parameters [ data_block_name ][ \"ids\" ] = scene_ids input_parameters [ data_block_name ][ \"limit\" ] = len ( scene_ids ) input_parameters [ data_block_name ] . pop ( \"time\" ) elif start_date is not None and end_date is not None : time = f \" { start_date } T00:00:00Z/ { end_date } T23:59:59Z\" input_parameters [ data_block_name ][ \"time\" ] = time if geometry is not None : aoi_fc = any_vector_to_fc ( vector = geometry , ) aoi_feature = fc_to_query_geometry ( fc = aoi_fc , geometry_operation = geometry_operation , # type: ignore squash_multiple_features = handle_multiple_features , ) input_parameters [ data_block_name ][ geometry_operation ] = aoi_feature return input_parameters","title":"construct_parameters()"},{"location":"reference/workflow/#up42.workflow.Workflow.construct_parameters_parallel","text":"Maps a list of geometries and a list of time series into a list of input parameters of a workflow. If you pass 2 geometries and 1 time interval this will result in 2 x 1 input parameters. Parameters: Name Type Description Default geometries List[Union[Dict, geojson.feature.Feature, geojson.geometry.Polygon, shapely.geometry.polygon.Polygon, shapely.geometry.point.Point]] List of unit geometries to map with times. None interval_dates List[Tuple[str, str]] List of tuples of start and end dates, i.e. (\"2014-01-01\",\"2015-01-01\") . None scene_ids List List of scene ids. Will be mapped 1:1 to each job. All other arguments are ignored except geometries if passed. None limit_per_job int Limit passed to be passed to each individual job parameter. 1 geometry_operation str Geometry operation to be passed to each job parameter. 'intersects' Returns: Type Description List[dict] List of dictionary of constructed input parameters. Source code in up42/workflow.py def construct_parameters_parallel ( self , geometries : List [ Union [ Dict , Feature , geojson_Polygon , Polygon , Point , ] ] = None , interval_dates : List [ Tuple [ str , str ]] = None , scene_ids : List = None , limit_per_job : int = 1 , geometry_operation : str = \"intersects\" , ) -> List [ dict ]: \"\"\" Maps a list of geometries and a list of time series into a list of input parameters of a workflow. If you pass 2 geometries and 1 time interval this will result in 2 x 1 input parameters. Args: geometries: List of unit geometries to map with times. interval_dates: List of tuples of start and end dates, i.e. `(\"2014-01-01\",\"2015-01-01\")`. scene_ids: List of scene ids. Will be mapped 1:1 to each job. All other arguments are ignored except geometries if passed. limit_per_job: Limit passed to be passed to each individual job parameter. geometry_operation: Geometry operation to be passed to each job parameter. Returns: List of dictionary of constructed input parameters. \"\"\" # TODO: Rename arguments result_params = [] # scene_ids mapped to geometries if scene_ids is not None and geometries is not None : for geo in geometries : for scene_id in scene_ids : params = self . construct_parameters ( geometry = geo , scene_ids = [ scene_id ], geometry_operation = geometry_operation , ) result_params . append ( params ) # interval_dates mapped to geometries elif interval_dates is not None and geometries is not None : for geo in geometries : for start_date , end_date in interval_dates : params = self . construct_parameters ( geometry = geo , geometry_operation = geometry_operation , start_date = start_date , end_date = end_date , limit = limit_per_job , ) result_params . append ( params ) # only scene_ids elif scene_ids is not None : for scene_id in scene_ids : result_params . append ( self . construct_parameters ( geometry = None , scene_ids = [ scene_id ], ) ) else : raise ValueError ( \"Please provides geometries and scene_ids, geometries\" \"and time_interval or scene_ids.\" ) return result_params","title":"construct_parameters_parallel()"},{"location":"reference/workflow/#up42.workflow.Workflow.delete","text":"Deletes the workflow and sets the Python object to None. Source code in up42/workflow.py def delete ( self ) -> None : \"\"\" Deletes the workflow and sets the Python object to None. \"\"\" url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /workflows/\" f \" { self . workflow_id } \" ) self . auth . _request ( request_type = \"DELETE\" , url = url , return_text = False ) logger . info ( f \"Successfully deleted workflow: { self . workflow_id } \" ) del self","title":"delete()"},{"location":"reference/workflow/#up42.workflow.Workflow.get_compatible_blocks","text":"Gets all compatible blocks for the current workflow. If the workflow is empty it will provide all data blocks, if the workflow already has workflow tasks, it will provide the compatible blocks for the last workflow task in the workflow. Currently no data blocks can be attached to other data blocks. Source code in up42/workflow.py def get_compatible_blocks ( self ) -> Dict : \"\"\" Gets all compatible blocks for the current workflow. If the workflow is empty it will provide all data blocks, if the workflow already has workflow tasks, it will provide the compatible blocks for the last workflow task in the workflow. Currently no data blocks can be attached to other data blocks. \"\"\" last_task = list ( self . get_workflow_tasks ( basic = True ) . keys ())[ - 1 ] # type: ignore url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /workflows/ { self . workflow_id } /\" f \"compatible-blocks?parentTaskName= { last_task } \" ) response_json = self . auth . _request ( request_type = \"GET\" , url = url ) compatible_blocks = response_json [ \"data\" ][ \"blocks\" ] compatible_blocks = { block [ \"name\" ]: block [ \"blockId\" ] for block in compatible_blocks } return compatible_blocks","title":"get_compatible_blocks()"},{"location":"reference/workflow/#up42.workflow.Workflow.get_jobs","text":"Get all jobs associated with the workflow as a JobCollection or json. Parameters: Name Type Description Default return_json bool If true, returns the job info jsons instead of a JobCollection. False Returns: Type Description Union[up42.jobcollection.JobCollection, List[Dict]] A JobCollection, or alternatively the jobs info as json. Source code in up42/workflow.py def get_jobs ( self , return_json : bool = False ) -> Union [ JobCollection , List [ Dict ]]: \"\"\" Get all jobs associated with the workflow as a JobCollection or json. Args: return_json: If true, returns the job info jsons instead of a JobCollection. Returns: A JobCollection, or alternatively the jobs info as json. \"\"\" url = f \" { self . auth . _endpoint () } /projects/ { self . project_id } /jobs\" response_json = self . auth . _request ( request_type = \"GET\" , url = url ) jobs_json = response_json [ \"data\" ] jobs_workflow_json = [ j for j in jobs_json if j [ \"workflowId\" ] == self . workflow_id ] logger . info ( f \"Got { len ( jobs_workflow_json ) } jobs for workflow \" f \" { self . workflow_id } in project { self . project_id } .\" ) if return_json : return jobs_workflow_json else : jobs = [ Job ( self . auth , job_id = job [ \"id\" ], project_id = self . project_id ) for job in tqdm ( jobs_workflow_json ) ] jobcollection = JobCollection ( auth = self . auth , project_id = self . project_id , jobs = jobs ) return jobcollection","title":"get_jobs()"},{"location":"reference/workflow/#up42.workflow.Workflow.get_parameters_info","text":"Gets infos about the workflow parameters of each block in the current workflow to make it easy to construct the desired parameters. Returns: Type Description Dict Workflow parameters info json. Source code in up42/workflow.py def get_parameters_info ( self ) -> Dict : \"\"\" Gets infos about the workflow parameters of each block in the current workflow to make it easy to construct the desired parameters. Returns: Workflow parameters info json. \"\"\" workflow_parameters_info = {} workflow_tasks = self . get_workflow_tasks () for task in workflow_tasks : task_name = task [ \"name\" ] task_default_parameters = task [ \"block\" ][ \"parameters\" ] workflow_parameters_info [ task_name ] = task_default_parameters return workflow_parameters_info","title":"get_parameters_info()"},{"location":"reference/workflow/#up42.workflow.Workflow.get_workflow_tasks","text":"Get the workflow-tasks of the workflow (Blocks in a workflow are called workflow_tasks) Parameters: Name Type Description Default basic bool If selected returns a simplified task-name : task-id` version. False Returns: Type Description Union[List, Dict] The workflow task info. Source code in up42/workflow.py def get_workflow_tasks ( self , basic : bool = False ) -> Union [ List , Dict ]: \"\"\" Get the workflow-tasks of the workflow (Blocks in a workflow are called workflow_tasks) Args: basic: If selected returns a simplified task-name : task-id` version. Returns: The workflow task info. \"\"\" url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /workflows/\" f \" { self . workflow_id } /tasks\" ) response_json = self . auth . _request ( request_type = \"GET\" , url = url ) tasks = response_json [ \"data\" ] logger . info ( f \"Got { len ( tasks ) } tasks/blocks in workflow { self . workflow_id } .\" ) if basic : return { task [ \"name\" ]: task [ \"id\" ] for task in tasks } else : return tasks","title":"get_workflow_tasks()"},{"location":"reference/workflow/#up42.workflow.Workflow.run_job","text":"Creates and runs a new job. Parameters: Name Type Description Default input_parameters Union[Dict, str, pathlib.Path] Either json string of workflow parameters or filepath to json. None track_status bool Automatically attaches workflow.track_status which queries the job status every 30 seconds. False name str The job name. Optional, by default the workflow name is assigned. None Returns: Type Description Job The spawned job object. Source code in up42/workflow.py def run_job ( self , input_parameters : Union [ Dict , str , Path ] = None , track_status : bool = False , name : str = None , ) -> \"Job\" : \"\"\" Creates and runs a new job. Args: input_parameters: Either json string of workflow parameters or filepath to json. track_status: Automatically attaches workflow.track_status which queries the job status every 30 seconds. name: The job name. Optional, by default the workflow name is assigned. Returns: The spawned job object. \"\"\" return self . _helper_run_job ( input_parameters = input_parameters , track_status = track_status , name = name )","title":"run_job()"},{"location":"reference/workflow/#up42.workflow.Workflow.run_jobs_parallel","text":"Create and run jobs in parallel. Parameters: Name Type Description Default input_parameters_list List[Dict] List of dictionary of input parameters None name str The job name. Optional, by default the workflow name is assigned. None max_concurrent_jobs int The maximum number of jobs to run in parallel. This is defined in the project settings. 10 Returns: Type Description JobCollection The spawned JobCollection object. Exceptions: Type Description ValueError When max_concurrent_jobs is greater than max_concurrent_jobs set in project settings. Source code in up42/workflow.py def run_jobs_parallel ( self , input_parameters_list : List [ Dict ] = None , name : str = None , max_concurrent_jobs : int = 10 , ) -> \"JobCollection\" : \"\"\" Create and run jobs in parallel. Args: input_parameters_list: List of dictionary of input parameters name: The job name. Optional, by default the workflow name is assigned. max_concurrent_jobs: The maximum number of jobs to run in parallel. This is defined in the project settings. Returns: The spawned JobCollection object. Raises: ValueError: When max_concurrent_jobs is greater than max_concurrent_jobs set in project settings. \"\"\" jobcollection = self . _helper_run_parallel_jobs ( input_parameters_list = input_parameters_list , max_concurrent_jobs = max_concurrent_jobs , name = name , ) return jobcollection","title":"run_jobs_parallel()"},{"location":"reference/workflow/#up42.workflow.Workflow.test_job","text":"Create a run a new test job (Test Query). With this test query you will not be charged with any data or processing credits, but have a preview of the job result. Parameters: Name Type Description Default input_parameters Union[Dict, str, pathlib.Path] Either json string of workflow parameters or filepath to json. None track_status bool Automatically attaches workflow.track_status which queries the job status every 30 seconds. False name str The job name. Optional, by default the workflow name is assigned. None Returns: Type Description Job The spawned test job object. Source code in up42/workflow.py def test_job ( self , input_parameters : Union [ Dict , str , Path ] = None , track_status : bool = False , name : str = None , ) -> \"Job\" : \"\"\" Create a run a new test job (Test Query). With this test query you will not be charged with any data or processing credits, but have a preview of the job result. Args: input_parameters: Either json string of workflow parameters or filepath to json. track_status: Automatically attaches workflow.track_status which queries the job status every 30 seconds. name: The job name. Optional, by default the workflow name is assigned. Returns: The spawned test job object. \"\"\" return self . _helper_run_job ( input_parameters = input_parameters , test_job = True , track_status = track_status , name = name , )","title":"test_job()"},{"location":"reference/workflow/#up42.workflow.Workflow.test_jobs_parallel","text":"Create and run test jobs (Test Query) in parallel. With this test query you will not be charged with any data or processing credits, but have a preview of the job result. Parameters: Name Type Description Default input_parameters_list List[Dict] List of dictionary of input parameters None name str The job name. Optional, by default the workflow name is assigned. None max_concurrent_jobs int The maximum number of jobs to run in parallel. This is defined in the project settings. 10 Returns: Type Description JobCollection The spawned test JobCollection object. Exceptions: Type Description ValueError When max_concurrent_jobs is greater than max_concurrent_jobs set in project settings. Source code in up42/workflow.py def test_jobs_parallel ( self , input_parameters_list : List [ Dict ] = None , name : str = None , max_concurrent_jobs : int = 10 , ) -> \"JobCollection\" : \"\"\" Create and run test jobs (Test Query) in parallel. With this test query you will not be charged with any data or processing credits, but have a preview of the job result. Args: input_parameters_list: List of dictionary of input parameters name: The job name. Optional, by default the workflow name is assigned. max_concurrent_jobs: The maximum number of jobs to run in parallel. This is defined in the project settings. Returns: The spawned test JobCollection object. Raises: ValueError: When max_concurrent_jobs is greater than max_concurrent_jobs set in project settings. \"\"\" return self . _helper_run_parallel_jobs ( input_parameters_list = input_parameters_list , max_concurrent_jobs = max_concurrent_jobs , test_job = True , name = name , )","title":"test_jobs_parallel()"},{"location":"reference/workflow/#up42.workflow.Workflow.update_name","text":"Updates the workflow name and description. Parameters: Name Type Description Default name str New name of the workflow. None description str New description of the workflow. None Source code in up42/workflow.py def update_name ( self , name : str = None , description : str = None ) -> None : \"\"\" Updates the workflow name and description. Args: name: New name of the workflow. description: New description of the workflow. \"\"\" properties_to_update = { \"name\" : name , \"description\" : description } url = ( f \" { self . auth . _endpoint () } /projects/ { self . project_id } /workflows/\" f \" { self . workflow_id } \" ) self . auth . _request ( request_type = \"PUT\" , url = url , data = properties_to_update ) logger . info ( f \"Updated workflow name: { properties_to_update } \" )","title":"update_name()"}]}